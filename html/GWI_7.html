<div class="container">

<table style="width: 100%;"><tr>
<td>GWI-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Count and continuous generalized variability indexes
</h2>

<h3>Description</h3>

<p>Univariate Poisson dispersion index <code>di.fun</code>, univariate exponential variation index <code>vi.fun</code> functions are performed. Next, the univariate binomial dispersion index <code>dib.fun</code>, the univariate negative binomial dispersion index <code>dinb.fun</code> and the univariate inverse Gaussian variation index <code>viiG.fun</code> functions are given. Finally, the generalized dispersion index and its marginal one <code>gmdi.fun</code> , the generalized variation index and its marginal one <code>gmvi.fun</code> functions are displayed.
</p>


<h3>Details</h3>


<dl>
<dt>The univariate Poisson dispersion index (DI) and its relative versions with respect to binomial and negative binomial distributions:</dt>
<dd>
<p>The Poisson dispersion phenomenon is well-known and very widely used in practice; see, e.g., Kokonendji (2014) for a review of count (or discrete integer-valued) models. There are many interpretable mechanisms leading to this phenomenon which makes it possible to classify count distributions and make inference; see, e.g., Mizère et al. (2006) and Touré et al. (2020) for approximative statistical tests. Introduced from Fisher (1934), the Poisson dispersion index,  also called the Fisher dispersion index, of a count random variable <code class="reqn">X</code> on <code class="reqn">S=\{0,1,2,\ldots\}=:N_0</code> can be defined as </p>
<p style="text-align: center;"><code class="reqn">DI(X)=\frac{VarX}{EX},</code>
</p>
<p> the ratio of variance to mean. In fact, the positive quantity <code class="reqn">DI(X)</code> is the ratio of two variances since <code class="reqn">EX</code> is the expected variance under the Poisson distribution. Hence, one easily deduces the concept of the relative dispersion index (denoted by RDI)
by choosing another reference than the Poisson distribution. Indeed, if <code class="reqn">X</code> and <code class="reqn">Y</code> are two count random variables on the same support <code class="reqn">S\subseteq N_0</code> such that <code class="reqn">EX=EY</code>, then
</p>
<p style="text-align: center;"><code class="reqn">RDI_Y(X):=\frac{VarX}{Var Y}=\frac{DI(X)}{DI(Y)} &gt;=&lt; 1;</code>
</p>

<p>i.e. <code class="reqn">X</code> is over-, equi- and under-dispersed compared to <code class="reqn">Y</code> if <code class="reqn">VarX &gt; VarY</code>, <code class="reqn">VarX = VarY</code> and <code class="reqn">VarX &lt; VarY</code>, respectively.<br><br>
For instance, the binomial dispersion index is defined as </p>
<p style="text-align: center;"><code class="reqn">RDI_B(X)=\frac{var X}{EX(1-EX/N)},</code>
</p>
<p> where <code class="reqn">N\in \{1,2,\ldots\}</code> is the fixed number of trials. Also, the negative binomial dispersion index is defined as </p>
<p style="text-align: center;"><code class="reqn">RDI_NB(X)=\frac{varX}{EX(1+EX/ \lambda)},</code>
</p>
<p> where <code class="reqn">\lambda &gt; 0</code> is the dispersion parameter. See also, Weiss (2018, page 15) and Abid et al. (2021) for more details.
</p>
</dd>
</dl>
<dl>
<dt>The univariate variation index (VI) and its relative version with respect to inverse Gaussian distribution:</dt>
<dd>
<p>More recently, Abid et al. (2020) have introduced the exponential variation index for positive continuous random variable <code class="reqn">X</code> on <code class="reqn">[0,\infty)</code> as </p>
<p style="text-align: center;"><code class="reqn">VI(X)=\frac{VarX}{(EX)^2}.</code>
</p>
<p> It can be viewed as the squared coefficient of variation. It is used in the framework of reliability to discriminate distribution of increasing/decreasing failure rate on the average (IFRA/DFRA); see, e.g., Barlow and Proschan (1981) in the sense of the coefficient of variation. See also Touré et al. (2020) for more details. Following RDI, the relative variation index (RVI) is defined, for two continuous random variables <code class="reqn">X</code> and <code class="reqn">Y</code> on the same support <code class="reqn">S = [0,\infty)</code> with <code class="reqn">EX = EY</code>, by
</p>
<p style="text-align: center;"><code class="reqn">RVI_Y(X):=\frac{VarX}{VarY}=\frac{VI(X)}{VI(Y)} &gt;=&lt; 1;</code>
</p>

<p>i.e. <code class="reqn">X</code> is over-, equi- and under-varied compared to <code class="reqn">Y</code> if <code class="reqn">VarX &gt; VarY</code>, <code class="reqn">VarX = VarY</code> and <code class="reqn">VarX &lt; VarY</code>, respectively. For instance, the inverse Gaussian variation index is defined as </p>
<p style="text-align: center;"><code class="reqn">RVI_IG(X)=\lambda^2\frac{var X}{(EX)^3},</code>
</p>
<p> where <code class="reqn">\lambda &gt; 0</code> is the shape parameter.
</p>
</dd>
</dl>
<p>Next, consider the following notations. Let <code class="reqn">Y</code> = <code class="reqn">(Y_1,\ldots,Y_k)^{\top}</code> be a nondegenerate count or continuous <code class="reqn">k</code>-variate random vector, <code class="reqn">k\ge 1</code>. Let also <code class="reqn">EY</code> be the mean vector of <code class="reqn">Y</code> and <code class="reqn">covY</code>= <code class="reqn">(cov(Y_i,Y_j) )_{i,j\in \{1,\ldots,k\}}</code> the covariance matrix of <code class="reqn">Y</code>.
</p>

<dl>
<dt>The generalized dispersion index (GDI) and marginal dispersion index (MVI):</dt>
<dd>
<p>Kokonendji and Puig (2018) have introduced the <em>generalized dispersion index</em> for count vector <code class="reqn">Y</code> on <code class="reqn">\{0,1,2,\ldots\}^k</code> by
</p>
<p style="text-align: center;"><code class="reqn">GDI(Y) =\frac{\sqrt{EY}^{\top} ( covY)\sqrt{EY}}{EY^{\top}EY}.</code>
</p>

<p>Note that when <code class="reqn">k=1</code>, <code class="reqn">GDI(Y)</code> is just the classical Fisher dispersion index DI.
<code class="reqn">GDI</code>(<code class="reqn">Y</code>) makes it possible to compare the full variability of <code class="reqn">Y</code> (in the numerator) with respect to its expected uncorrelated Poissonian variability (in the denominator) which depends only on <code class="reqn">EY</code>. <code class="reqn">GDI(Y)</code> takes into account the correlation between variables.
For only taking into account the dispersion information coming from the margins, the authors defined the "marginal dispersion index":
</p>
<p style="text-align: center;"><code class="reqn">MDI(Y) = \frac{\sqrt{EY}^{\top}( diag varY )\sqrt{EY}}{EY^{\top}EY}=\sum_{j=1}^k\frac{\{E(Y_j)\}^2}{EY^{\top}EY} DI(Y_j).</code>
</p>
</dd>
</dl>
<dl>
<dt>The generalized variation index (GVI) and marginal variation index (MVI):</dt>
<dd>
<p>Similarly, Kokonendji et al. (2020) defined the <em>generalized variation index</em> for positive continuous vector <code class="reqn">Y</code> on <code class="reqn">[0, \infty)^k</code> by
</p>
<p style="text-align: center;"><code class="reqn">GVI(Y) =\frac{EY^{\top} ( covY) EY}{(EY^{\top}EY)^2}.</code>
</p>

<p>Remark that when <code class="reqn">k=1</code>, <code class="reqn">GVI(Y)</code> is the univariate variation index VI.
<code class="reqn">GVI(Y)</code> makes it possible to compare the full variability of <code class="reqn">Y</code> (in the numerator) with respect to its expected uncorrelated exponential variability (in the denominator) which depends only on <code class="reqn">EY</code>. Also, <code class="reqn">GVI(Y)</code> takes into account the correlation between variables.
To only take into account the variation information coming from the margins, Kokonendji et al. (2020) defined the "marginal variation index":
</p>
<p style="text-align: center;"><code class="reqn">MVI(Y) = \frac{EY^{\top}( diag varY )EY}{(EY^{\top}EY)^2}=\sum_{j=1}^k\frac{(EY_j)^4}{(EY^{\top}EY)^2} VI(Y_j).
</code>
</p>

</dd>
</dl>
<h3>Author(s)</h3>

<p>Aboubacar Y. Touré and Célestin C. Kokonendji
</p>
<p>Maintainer: Aboubacar Y. Touré &lt;aboubacaryacoubatoure.ussgb@gmail.com&gt;
</p>


<h3>References</h3>

<p>Abid, R., Kokonendji, C.C. and Masmoudi, A. (2020). Geometric Tweedie regression models for continuous and semicontinuous data with variation phenomenon, <em>AStA Advances in Statistical Analysis</em> <b>104</b>, 33-58.
</p>
<p>Abid, R.,Kokonendji, C.C. and Masmoudi, A. (2021). On Poisson-exponential-Tweedie models for ultra-overdispersed count data, <em>AStA Advances in Statistical Analysis</em> <b>105</b>, 1-23.
</p>
<p>Barlow, R.A. and Proschan, F. (1981). Statistical Theory of Reliability and Life Testing : Probability Models, <em>Silver Springs</em>, Maryland.
</p>
<p>Fisher, R.A. (1934). The effects of methods of ascertainment upon the estimation of frequencies, <em>Annals of Eugenics</em> <b>6</b>, 13-25.
</p>
<p>Kokonendji, C.C., Over- and underdispersion models. In: N. Balakrishnan (Ed.) The Wiley Encyclopedia of Clinical Trials- Methods and Applications of Statistics in Clinical Trials, <b>Vol.2</b> (Chap.30), pp. 506-526. <em>Wiley</em>, New York (2014).
</p>
<p>Kokonendji, C.C. and Puig, P. (2018). Fisher dispersion index for multivariate count distributions : A review and a new proposal, <em>Journal of Multivariate Analysis</em> <b>165</b>, 180-193.
</p>
<p>Kokonendji, C.C., Touré, A.Y. and Sawadogo, A. (2020). Relative variation indexes for multivariate continuous distributions on <code class="reqn">[0,\infty)^k</code> and extensions, <em>AStA Advances in Statistical Analysis</em> <b>104</b>, 285-307.
</p>
<p>Mizère, D., Kokonendji, C.C. and Dossou-Gbété, S. (2006). Quelques tests de la loi de Poisson contre des alternatives géenérales basées sur l'indice de dispersion de Fisher, <em>Revue de Statistique Appliquée</em> <b>54</b>, 61-84.
</p>
<p>Touré, A.Y., Dossou-Gbété, S. and Kokonendji, C.C. (2020). Asymptotic normality of the test statistics for relative dispersion and relative variation indexes, <em>Journal of Applied Statistics</em> <b>47</b>, 2479-2491.
</p>
<p>Weiss, C.H. (2018). An Introduction to Discrete-Valued Times Series. <em>Wiley</em>, Hoboken NJ.
</p>


</div>