<div class="container">

<table style="width: 100%;"><tr>
<td>johnson_neyman</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Spotlight-analysis: Create Johnson-Neyman confidence intervals and plots</h2>

<h3>Description</h3>

<p>Function conduct a spotlight-analysis to create so-called
Johnson-Neyman intervals. The <code>plot()</code> method can be used to visualize the
results of the Johnson-Neyman test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">johnson_neyman(x, precision = 500, p_adjust = NULL, ...)

spotlight_analysis(x, precision = 500, p_adjust = NULL, ...)

## S3 method for class 'ggjohnson_neyman'
plot(
  x,
  colors = c("#f44336", "#2196F3"),
  show_association = TRUE,
  show_rug = FALSE,
  verbose = TRUE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An object of class <code>ggeffects</code>, as returned by the functions
from this package.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>precision</code></td>
<td>
<p>Number of values used for the range of the moderator variable
to calculate the Johnson-Neyman interval. This argument is passed down to
<code>pretty(..., n = precision)</code>. Usually, the default value of 500 is sufficient.
Increasing this value will result in a smoother plot and more accurate values
for the interval bounds, but can also slightly increase the computation time.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_adjust</code></td>
<td>
<p>Character vector, if not <code>NULL</code>, indicates the method to
adjust p-values. See <code>stats::p.adjust()</code> or <code>stats::p.adjust.methods</code>
for details. Further possible adjustment methods are <code>"tukey"</code> or <code>"sidak"</code>,
and for <code>johnson_neyman()</code>, <code>"fdr"</code> (or <code>"bh"</code>) and <code>"esarey"</code> (or its
short-cut <code>"es"</code>) are available options. Some caution is necessary when
adjusting p-value for multiple comparisons. See also section <em>P-value adjustment</em>
below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed down to <code>test_predictions()</code> (and then probably
further to <code>marginaleffects::slopes()</code>). See <code>?test_predictions</code> for further
details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>colors</code></td>
<td>
<p>Colors used for the plot. Must be a vector with two color
values. Only used if <code>show_association = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show_association</code></td>
<td>
<p>Logical, if <code>TRUE</code>, highlights the range where values
of the moderator are positively or negtatively associated with the outcome.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>show_rug</code></td>
<td>
<p>Logical, if <code>TRUE</code>, adds a rug with raw data of the moderator
variable to the plot. This helps visualizing its distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Show/hide printed message for plots.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Johnson-Neyman intervals help to understand where slopes are significant
in the context of interactions in regression models. Thus, the interval is only
useful if the model contains at least one interaction term. The function
accepts the results of a call to <code>predict_response()</code>. The <em>first</em> and the
<em>last</em> focal term used in the <code>terms</code> argument of <code>predict_response()</code> must
be numeric. The function will then test the slopes of the first focal terms
against zero, for different moderator values of the last focal term. If only
one numeric focal term is given, the function will create contrasts by levels
of the categorical focal term. Use <code>plot()</code> to create a plot of the results.
</p>
<p>To avoid misleading interpretations of the plot, we speak of "positive" and
"negative" associations, respectively, and "no clear" associations (instead
of "significant" or "non-significant"). This should prevent the user from
considering a non-significant range of values of the moderator as "accepting
the null hypothesis".
</p>


<h3>Value</h3>

<p>A data frame including contrasts of the <code>test_predictions()</code> for the
given interaction terms; for <code>plot()</code>, returns a Johnson-Neyman plot.
</p>


<h3>P-value adjustment for multiple comparisons</h3>

<p>Note that p-value adjustment for methods supported by <code>p.adjust()</code> (see also
<code>p.adjust.methods</code>), each row is considered as one set of comparisons, no
matter which <code>test</code> was specified. That is, for instance, when <code>test_predictions()</code>
returns eight rows of predictions (when <code>test = NULL</code>), and <code>p_adjust = "bonferroni"</code>,
the p-values are adjusted in the same way as if we had a test of pairwise
comparisons (<code>test = "pairwise"</code>) where eight rows of comparisons are
returned. For methods <code>"tukey"</code> or <code>"sidak"</code>, a rank adjustment is done
based on the number of combinations of levels from the focal predictors
in <code>terms</code>. Thus, the latter two methods may be useful for certain tests
only, in particular pairwise comparisons.
</p>
<p>For <code>johnson_neyman()</code>, the only available adjustment methods are <code>"fdr"</code>
(or <code>"bh"</code>) (<em>Benjamini &amp; Hochberg (1995)</em>) and <code>"esarey"</code> (or <code>"es"</code>)
(<em>Esarey and Sumner 2017</em>). These usually return similar results. The major
difference is that <code>"fdr"</code> can be slightly faster and more stable in edge
cases, however, confidence intervals are not updated. Only the p-values are
adjusted. <code>"esarey"</code> is slower, but confidence intervals are updated as well.
</p>


<h3>References</h3>

<p>Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and
multilevel regression: Inferential and graphical techniques. Multivariate
Behavioral Research, 40(3), 373-400. doi: 10.1207/s15327906mbr4003_5
</p>
<p>Esarey, J., &amp; Sumner, J. L. (2017). Marginal effects in interaction models:
Determining and controlling the false positive rate. Comparative Political
Studies, 1–33. Advance online publication. doi: 10.1177/0010414017730080
</p>
<p>Johnson, P.O. &amp; Fay, L.C. (1950). The Johnson-Neyman technique, its theory
and application. Psychometrika, 15, 349-367. doi: 10.1007/BF02288864
</p>
<p>McCabe CJ, Kim DS, King KM. Improving Present Practices in the Visual Display
of Interactions. Advances in Methods and Practices in Psychological Science.
2018;1(2):147-165. doi:10.1177/2515245917746792
</p>
<p>Spiller, S. A., Fitzsimons, G. J., Lynch, J. G., &amp; McClelland, G. H. (2013).
Spotlights, Floodlights, and the Magic Number Zero: Simple Effects Tests in
Moderated Regression. Journal of Marketing Research, 50(2), 277–288.
doi:10.1509/jmr.12.0420
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
data(efc, package = "ggeffects")
efc$c172code &lt;- as.factor(efc$c172code)
m &lt;- lm(neg_c_7 ~ c12hour * barthtot * c172code, data = efc)

pr &lt;- predict_response(m, c("c12hour", "barthtot"))
johnson_neyman(pr)
plot(johnson_neyman(pr))

pr &lt;- predict_response(m, c("c12hour", "c172code", "barthtot"))
johnson_neyman(pr)
plot(johnson_neyman(pr))

# robust standard errors
if (requireNamespace("sandwich")) {
  johnson_neyman(pr, vcov = sandwich::vcovHC)
}

## End(Not run)

</code></pre>


</div>