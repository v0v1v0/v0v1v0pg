<div class="container">

<table style="width: 100%;"><tr>
<td>mixture</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>mixtures of probability distributions</h2>

<h3>Description</h3>

<p><code>mixture</code> combines other probability distributions into a
single mixture distribution, either over a variable, or for fixed data.
</p>


<h3>Usage</h3>

<pre><code class="language-R">mixture(..., weights, dim = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>variable greta arrays following probability distributions (see
<code>distributions()</code>); the component distributions in a mixture
distribution.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a column vector or array of mixture weights, which must be
positive, but need not sum to one. The first dimension must be the number
of distributions, the remaining dimensions must either be 1 or match the
distribution dimension.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dim</code></td>
<td>
<p>the dimensions of the greta array to be returned, either a scalar
or a vector of positive integers.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>weights</code> are rescaled to sum to one along the first
dimension, and are then used as the mixing weights of the distribution.
I.e. the probability density is calculated as a weighted sum of the
component probability distributions passed in via <code style="white-space: pre;">⁠\dots⁠</code>
</p>
<p>The component probability distributions must all be either continuous or
discrete, and must have the same dimensions.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# a scalar variable following a strange bimodal distibution
weights &lt;- uniform(0, 1, dim = 3)
a &lt;- mixture(normal(-3, 0.5),
  normal(3, 0.5),
  normal(0, 3),
  weights = weights
)
m &lt;- model(a)
plot(mcmc(m, n_samples = 500))

# simulate a mixture of poisson random variables and try to recover the
# parameters with a Bayesian model
x &lt;- c(
  rpois(800, 3),
  rpois(200, 10)
)

weights &lt;- uniform(0, 1, dim = 2)
rates &lt;- normal(0, 10, truncation = c(0, Inf), dim = 2)
distribution(x) &lt;- mixture(poisson(rates[1]),
  poisson(rates[2]),
  weights = weights
)
m &lt;- model(rates)
draws_rates &lt;- mcmc(m, n_samples = 500)

# check the mixing probabilities after fitting using calculate()
# (you could also do this within the model)
normalized_weights &lt;- weights / sum(weights)
draws_weights &lt;- calculate(normalized_weights, draws_rates)

# get the posterior means
summary(draws_rates)$statistics[, "Mean"]
summary(draws_weights)$statistics[, "Mean"]

# weights can also be an array, giving different mixing weights
# for each observation (first dimension must be number of components)
dim &lt;- c(5, 4)
weights &lt;- uniform(0, 1, dim = c(2, dim))
b &lt;- mixture(normal(1, 1, dim = dim),
  normal(-1, 1, dim = dim),
  weights = weights
)

## End(Not run)
</code></pre>


</div>