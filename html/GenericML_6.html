<div class="container">

<table style="width: 100%;"><tr>
<td>GenericML_single</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Single iteration of the GenericML algorithm</h2>

<h3>Description</h3>

<p>Performs generic ML inference for a single learning technique and a given split of the data. Can be seen as a single iteration of Algorithm 1 in the paper.
</p>


<h3>Usage</h3>

<pre><code class="language-R">GenericML_single(
  Z,
  D,
  Y,
  learner,
  propensity_scores,
  M_set,
  A_set = setdiff(1:length(Y), M_set),
  Z_CLAN = NULL,
  HT = FALSE,
  quantile_cutoffs = c(0.25, 0.5, 0.75),
  X1_BLP = setup_X1(),
  X1_GATES = setup_X1(),
  diff_GATES = setup_diff(),
  diff_CLAN = setup_diff(),
  vcov_BLP = setup_vcov(),
  vcov_GATES = setup_vcov(),
  equal_variances_CLAN = FALSE,
  significance_level = 0.05,
  min_variation = 1e-05
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>A numeric design matrix that holds the covariates in its columns.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>A binary vector of treatment assignment. Value one denotes assignment to the treatment group and value zero assignment to the control group.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>A numeric vector containing the response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learner</code></td>
<td>
<p>A character specifying the machine learner to be used for estimating the baseline conditional average (BCA) and conditional average treatment effect (CATE). Either <code>'lasso'</code>, <code>'random_forest'</code>, <code>'tree'</code>, or a custom learner specified with <code>mlr3</code> syntax. In the latter case, do <em>not</em> specify in the <code>mlr3</code> syntax specification if the learner is a regression learner or classification learner. Example: <code>'mlr3::lrn("ranger", num.trees = 100)'</code> for a random forest learner with 100 trees. Note that this is a string and the absence of the <code>classif.</code> or <code>regr.</code> keywords. See <a href="https://mlr3learners.mlr-org.com">https://mlr3learners.mlr-org.com</a> for a list of <code>mlr3</code> learners.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>propensity_scores</code></td>
<td>
<p>A numeric vector of propensity score estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M_set</code></td>
<td>
<p>A numerical vector of indices of observations in the main sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A_set</code></td>
<td>
<p>A numerical vector of indices of observations in the auxiliary sample. Default is complementary set to <code>M_set</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z_CLAN</code></td>
<td>
<p>A numeric matrix holding variables on which classification analysis (CLAN) shall be performed. CLAN will be performed on each column of the matrix. If <code>NULL</code> (default), then <code>Z_CLAN = Z</code>, i.e. CLAN is performed for all variables in <code>Z</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>HT</code></td>
<td>
<p>Logical. If <code>TRUE</code>, a Horvitz-Thompson (HT) transformation is applied in the BLP and GATES regressions. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quantile_cutoffs</code></td>
<td>
<p>The cutoff points of the quantiles that shall be used for GATES grouping. Default is <code>c(0.25, 0.5, 0.75)</code>, which corresponds to the four quartiles.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X1_BLP</code></td>
<td>
<p>Specifies the design matrix <code class="reqn">X_1</code> in the regression. Must be an object of class  <code>"setup_X1"</code>. See the documentation of <code>setup_X1()</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X1_GATES</code></td>
<td>
<p>Same as <code>X1_BLP</code>, just for the GATES regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diff_GATES</code></td>
<td>
<p>Specifies the generic targets of GATES. Must be an object of class <code>"setup_diff"</code>. See the documentation of <code>setup_diff()</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>diff_CLAN</code></td>
<td>
<p>Same as <code>diff_GATES</code>, just for the CLAN generic targets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vcov_BLP</code></td>
<td>
<p>Specifies the covariance matrix estimator in the BLP regression. Must be an object of class <code>"setup_vcov"</code>. See the documentation of <code>setup_vcov()</code> for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vcov_GATES</code></td>
<td>
<p>Same as <code>vcov_BLP</code>, just for the GATES regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>equal_variances_CLAN</code></td>
<td>
<p>Logical. If <code>TRUE</code>, then all within-group variances of the CLAN groups are assumed to be equal. Default is <code>FALSE</code>. This specification is required for heteroskedasticity-robust variance estimation on the difference of two CLAN generic targets (i.e. variance of the difference of two means). If <code>TRUE</code> (corresponds to homoskedasticity assumption), the pooled variance is used. If <code>FALSE</code> (heteroskedasticity), the variance of Welch's t-test is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>significance_level</code></td>
<td>
<p>Significance level for VEIN. Default is 0.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_variation</code></td>
<td>
<p>Specifies a threshold for the minimum variation of the BCA/CATE predictions. If the variation of a BCA/CATE prediction falls below this threshold, random noise with distribution <code class="reqn">N(0, var(Y)/20)</code> is added to it. Default is <code>1e-05</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The specifications <code>"lasso"</code>, <code>"random_forest"</code>, and <code>"tree"</code> in <code>learner</code> correspond to the following <code>mlr3</code> specifications (we omit the keywords <code>classif.</code> and <code>regr.</code>). <code>"lasso"</code> is a cross-validated Lasso estimator, which corresponds to <code>'mlr3::lrn("cv_glmnet", s = "lambda.min", alpha = 1)'</code>. <code>"random_forest"</code> is a random forest with 500 trees, which corresponds to <code>'mlr3::lrn("ranger", num.trees = 500)'</code>. <code>"tree"</code> is a tree learner, which corresponds to <code>'mlr3::lrn("rpart")'</code>.
</p>


<h3>Value</h3>

<p>A list with the following components:
</p>

<dl>
<dt><code>BLP</code></dt>
<dd>
<p>An object of class <code>"BLP"</code>.</p>
</dd>
<dt><code>GATES</code></dt>
<dd>
<p>An object of class <code>"GATES"</code>.</p>
</dd>
<dt><code>CLAN</code></dt>
<dd>
<p>An object of class <code>"CLAN"</code>.</p>
</dd>
<dt><code>proxy_BCA</code></dt>
<dd>
<p>An object of class <code>"proxy_BCA"</code>.</p>
</dd>
<dt><code>proxy_CATE</code></dt>
<dd>
<p>An object of class <code>"proxy_CATE"</code>.</p>
</dd>
<dt><code>best</code></dt>
<dd>
<p>Estimates of the <code class="reqn">\Lambda</code> parameters for finding the best learner. Returned by <code>lambda_parameters()</code>.</p>
</dd>
</dl>
<h3>References</h3>

<p>Chernozhukov V., Demirer M., Duflo E., Fernández-Val I. (2020). “Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments.” <em>arXiv preprint arXiv:1712.04802</em>. URL: <a href="https://arxiv.org/abs/1712.04802">https://arxiv.org/abs/1712.04802</a>.
</p>
<p>Lang M., Binder M., Richter J., Schratz P., Pfisterer F., Coors S., Au Q., Casalicchio G., Kotthoff L., Bischl B. (2019). “mlr3: A Modern Object-Oriented Machine Learning Framework in R.” <em>Journal of Open Source Software</em>, <b>4</b>(44), 1903. doi: <a href="https://doi.org/10.21105/joss.01903">10.21105/joss.01903</a>.
</p>


<h3>See Also</h3>

<p><code>GenericML()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">if(require("ranger")){
## generate data
set.seed(1)
n  &lt;- 150                        # number of observations
p  &lt;- 5                          # number of covariates
Z  &lt;- matrix(runif(n*p), n, p)   # design matrix
D  &lt;- rbinom(n, 1, 0.5)          # random treatment assignment
Y  &lt;- runif(n)                   # outcome variable
propensity_scores &lt;- rep(0.5, n) # propensity scores
M_set &lt;- sample(1:n, size = n/2) # main set

## specify learner
learner &lt;- "mlr3::lrn('ranger', num.trees = 10)"

## run single GenericML iteration
GenericML_single(Z, D, Y, learner, propensity_scores, M_set)
}

</code></pre>


</div>