<div class="container">

<table style="width: 100%;"><tr>
<td>gmdh.gia</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>GMDH GIA</h2>

<h3>Description</h3>

<p>Build a regression model performing GMDH GIA (Generalized Iterative Algorithm) with Active Neurons (Combinatorial algorithm). <br>
For more information, please read the package's vignette.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gmdh.gia(
  X,
  y,
  prune = ncol(X),
  criteria = c("PRESS", "test", "ICOMP"),
  x.test = NULL,
  y.test = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>matrix with N&gt;3 columns and M rows, containing independent variables in the model. <br>
The data must not contain NAs</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>vector or matrix containing dependent variable in the model. <br>
The data must not contain NAs</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prune</code></td>
<td>
<p>an integer whose recommended minimum value is the number of initial regressors. <br>
The maximum value will depend on the available RAM. <br>
Prune is the selected number of neurons from layer i to layer i+1. The resulting layer i+1 has prune(prune-1)/2 neurons; for example with prune=150, the resulting nerurons will be 11.175</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criteria</code></td>
<td>
<p>GMDH external criteria. Values: <br></p>

<ul>
<li>
<p> PRESS: predicted residual error sum of squares. <br></p>
</li>
<li>
<p> test: use x.test and y.test to estimate RMSE (root mean squeare errors). <br></p>
</li>
<li>
<p> ICOMP: Index of Informational Complexity. Like PRESS, it is computed without recalculating of system.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x.test</code></td>
<td>
<p>matrix with a sample randomly drawn from the initial data. <br>
It is used when criteria = test. <br>
This sample should not be included in X.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y.test</code></td>
<td>
<p>vector or matrix with y values correspond with x.test values.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>An object of class gia.
</p>


<h3>References</h3>

<p>Bozdogan, H. and Haughton, D.M.A. (1998): "Information complexity criteria for regression models", Computational Statistics &amp; Data Analysis, 28, pp. 51-76 &lt;doi: 10.1016/S0167-9473(98)00025-5&gt; <br></p>
<p>Farlow, S.J. (1981): "The GMDH algorithm of Ivakhnenko", The American Statistician, 35(4), pp. 210-215. &lt;doi: 10.2307/2683292&gt; <br></p>
<p>Hild, Ch. R. and Bozdogan, H. (1995): "The use of information-based model selection criteria in the GMDH algorithm", Systems Analysis Modelling Simulation, 20(1-2), pp. 29-50 <br></p>
<p>Ivakhnenko, A.G. (1968): "The Group Method of Data Handling - A Rival of the Method of Stochastic Approximation", Soviet Automatic Control, 13(3), pp. 43-55 <br></p>
<p>MÃ¼ller, J.-A., Ivachnenko, A.G. and Lemke, F. (1998): "GMDH Algorithms for Complex Systems Modelling", Mathematical and Computer Modelling of Dynamical Systems, 4(4), pp. 275-316 &lt;doi: 10.1080/13873959808837083&gt; <br></p>
<p>Stepashko, V. Bulgakova, O. and Zosimov V. (2018): "Construction and Research of the Generalized Iterative GMDH Algorithm with Active Neurons", Advances in Intelligent Systems and Computing II, pp. 492-510 &lt;doi:10.1007/978-3-319-70581-1_35&gt;
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(123)
x &lt;- matrix(data = c(rnorm(500)), ncol = 4, nrow = 125)
colnames(x) &lt;- c("a", "b", "c", "d")
y &lt;- matrix(data = c(10 + x[, "a"] + x[, "d"]^2), ncol = 1)
colnames(y) &lt;- "y"
x.test &lt;- x[1:5, ]
y.test &lt;- y[1:5]
x &lt;- x[-c(1:5), ]
y &lt;- y[-c(1:5)]

mod &lt;- gmdh.gia(X = x, y = y, criteria = "PRESS")
pred &lt;- predict(mod, x.test)
summary(sqrt((pred - y.test)^2))

</code></pre>


</div>