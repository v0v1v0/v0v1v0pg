<div class="container">

<table style="width: 100%;"><tr>
<td>gp_draw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Make predictions with a GP model</h2>

<h3>Description</h3>

<p>Function <code>gp_pred</code> can be used to make analytic predictions for the latent function
values at test points, whereas <code>gp_draw</code>
can be used to draw from the predictive distribution (or from the prior if the GP has
not been fitted yet.)
</p>


<h3>Usage</h3>

<pre><code class="language-R">gp_draw(
  gp,
  xnew,
  draws = NULL,
  transform = TRUE,
  target = FALSE,
  marginal = FALSE,
  cfind = NULL,
  jitter = NULL,
  seed = NULL,
  ...
)

gp_pred(
  gp,
  xnew,
  var = FALSE,
  quantiles = NULL,
  transform = FALSE,
  cfind = NULL,
  jitter = NULL,
  quad_order = 15,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>gp</code></td>
<td>
<p>A GP model object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xnew</code></td>
<td>
<p>N-by-d matrix of input values (N is the number of test points and d
the input dimension).
Can also be a vector of length N if the model has only a single input.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>draws</code></td>
<td>
<p>Number of draws to generate from the predictive distribution for the
latent values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>transform</code></td>
<td>
<p>Whether to transform the draws of latent values to the same scale
as the target y, that is, through the response (or inverse-link) function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>If TRUE, draws values for the target variable <code>y</code> instead of the latent
function values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>marginal</code></td>
<td>
<p>If TRUE, then draws for each test point are only marginally correct, but the
covariance structure between test points is not retained. However, this will make the sampling
considerably faster in some cases, and can be useful if one is interested only in looking
at the marginal predictive distributions for a large number of test locations
(for example, in posterior predictive checking).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cfind</code></td>
<td>
<p>Indices of covariance functions to be used in the prediction. By default uses
all covariance functions.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter</code></td>
<td>
<p>Magnitude of diagonal jitter for covariance matrices for numerical stability.
Default is 1e-6.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed for draws.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional parameters that might be needed. For example <code>offset</code> or 
keyword <code>trials</code> for binomial and beta-binomial likelihoods.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var</code></td>
<td>
<p>Whether to compute the predictive variances along with predictive mean.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quantiles</code></td>
<td>
<p>Vector of probabilities between 0 and 1 indicating which quantiles are to
be predicted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quad_order</code></td>
<td>
<p>Quadrature order in order to compute the mean and variance on
the transformed scale.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>gp_pred</code> returns a list with fields giving the predictive mean, variance and
quantiles (the last two are computed only if requested). <code>gp_draw</code> returns an N-by-draws
matrix of random draws from the predictive distribution, where N is the number of test points.
</p>


<h3>References</h3>

<p>Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning. MIT Press.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Generate some toy data
set.seed(1242)
n &lt;- 50
x &lt;- matrix(rnorm(n * 3), nrow = n)
f &lt;- sin(x[, 1]) + 0.5 * x[, 2]^2 + x[, 3]
y &lt;- f + 0.5 * rnorm(n)
x &lt;- data.frame(x1 = x[, 1], x2 = x[, 2], x3 = x[, 3])

# More than one covariance function; one for x1 and x2, and another one for x3
cf1 &lt;- cf_nn(c("x1", "x2"), prior_sigma0 = prior_half_t(df = 4, scale = 2))
cf2 &lt;- cf_sexp("x3")
cfs &lt;- list(cf1, cf2)
lik &lt;- lik_gaussian()
gp &lt;- gp_init(cfs, lik)
gp &lt;- gp_optim(gp, x, y, maxiter = 500)

# plot the predictions with respect to x1, when x2 = x3 = 0
xt &lt;- cbind(x1 = seq(-3, 3, len = 50), x2 = 0, x3 = 0)
pred &lt;- gp_pred(gp, xt)
plot(xt[, "x1"], pred$mean, type = "l")

# draw from the predictive distribution
xt &lt;- cbind(x1 = seq(-3, 3, len = 50), x2 = 0, x3 = 0)
draws &lt;- gp_draw(gp, xt, draws = 100)
plot(xt[, "x1"], draws[, 1], type = "l")
for (i in 2:50) {
  lines(xt[, "x1"], draws[, i])
}

# plot effect with respect to x3 only
xt &lt;- cbind("x3" = seq(-3, 3, len = 50))
pred &lt;- gp_pred(gp, xt, cfind = 2)
plot(xt, pred$mean, type = "l")


</code></pre>


</div>