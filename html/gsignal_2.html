<div class="container">

<table style="width: 100%;"><tr>
<td>arburg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Autoregressive model coefficients - Burg's method</h2>

<h3>Description</h3>

<p>Calculate the coefficients of an autoregressive model using the whitening
lattice-filter method of Burg (1968)[1].
</p>


<h3>Usage</h3>

<pre><code class="language-R">arburg(x, p, criterion = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>input data, specified as a numeric or complex vector or matrix. In
case of a vector it represents a single signal; in case of a matrix each
column is a signal.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>model order; number of poles in the AR model or limit to the number
of poles if a valid criterion is provided. Must be &lt; length(x) - 2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>criterion</code></td>
<td>
<p>model-selection criterion. Limits the number of poles so
that spurious poles are not added when the whitened data has no more
information in it. Recognized values are:
</p>

<dl>
<dt>AKICc</dt>
<dd>
<p>approximate corrected Kullback information criterion
(recommended)</p>
</dd>
<dt>KIC</dt>
<dd>
<p>Kullback information criterion</p>
</dd>
<dt>AICc</dt>
<dd>
<p>corrected Akaike information criterion</p>
</dd>
<dt>AIC</dt>
<dd>
<p>Akaike information criterion</p>
</dd>
<dt>FPE</dt>
<dd>
<p>final prediction error</p>
</dd>
</dl>
<p>The default is to NOT use a model-selection criterion (NULL)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The inverse of the autoregressive model is a moving-average filter which
reduces <code>x</code> to white noise. The power spectrum of the AR model is an
estimate of the maximum entropy power spectrum of the data. The function
<code>ar_psd</code> calculates the power spectrum of the AR model.
</p>
<p>For data input <code>x(n)</code> and white noise <code>e(n)</code>, the autoregressive
model is

</p>
<pre>
                          p+1
    x(n) = sqrt(v).e(n) + SUM a(k).x(n-k)
                          k=1
 </pre>
<p><code>arburg</code> does not remove the mean from the data. You should remove the
mean from the data if you want a power spectrum. A non-zero mean can produce
large errors in a power-spectrum estimate.  See <code>detrend</code>
</p>


<h3>Value</h3>

<p>A <code>list</code> containing the following elements:
</p>

<dl>
<dt>a</dt>
<dd>
<p>vector or matrix containing <code>(p+1)</code> autoregression
coefficients. If <code>x</code> is a matrix, then each row of a corresponds to
a column of <code>x</code>. <code>a</code> has <code>p + 1</code> columns.</p>
</dd>
<dt>e</dt>
<dd>
<p>white noise input variance, returned as a vector. If <code>x</code> is
a matrix, then each element of e corresponds to a column of <code>x</code>.</p>
</dd>
<dt>k</dt>
<dd>
<p>Reflection coefficients defining the lattice-filter embodiment
of the model returned as vector or a matrix. If <code>x</code> is a matrix,
then each column of <code>k</code> corresponds to a column of <code>x</code>.
<code>k</code> has <code>p</code> rows.</p>
</dd>
</dl>
<h3>Note</h3>

<p>AIC, AICc, KIC and AKICc are based on information theory. They  attempt
to balance the complexity (or length) of the model against how well the
model fits the data.  AIC and KIC are biased estimates of the asymmetric
and the symmetric Kullback-Leibler divergence, respectively. AICc and AKICc
attempt to correct the bias. See reference [2].
</p>


<h3>Author(s)</h3>

<p>Peter V. Lanspeary, <a href="mailto:pvl@mecheng.adelaide.edu.au">pvl@mecheng.adelaide.edu.au</a>.<br>
Conversion to R by Geert van Boxtel, <a href="mailto:gjmvanboxtel@gmail.com">gjmvanboxtel@gmail.com</a>.
</p>


<h3>References</h3>

<p>[1] Burg, J.P. (1968) A new analysis technique for time series
data, NATO advanced study Institute on Signal Processing with Emphasis on
Underwater Acoustics, Enschede, Netherlands, Aug. 12-23, 1968.<br>
[2] Seghouane, A. and Bekara, M. (2004). A small sample model selection
criterion based on Kullbackâ€™s symmetric divergence. IEEE Trans. Sign.
Proc., 52(12), pp 3314-3323,
</p>


<h3>See Also</h3>

<p><code>ar_psd</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">A &lt;- Arma(1, c(1, -2.7607, 3.8106, -2.6535, 0.9238))
y &lt;- filter(A, 0.2 * rnorm(1024))
coefs &lt;- arburg(y, 4)

</code></pre>


</div>