<div class="container">

<table style="width: 100%;"><tr>
<td>WeakRankNorm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Weak ranking family (normalized)</h2>

<h3>Description</h3>

<p>Gradient-free Gradient Boosting family for the normalized weak ranking loss function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">WeakRankNorm(K)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>Indicates that we are only interesting in the top <code class="reqn">K</code> instances. Must be an integer between 1 and the number
<code class="reqn">n</code> of observations.</p>
</td>
</tr></table>
<h3>Details</h3>

<p>A more intuitive loss function than the weak ranking loss thanks to its normalization to a maximum value
of 1. For example, if a number <code class="reqn">c</code> of the top <code class="reqn">K</code> instances has not been ranked at the top of the list, the
normalized weak ranking loss is <code class="reqn">C/K</code>. <code>WeakRankNorm</code> returns a family object as in the package <code>mboost</code>.
</p>


<h3>Value</h3>

<p>A Boosting family object
</p>


<h3>References</h3>

<p>Werner, T., Gradient-Free Gradient Boosting, PhD Thesis, Carl von Ossietzky University Oldenburg, 2020,
Remark (5.2.4)
</p>
<p>T. Hothorn, P. BÃ¼hlmann, T. Kneib, M. Schmid, and B. Hofner. mboost: Model-Based
Boosting, 2017
</p>


</div>