<div class="container">

<table style="width: 100%;"><tr>
<td>grafzahl</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fine tune a pretrained Transformer model for texts</h2>

<h3>Description</h3>

<p>Fine tune (or train) a pretrained Transformer model for your given training labelled data <code>x</code> and <code>y</code>. The prediction task can be classification (if <code>regression</code> is <code>FALSE</code>, default) or regression (if <code>regression</code> is <code>TRUE</code>).
</p>


<h3>Usage</h3>

<pre><code class="language-R">grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

## Default S3 method:
grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

## S3 method for class 'corpus'
grafzahl(
  x,
  y = NULL,
  model_name = "xlm-roberta-base",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)

textmodel_transformer(...)

## S3 method for class 'character'
grafzahl(
  x,
  y = NULL,
  model_name = "xlmroberta",
  regression = FALSE,
  output_dir,
  cuda = detect_cuda(),
  num_train_epochs = 4,
  train_size = 0.8,
  args = NULL,
  cleanup = TRUE,
  model_type = NULL,
  manual_seed = floor(runif(1, min = 1, max = 721831)),
  verbose = TRUE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>the corpus or character vector of texts on which the model will be trained. Depending on <code>train_size</code>, some texts will be used for cross-validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>training labels. It can either be a single string indicating which docvars of the corpus is the training labels; a vector of training labels in either character or factor; or <code>NULL</code> if the corpus contains exactly one column in docvars and that column is the training labels. If <code>x</code> is a character vector, <code>y</code> must be a vector of the same length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_name</code></td>
<td>
<p>string indicates either 1) the model name on Hugging Face website; 2) the local path of the model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regression</code></td>
<td>
<p>logical, if <code>TRUE</code>, the task is regression, classification otherwise.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_dir</code></td>
<td>
<p>string, location of the output model. If missing, the model will be stored in a temporary directory. Important: Please note that if this directory exists, it will be overwritten.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cuda</code></td>
<td>
<p>logical, whether to use CUDA, default to <code>detect_cuda()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_train_epochs</code></td>
<td>
<p>numeric, if <code>train_size</code> is not exactly 1.0, the maximum number of epochs to try in the "early stop" regime will be this number times 5 (i.e. 4 * 5 = 20 by default). If <code>train_size</code> is exactly 1.0, the number of epochs is exactly that.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_size</code></td>
<td>
<p>numeric, proportion of data in <code>x</code> and <code>y</code> to be used actually for training. The rest will be used for cross validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>args</code></td>
<td>
<p>list, additionally parameters to be used in the underlying simple transformers</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cleanup</code></td>
<td>
<p>logical, if <code>TRUE</code>, the <code>runs</code> directory generated will be removed when the training is done</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_type</code></td>
<td>
<p>a string indicating model_type of the input model. If <code>NULL</code>, it will be inferred from <code>model_name</code>. Supported model types are available in supported_model_types.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>manual_seed</code></td>
<td>
<p>numeric, random seed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical, if <code>TRUE</code>, debug messages will be displayed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>paramters pass to <code>grafzahl()</code></p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a <code>grafzahl</code> S3 object with the following items
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>original function call</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>input_data</code></td>
<td>
<p>input_data for the underlying python function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output_dir</code></td>
<td>
<p>location of the output model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_type</code></td>
<td>
<p>model type</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_name</code></td>
<td>
<p>model name</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>regression</code></td>
<td>
<p>whether or not it is a regression model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>levels</code></td>
<td>
<p>factor levels of y</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>manual_seed</code></td>
<td>
<p>random seed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>meta</code></td>
<td>
<p>metadata about the current session</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>predict.grafzahl()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">if (detect_conda() &amp;&amp; interactive()) {
library(quanteda)
set.seed(20190721)
## Using the default cross validation method
model1 &lt;- grafzahl(unciviltweets, model_type = "bertweet", model_name = "vinai/bertweet-base")
predict(model1)

## Using LIME
input &lt;- corpus(ecosent, text_field = "headline")
training_corpus &lt;- corpus_subset(input, !gold)
model2 &lt;- grafzahl(x = training_corpus,
                 y = "value",
                 model_name = "GroNLP/bert-base-dutch-cased")
test_corpus &lt;- corpus_subset(input, gold)
predicted_sentiment &lt;- predict(model2, test_corpus)
require(lime)
sentences &lt;- c("Dijsselbloem pessimistisch over snelle stappen Grieken",
               "Aandelenbeurzen zetten koersopmars voort")
explainer &lt;- lime(training_corpus, model2)
explanations &lt;- explain(sentences, explainer, n_labels = 1,
                        n_features = 2)
plot_text_explanations(explanations)
}
</code></pre>


</div>