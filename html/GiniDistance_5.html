<div class="container">

<table style="width: 100%;"><tr>
<td>dCov</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Distance Covariance Statistic</h2>

<h3>Description</h3>

<p>Computes distance covariance statistic,
in which Xs are quantitative and Y are categorical and return the measures of dependence.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  dCov(x, y, alpha)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> data </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> label of data or response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p> exponent on Euclidean distance, in (0,2]</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>dCov</code> calls <code>dcov</code> function from energy package to compute distance covariance statistic.
The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Arguments
<code>x</code>, <code>y</code> are treated as data and labels.
</p>
<p>The distance covariance (<cite>Sezekley07</cite>) is extended from Euclidean space to general metric spaces by Lyons (2013). Based on that idea, we define the discrete metric   
</p>
<p style="text-align: center;"><code class="reqn">d(y, y^\prime) =|y-y^\prime|:=  I(y\neq y^\prime),</code>
</p>

<p>where <code class="reqn">I (\cdot)</code> is the indicator function. Equipped with this set difference metric on the support of <code class="reqn">Y</code> and Euclidean 
distance on the support of <code class="reqn">\mathbf{X}</code>, the corresponding distance covariance and distance correlation for numerical <code class="reqn">\mathbf{X}</code> and categorical <code class="reqn">Y</code> variables are as follows. 
</p>
<p>Let <code class="reqn">A=(a_{ij})</code> be a symmetric, <code class="reqn">n \times n</code>, centered distance matrix of sample <code class="reqn">\bf x_1,\cdots, \bf x_n</code>. The <code class="reqn">(i,j)</code>-th entry of <code class="reqn">A</code> is <code class="reqn">a_{ij}-\frac{1}{n-2}a_{i\cdot}-\frac{1}{n-2}a_{\cdot j} + \frac{1}{(n-1)(n-2)}a_{\cdot \cdot}</code> if <code class="reqn">i \neq j</code> and 0 if <code class="reqn">i=j</code>,
where <code class="reqn">a_{ij} = \|\bf x_i-\bf x_j\|^{\alpha}</code>, <code class="reqn">a_{i\cdot} = \sum_{j=1}^n a_{ij}</code>, <code class="reqn">a_{\cdot j} = \sum_{i=1}^n a_{ij}</code>, and <code class="reqn">a_{\cdot \cdot}=\sum_{i,j=1}^n a_{ij}</code>. Similarly, using the set difference metric, a symmetric, <code class="reqn">n \times n</code>, centered distance matrix is calculated for samples <code class="reqn">y_1,\cdots, y_n</code> and denoted by <code class="reqn">B = (b_{ij})</code>. Unbiased estimators of <code class="reqn">\mbox{dCov}(\bf X,Y;\alpha)</code> is   
</p>
<p><code class="reqn">\frac{1}{n(n-3)}\sum_{i\ne j}A_{ij}B_{ij}</code>.
</p>


<h3>Value</h3>

<p><code>dCov</code> returns the sample distance covariance between data <code>x</code> and label <code>y</code>. 
</p>


<h3>References</h3>

<p>Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability, 41 (5), 3284-3305. 
</p>
<p>Rizzo, M.L. and Szekely, G.J., (2017). Energy: E-Statistics: Multivariate Inference via the Energy of Data (R Package), Version 1.7-0.
</p>
<p>Szekely, G. J., Rizzo, M. L. and Bakirov, N. (2007). Measuring and testing dependence by correlation of distances. Annals of Statistics, 35 (6), 2769-2794.
</p>


<h3>See Also</h3>

<p><code>dCor</code> <code>KdCov</code>  <code>KdCor</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">  x &lt;- iris[,1:4]
  y &lt;- unclass(iris[,5])
  dCov(x, y, alpha = 1)
</code></pre>


</div>