<div class="container">

<table style="width: 100%;"><tr>
<td>visualize.shrink</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Plots grpnet Shrinkage Operator or its Estimator
</h2>

<h3>Description</h3>

<p>Makes a plot or returns a data frame containing the group elastic net shrinkage operator (or its estimator) evaluated at a sequence of input values.
</p>


<h3>Usage</h3>

<pre><code class="language-R">visualize.shrink(x = seq(-5, 5, length.out = 1001), 
                penalty = c("LASSO", "MCP", "SCAD"), 
                alpha = 1, 
                lambda = 1, 
                gamma = 4, 
                fitted = FALSE,
                plot = TRUE,
                subtitle = TRUE,
                legend = TRUE,
                location = "top",
                ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>sequence of values at which to evaluate the penalty.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>

<p>which penalty or penalties should be plotted?  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>

<p>elastic net tuning parameter (between 0 and 1).  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>overall tuning parameter (non-negative).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>

<p>additional hyperparameter for MCP (&gt;1) or SCAD (&gt;2).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted</code></td>
<td>

<p>if <code>FALSE</code> (default), then the shrinkage operator is plotted; otherwise the shrunken estimator is plotted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plot</code></td>
<td>

<p>if <code>TRUE</code> (default), then the result is plotted; otherwise the result is returned as a data frame.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subtitle</code></td>
<td>

<p>if <code>TRUE</code> (default), then the hyperparameter values are displayed in the subtitle. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>legend</code></td>
<td>

<p>if <code>TRUE</code> (default), then a legend is included to distinguish the different <code>penalty</code> types.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>location</code></td>
<td>

<p>the legend's location; ignored if <code>legend = FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>

<p>addition arguments passed to <code>plot</code> function, e.g., <code>xlim</code>, <code>ylim</code>, etc.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The updates for the group elastic net estimator have the form
</p>
<p style="text-align: center;"><code class="reqn">\boldsymbol\beta_{\alpha, \lambda}^{(t+1)} = S_{\lambda_1, \lambda_2}(\|\mathbf{b}_{\alpha, \lambda}^{(t+1)}\|) \mathbf{b}_{\alpha, \lambda}^{(t+1)}</code>
</p>

<p>where <code class="reqn">S_{\lambda_1, \lambda_2}(\cdot)</code> is a shrinkage and selection operator, and 
</p>
<p style="text-align: center;"><code class="reqn">\mathbf{b}_{\alpha, \lambda}^{(t+1)} = \boldsymbol\beta_{\alpha, \lambda}^{(t)} + (\delta_{(t)} \epsilon)^{-1} \mathbf{g}^{(t)}</code>
</p>

<p>is the unpenalized update with <code class="reqn">\mathbf{g}^{(t)}</code> denoting the current gradient.
</p>
<p>Note that <code class="reqn">\lambda_1 = \lambda \alpha</code> is the L1 tuning parameter, <code class="reqn">\lambda_2 = \lambda (1-\alpha)</code> is the L2 tuning parameter, <code class="reqn">\delta_{(t)}</code> is an upper-bound on the weights appearing in the Fisher information matrix, and <code class="reqn">\epsilon</code> is the largest eigenvalue of the Gramm matrix <code class="reqn">n^{-1} \mathbf{X}^\top \mathbf{X}</code>. 
</p>


<h3>Value</h3>

<p>If <code>plot = TRUE</code>, then produces a plot.
</p>
<p>If <code>plot = FALSE</code>, then returns a data frame.
</p>


<h3>Author(s)</h3>

<p>Nathaniel E. Helwig &lt;helwig@umn.edu&gt;
</p>


<h3>References</h3>

<p>Fan J, &amp; Li, R. (2001). Variable selection via nonconcave penalized likelihood and its oracle properties. <em>Journal of the American Statistical Association, 96</em>(456), 1348-1360. <a href="https://doi.org/10.1198/016214501753382273">doi:10.1198/016214501753382273</a>
</p>
<p>Helwig, N. E. (2024). Versatile descent algorithms for group regularization and variable selection in generalized linear models. <em>Journal of Computational and Graphical Statistics</em>. <a href="https://doi.org/10.1080/10618600.2024.2362232">doi:10.1080/10618600.2024.2362232</a>
</p>
<p>Tibshirani, R. (1996). Regression and shrinkage via the Lasso. <em>Journal of the Royal Statistical Society, Series B, 58</em>, 267-288. <a href="https://doi.org/10.1111/j.2517-6161.1996.tb02080.x">doi:10.1111/j.2517-6161.1996.tb02080.x</a>
</p>
<p>Zhang CH (2010). Nearly unbiased variable selection under minimax concave penalty. <em>The Annals of Statistics, 38</em>(2), 894-942. <a href="https://doi.org/10.1214/09-AOS729">doi:10.1214/09-AOS729</a>
</p>


<h3>See Also</h3>

<p><code>visualize.penalty</code> for plotting penalty function
</p>


<h3>Examples</h3>

<pre><code class="language-R"># plot shrinkage operator
visualize.shrink()

# plot shrunken estimator
visualize.shrink(fitted = TRUE)
</code></pre>


</div>