<div class="container">

<table style="width: 100%;"><tr>
<td>CompoundAuxFit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fitting the Compound Distribution based on the GB2 by the Method of Pseudo Maximum Likelihood Estimation using Auxiliary Information
</h2>

<h3>Description</h3>

<p>Calculates the log-likelihood, the score functions of the log-likelihood and fits the compound distribution based on the GB2 and using auxiliary information.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pkl.cavgb2(z, lambda)
lambda0.cavgb2(pl0, z, w=rep(1, dim(z)[1]))
logl.cavgb2(fac, z, lambda, w=rep(1, dim(fac)[1]))
scores.cavgb2(fac, z, lambda, w=rep(1, dim(fac)[1]))
ml.cavgb2(fac, z, lambda0, w = rep(1, dim(fac)[1]), maxiter = 100, fnscale=length(w)) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>z</code></td>
<td>
<p>numeric; a matrix of auxiliary variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>numeric; a matrix of parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pl0</code></td>
<td>
<p>numeric; a vector of initial proportions defining the number of components and the weight of each component density in the decomposition. Sums to one.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>numeric; vector of weights of length the number of rows of the matrix <code>fac</code>. By default <code>w</code> is a vector of 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fac</code></td>
<td>
<p>numeric; a matrix of Gamma factors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda0</code></td>
<td>
<p>numeric; a matrix of initial parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>numeric; maximum number of iterations to perform. By default <code>maxiter</code> = 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fnscale</code></td>
<td>
<p>numeric; parameter of the <code>optim</code> function. By default <code>fnscale</code> is equal to the lenth of the vector of weights (value of <code>fnscale</code> in 
the preceding version of the package). Permits to solve some convergence problems (see <code>optim</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>We model the probabilities <code class="reqn">p_\ell</code> with auxiliary variables. Let <code class="reqn">z_k</code> denote the vector of auxiliary information for unit <code class="reqn">k</code>. This auxiliary information modifies the probabilities <code class="reqn">p_\ell</code> at the unit level. Denote by <code class="reqn">p_{k,\ell}</code> the weight of the density <code class="reqn">f_\ell</code> for unit <code class="reqn">k</code>. For <code class="reqn">\ell=1,...,L-1</code>, we pose a linear model for the log-ratio <code class="reqn">v_{k,\ell}</code>:
</p>
<p style="text-align: center;"><code class="reqn">\log(p_{k,\ell}/p_{k,L}) = v_{k,\ell} =\sum_{i=1}^I \lambda_{\ell i} z_{k i}= \mathbf{z}_k^{T} \boldsymbol{\lambda_{\ell}}.</code>
</p>
 
<p>Function <code>pkl.cavgb2</code> calculates the <code class="reqn">p_{k,\ell}</code>. Function <code>lambda0.cavgb2</code> calculates the initial values <code class="reqn">\lambda_{\ell i}</code>, <code class="reqn">i= 1, ..., I</code>, <code class="reqn">\ell = 1, ..., L-1</code> . Let </p>
<p style="text-align: center;"><code class="reqn">\bar{z}_{i}=\sum_k w_k z_{ki}/\sum_k w_k</code>
</p>
<p> be the mean value of the <code class="reqn">i</code>-th explanatory variable. 
Writing </p>
<p style="text-align: center;"><code class="reqn">\log(\hat{p}^{(0)}_\ell / \hat{p}^{(0)}_L)=v^{(0)}_\ell = \sum_{i=1}^I \lambda^{(0)}_{\ell i} \bar{z}_{i},</code>
</p>
<p> we can choose <code class="reqn">\lambda^{(0)}_{\ell i}= v^{(0)}_\ell / (I \bar{z}_{i}).</code> Analogically to the ordinary fit of the compound distribution based on the GB2 <code>CompoundFit</code>, we express the log-likelihood as a weighted mean of <code class="reqn">log(f) = log(\sum(p_{k,\ell} f_\ell(x_k))</code>, evaluated at the data points, where <code class="reqn">f</code> is the GB2 compound density.
The scores are obtained as the weighted sums of the first derivatives of the log-likelihood, with respect to the parameters <code class="reqn">\lambda_\ell, \ \ell=1, ..., L-1</code>, evaluated at the data points. 
Function <code>ml.cavgb2</code> performs maximum likelihood estimation through the general-purpose optimization function <code>optim</code> from package <code>stats</code>. 
The considered method of optimization is "BFGS" (<code>optim</code>). Once we have the fitted parameters <code class="reqn">\hat{\lambda}</code> we can deduce the fitted parameters <code class="reqn">\hat{v{k\ell}}</code> and 
<code class="reqn">\hat{p_{k\ell}}</code> in function of <code class="reqn">\bar{z}</code> and <code class="reqn">\hat{\lambda}_{\ell}</code>.
</p>


<h3>Value</h3>

<p><code>pkl.cavgb2</code> returns a matrix of probabilities. <code>lambda0.cavgb2</code> returns a matrix of size <code class="reqn">I \times L-1</code>. 
<code>logl.cavgb2</code> returns the value of the pseudo log-likelihood. 
<code>scores.cavgb2</code> returns the weighted sum of the scores of the log-likelihood.
<code>ml.cavgb2</code> returns a list containing two objects - the vector of fitted coefficients <code class="reqn">\hat{\lambda_\ell}</code> and the output of the "BFGS" fit.
</p>


<h3>Author(s)</h3>

<p>Monique Graf and Desislava Nedyalkova
</p>


<h3>See Also</h3>

<p><code>optim</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 

library(simFrame)
data(eusilcP)

# Stratified cluster sampling
set.seed(12345)
srss &lt;- SampleControl(design = "region", grouping = "hid", size = c(200*3, 1095*3, 1390*3,
 425*3, 820*3, 990*3, 400*3, 450*3, 230*3), k = 1)

# Draw a sample
s1 &lt;- draw(eusilcP,srss)
#names(s1)

# Creation of auxiliary variables
ind &lt;- order(s1[["hid"]])
ss1 &lt;- data.frame(hid=s1[["hid"]], region=s1[["region"]], hsize=s1[["hsize"]], 
peqInc=s1[["eqIncome"]], age=s1[["age"]], pw=s1[[".weight"]])[ind,]
ss1[["child"]] &lt;- as.numeric((ss1[["age"]]&lt;=14))
ss1[["adult"]] &lt;- as.numeric((ss1[["age"]]&gt;=20))
sa &lt;- aggregate(ss1[,c("child","adult")],list(ss1[["hid"]]),sum)
names(sa)[1] &lt;- "hid"
sa[["children"]] &lt;- as.numeric((sa[["child"]]&gt;0))
sa[["single_a"]] &lt;- as.numeric((sa[["adult"]]==1))
sa[["sa.ch"]] &lt;- sa[["single_a"]]*sa[["children"]]
sa[["ma.ch"]] &lt;- (1-sa[["single_a"]])*sa[["children"]]
sa[["nochild"]] &lt;- 1-sa[["children"]]

# New data set
ns &lt;- merge(ss1[,c("hid","region","hsize","peqInc","pw")], 
sa[,c("hid","nochild","sa.ch","ma.ch")], by="hid")

# Ordering the data set
ns &lt;- ns[!is.na(ns$peqInc),]
index &lt;- order(ns$peqInc)
ns &lt;- ns[index,]

# 	Truncate at 0
ns &lt;- ns[ns$peqInc&gt;0,]
# income
peqInc &lt;- ns$peqInc
# weights
pw &lt;- ns$pw             

# Adding the weight adjustment
c1 &lt;- 0.1                                
pwa &lt;- robwts(peqInc,pw,c1,0.001)[[1]]        
corr &lt;- mean(pw)/mean(pwa)              
pwa &lt;- pwa*corr  

ns &lt;- data.frame(ns, aw=pwa) 

# Empirical indicators with original weights
emp.ind &lt;- c(main.emp(peqInc, pw),
              main.emp(peqInc[ns[["nochild"]]==1], pw[ns[["nochild"]]==1]),
              main.emp(peqInc[ns[["sa.ch"]]==1], pw[ns[["sa.ch"]]==1]),
              main.emp(peqInc[ns[["ma.ch"]]==1], pw[ns[["ma.ch"]]==1]))

# Matrix of auxiliary variables
z &lt;- ns[,c("nochild","sa.ch","ma.ch")]
#unique(z)
z &lt;- as.matrix(z)

# global GB2 fit, ML profile log-likelihood
gl.fit &lt;- profml.gb2(peqInc,pwa)$opt1
agl.fit &lt;- gl.fit$par[1]
bgl.fit &lt;- gl.fit$par[2]
pgl.fit &lt;- prof.gb2(peqInc,agl.fit,bgl.fit,pwa)[3]
qgl.fit &lt;- prof.gb2(peqInc,agl.fit,bgl.fit,pwa)[4]

# Likelihood and convergence
proflikgl &lt;- -gl.fit$value
convgl &lt;- gl.fit$convergence

# Fitted GB2 parameters and indicators
profgb2.par &lt;- c(agl.fit, bgl.fit, pgl.fit, qgl.fit)
profgb2.ind &lt;- main.gb2(0.6, agl.fit, bgl.fit, pgl.fit, qgl.fit)

# Initial lambda and pl
pl0 &lt;- c(0.2,0.6,0.2)
lambda0 &lt;- lambda0.cavgb2(pl0, z, pwa)

# left decomposition
decomp &lt;- "l"
facgl &lt;- fg.cgb2(peqInc, agl.fit, bgl.fit, pgl.fit, qgl.fit, pl0 ,decomp)
fitcml &lt;- ml.cavgb2(facgl, z, lambda0, pwa, maxiter=500) 
fitcml
convcl &lt;- fitcml[[2]]$convergence
convcl
lambdafitl &lt;- fitcml[[1]]
pglfitl &lt;-  pkl.cavgb2(diag(rep(1,3),lambdafitl)
row.names(pglfitl) &lt;- colnames(z)

## End(Not run)
</code></pre>


</div>