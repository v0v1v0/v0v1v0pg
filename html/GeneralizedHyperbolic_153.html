<div class="container">

<table style="width: 100%;"><tr>
<td>summary.hyperblm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Summary Output of Hyperbolic Regression</h2>

<h3>Description</h3>

<p>It obtains summary output from class 'hyperblm' object. The summary
output incldes the standard error, t-statistics, p values of the
coefficients estimates. Also the estimated parameters of hyperbolic
error distribution, the maximum likelihood, the stage one optimization
method, the two-stage alternating iterations and the convergence code.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'hyperblm'
summary(object, hessian = FALSE,
                           nboots = 1000, ...)

## S3 method for class 'summary.hyperblm'
print(x,
                                 digits = max(3, getOption("digits") - 3), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>An object of class <code>"hyperblm"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An object of class <code>"summary.hyperblm"</code> resulting from a
call to <code>summary.hyperblm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian</code></td>
<td>
<p>Logical. If is <code>TRUE</code>, the standard error is
calculated by the hessian matrix and the also hessian matrix is
returned. Otherwise, the standard error is approximated by
bootstrapping. See <b>Details</b>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nboots</code></td>
<td>
<p>Numeric. Number of bootstrap simulations to obtain the
bootstrap estimate of parameters standard errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Numeric. Desired number of digits when the object is
printed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Passes additional arguments to functions <code>bSE</code>,
<code>hyperblmhessian</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function <code>summary.hyperblm</code> provides two approaches to obtain
the standard error of parameters due to the fact that approximated
hessian matrix is not stable for such complex optimization. The first
approach is by approximated hessian matrix. The setting in the
argument list is <code>hessian = TRUE</code>. The Hessian matrix is
approximated by function <code>tsHessian</code>. However it may not
be reliable for some error distribution parameters, for instance, the
function obtains negative variance from the Hessian matrix. The second
approach is by parametric bootstrapping. The setting in the argument
list is <code>hessian = FALSE</code> which is also the default setting. The
default number of bootstrap stimulations is 1000, but users can
increase this when accuracy has priority over efficiency. Although the
bootstrapping is fairly slow, it provides reliable standard errors.
</p>


<h3>Value</h3>

<p><code>summary.hyperblm</code> returns an object of class
<code>summary.hyperblm</code> which is a list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>A names vector of regression coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distributionParams</code></td>
<td>
<p>A named vector of fitted hyperbolic error
distribution parameters.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>The fitted mean values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>The remaining after subtract fitted values from
response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MLE</code></td>
<td>
<p>The maximum likelihood value of the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>The optimization method for stage one.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paramStart</code></td>
<td>
<p>The start values of parameters that the user specified
(only where relevant).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residsParamStart</code></td>
<td>
<p>The start values of parameters returned by
<code>hyperbFitStand</code> (only where relevant).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The matched call.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>terms</code></td>
<td>
<p>The <code>terms</code> object used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>contrasts</code></td>
<td>
<p>The contrasts used (only where relevant).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xlevels</code></td>
<td>
<p>The levels of the factors used in the fitting (only where
relevant).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offset</code></td>
<td>
<p>The offset used (only where relevant).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xNames</code></td>
<td>
<p>The names of each explanatory variables. If explanatory
variables don't have names then they shall be named <code>x</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>yVec</code></td>
<td>
<p>The response vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xMatrix</code></td>
<td>
<p>The explanatory variables matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iterations</code></td>
<td>
<p>Number of two-stage alternating iterations to
convergency.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convergence</code></td>
<td>
<p>The convergence code for two-stage optimization: 0
if the system converged; 1 if first stage did not converge, 2 if the
second stage did not converge, 3 if the both stages did not converge.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>breaks</code></td>
<td>
<p>The cell boundaries found by a call the
<code>hist</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>hessian</code></td>
<td>
<p>Hessian Matrix. Only where <code>Hessian = TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tval</code></td>
<td>
<p><em>t</em>-statistics of regression coefficient estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rdf</code></td>
<td>
<p>Degrees of freedom.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pval</code></td>
<td>
<p>P-values of regression coefficients estimates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sds</code></td>
<td>
<p>Standard errors of regression coefficient estimates.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>David Scott <a href="mailto:d.scott@auckland.ac.nz">d.scott@auckland.ac.nz</a>,
Xinxing Li <a href="mailto:xli053@aucklanduni.ac.nz">xli053@aucklanduni.ac.nz</a>
</p>


<h3>References</h3>

<p>Barndorff-Nielsen, O. (1977). Exponentially Decreasing Distribution
for the Logarithm of Particle Size.
In <em>Proceedings of the Royal Society of London. Series A,
Mathematical and Physical Sciences</em>, Vol. 353, pp. 401â€“419.
</p>
<p>Prause, K. (1999). <em>The generalized hyperbolic models:
Estimation, financial derivatives and risk measurement</em>.
PhD Thesis, Mathematics Faculty, University of Freiburg.
</p>
<p>Trendall, Richard (2005). <em>hypReg: A Function for Fitting a
Linear Regression Model in R with Hyperbolic Error</em>.
Masters Thesis, Statistics Faculty, University of Auckland.
</p>
<p>Paolella, Marc S. (2007). <em>Intermediate Probability: A
Compitational Approach</em>.
pp. 415 -Chichester: Wiley.
</p>
<p>Scott, David J. and Wurtz, Diethelm and Chalabi, Yohan,
(2011). <em>Fitting the Hyperbolic Distribution with R: A Case Study
of Optimization Techniques</em>.
In preparation.
</p>
<p>Stryhn, H. and Christensen, J. (2003). <em>Confidence intervals by
the profile likelihood method, with applications in veterinary
epidemiology</em>. ISVEE X.
</p>


<h3>See Also</h3>

<p><code>print.summary.hyperblm</code> prints the summary output in a
table.
<code>hyperblm</code> fits linear model with hyperbolic
error distribution.
<code>print.hyperblm</code> prints the regression result in a table.
<code>coef.hyperblm</code> obtains the regression coefficients and
error distribution parameters of the fitted model.
<code>plot.hyperblm</code> obtains a residual vs fitted value plot, a
histgram of residuals with error distribution density curve on top, a
histgram of log residuals with error distribution error density curve
on top and a QQ plot.
<code>tsHessian</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## stackloss data example

# airflow &lt;- stackloss[, 1]
# temperature &lt;- stackloss[, 2]
# acid &lt;- stackloss[, 3]
# stack &lt;- stackloss[, 4]

# hyperblm.fit &lt;- hyperblm(stack ~ airflow + temperature + acid,
#                          tolerance = 1e-11)

# coef.hyperblm(hyperblm.fit)
# plot.hyperblm(hyperblm.fit, breaks = 20)
# summary.hyperblm(hyperblm.fit, hessian = FALSE)

</code></pre>


</div>