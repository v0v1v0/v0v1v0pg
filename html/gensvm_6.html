<div class="container">

<table style="width: 100%;"><tr>
<td>gensvm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit the GenSVM model</h2>

<h3>Description</h3>

<p>Fits the Generalized Multiclass Support Vector Machine model
with the given parameters. See the package documentation
(<code>gensvm-package</code>) for more general information about GenSVM.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gensvm(
  x,
  y,
  p = 1,
  lambda = 1e-08,
  kappa = 0,
  epsilon = 1e-06,
  weights = "unit",
  kernel = "linear",
  gamma = "auto",
  coef = 1,
  degree = 2,
  kernel.eigen.cutoff = 1e-08,
  verbose = FALSE,
  random.seed = NULL,
  max.iter = 1e+08,
  seed.V = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>data matrix with the predictors. <br><br>
Note that for SVMs categorical features should be converted to binary dummy
features. This can be done with using the <code>model.matrix</code>
function (i.e. <code>model.matrix( ~ var - 1)</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>class labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>parameter for the L_p norm of the loss function (1.0 &lt;= p &lt;= 2.0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>regularization parameter for the loss function (lambda &gt; 0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p>parameter for the hinge function in the loss function (kappa &gt;
-1.0)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>Stopping parameter for the optimization algorithm. The 
optimization will stop if the relative change in the loss function is below 
this value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>type or vector of instance weights to use. Options are 'unit'
for unit weights and 'group' for group size correction weights (eq. 4 in the
paper). Alternatively, a vector of weights can be provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>the kernel type to use in the classifier. It must be one of
'linear', 'poly', 'rbf', or 'sigmoid'. See the section "Kernels in GenSVM"
in <code>gensvm-package</code> for more info.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>kernel parameter for the rbf, polynomial, and sigmoid kernel.
If gamma is 'auto', then 1/n_features will be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>parameter for the polynomial and sigmoid kernel.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degree</code></td>
<td>
<p>parameter for the polynomial kernel</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel.eigen.cutoff</code></td>
<td>
<p>Cutoff point for the reduced eigendecomposition
used with kernel-GenSVM. Eigenvectors for which the ratio between their
corresponding eigenvalue and the largest eigenvalue is smaller than this
cutoff value will be dropped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Turn on verbose output and fit progress</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random.seed</code></td>
<td>
<p>Seed for the random number generator (useful for
reproducible output)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>Maximum number of iterations of the optimization algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed.V</code></td>
<td>
<p>Matrix to warm-start the optimization algorithm. This is
typically the output of <code>coef(fit)</code>. Note that this function will
silently drop seed.V if the dimensions don't match the provided data.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A "gensvm" S3 object is returned for which the print, predict, coef,
and plot methods are available. It has the following items:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>The call that was used to construct the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>The value of the lp norm in the loss function</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The regularization parameter used in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kappa</code></td>
<td>
<p>The hinge function parameter used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p>The stopping criterion used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>The instance weights type used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel</code></td>
<td>
<p>The kernel function used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gamma</code></td>
<td>
<p>The value of the gamma parameter of the kernel, if applicable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef</code></td>
<td>
<p>The value of the coef parameter of the kernel, if applicable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>degree</code></td>
<td>
<p>The degree of the kernel, if applicable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kernel.eigen.cutoff</code></td>
<td>
<p>The cutoff value of the reduced
eigendecomposition of the kernel matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Whether or not the model was fitted with progress output</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random.seed</code></td>
<td>
<p>The random seed used to seed the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>Maximum number of iterations of the algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.objects</code></td>
<td>
<p>Number of objects in the dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.features</code></td>
<td>
<p>Number of features in the dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.classes</code></td>
<td>
<p>Number of classes in the dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>classes</code></td>
<td>
<p>Array with the actual class labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V</code></td>
<td>
<p>Coefficient matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.iter</code></td>
<td>
<p>Number of iterations performed in training</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.support</code></td>
<td>
<p>Number of support vectors in the final model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>training.time</code></td>
<td>
<p>Total training time</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>This function returns partial results when the computation is interrupted by
the user.
</p>


<h3>Author(s)</h3>

<p>Gerrit J.J. van den Burg, Patrick J.F. Groenen <br>
Maintainer: Gerrit J.J. van den Burg &lt;gertjanvandenburg@gmail.com&gt;
</p>


<h3>References</h3>

<p>Van den Burg, G.J.J. and Groenen, P.J.F. (2016). <em>GenSVM: A Generalized
Multiclass Support Vector Machine</em>, Journal of Machine Learning Research,
17(225):1â€“42. URL <a href="https://jmlr.org/papers/v17/14-526.html">https://jmlr.org/papers/v17/14-526.html</a>.
</p>


<h3>See Also</h3>

<p><code>coef</code>, <code>print</code>, <code>predict</code>,
<code>plot</code>, <code>gensvm.grid</code>, <code>gensvm-package</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- iris[, -5]
y &lt;- iris[, 5]

# fit using the default parameters and show progress
fit &lt;- gensvm(x, y, verbose=TRUE)

# fit with some changed parameters
fit &lt;- gensvm(x, y, lambda=1e-6)

# Early stopping defined through epsilon
fit &lt;- gensvm(x, y, epsilon=1e-3)

# Early stopping defined through max.iter
fit &lt;- gensvm(x, y, max.iter=1000)

# Nonlinear training
fit &lt;- gensvm(x, y, kernel='rbf', max.iter=1000)
fit &lt;- gensvm(x, y, kernel='poly', degree=2, gamma=1.0, max.iter=1000)

# Setting the random seed and comparing results
fit &lt;- gensvm(x, y, random.seed=123, max.iter=1000)
fit2 &lt;- gensvm(x, y, random.seed=123, max.iter=1000)
all.equal(coef(fit), coef(fit2))


</code></pre>


</div>