<div class="container">

<table style="width: 100%;"><tr>
<td>gmcmtx0</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Matrix R* of generalized correlation coefficients captures nonlinearities.</h2>

<h3>Description</h3>

<p>This function checks for missing data for each pair individually. It then uses the
<code>kern</code> function to kernel regress x on y, and conversely y on x. It
needs the R package ‘np’, which reports the R-squares of each regression. 
<code>gmcmtx0()</code> function
reports their square roots after assigning them the observed sign of the Pearson 
correlation coefficient. Its threefold advantages are: (i)
It is asymmetric, yielding causal direction information
by relaxing the assumption of linearity implicit in usual correlation coefficients.
(ii) The r* correlation coefficients are generally larger upon admitting 
arbitrary nonlinearities.  (iii) max(|R*ij|, |R*ji|) measures (nonlinear) 
dependence.
For example, let x=1:20 and y=sin(x). This y has a perfect (100 percent)
nonlinear dependence on x, and yet Pearson correlation coefficient r(xy)
-0.0948372 is near zero, and the 95% confidence interval (-0.516, 0.363)
includes zero, implying that r(xy) is not significantly different from zero.  
This shows a miserable failure of traditional r(x,y) to measure dependence
when nonlinearities are present. 
<code>gmcmtx0(cbind(x,y))</code> will correctly reveal
perfect (nonlinear) dependence with generalized correlation coefficient =-1.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gmcmtx0(mym, nam = colnames(mym))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>mym</code></td>
<td>
<p>A matrix of data on variables in columns</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nam</code></td>
<td>
<p>Column names of the variables in the data matrix</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A non-symmetric R* matrix of generalized correlation coefficients
</p>


<h3>Author(s)</h3>

<p>Prof. H. D. Vinod, Economics Dept., Fordham University, NY
</p>


<h3>References</h3>

<p>Vinod, H. D.'Generalized Correlation and Kernel Causality with 
Applications in Development Economics' in Communications in 
Statistics -Simulation and Computation, 2015, 
<a href="https://doi.org/10.1080/03610918.2015.1122048">doi:10.1080/03610918.2015.1122048</a>
</p>
<p>Vinod, H. D. 'Matrix Algebra Topics in Statistics and Economics
Using R', Chapter 4 in 'Handbook of Statistics: Computational Statistics
with R', Vol.32, co-editors: M. B. Rao and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2014, pp. 143-176.
</p>
<p>Vinod, H. D. 'New exogeneity tests and causal paths,'
Chapter 2 in 'Handbook of Statistics: Conceptual Econometrics 
Using R', Vol.32, co-editors: H. D. Vinod and C.R. Rao. New York:
North Holland, Elsevier Science Publishers, 2019, pp. 33-64.
</p>
<p>Zheng, S., Shi, N.-Z., and Zhang, Z. (2012). 'Generalized measures 
of correlation for asymmetry, nonlinearity, and beyond,' 
Journal of the American Statistical Association, vol. 107, pp. 1239-1252.
</p>


<h3>See Also</h3>

<p>See Also as <code>gmcmtxBlk</code> for a more general version using
blocking allowing several bandwidths.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
gmcmtx0(mtcars[,1:3])

## Not run: 
set.seed(34);x=matrix(sample(1:600)[1:99],ncol=3)
colnames(x)=c('V1', 'v2', 'V3')
gmcmtx0(x)
## End(Not run)

</code></pre>


</div>