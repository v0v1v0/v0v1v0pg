<div class="container">

<table style="width: 100%;"><tr>
<td>hsic.var.rcv</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Error Variance Estimation in Genomic Prediction
</h2>

<h3>Description</h3>

<p>Estimation of error variance using Refitted Cross Validation in HSIC LASSO.
</p>


<h3>Usage</h3>

<pre><code class="language-R">hsic.var.rcv(x,y,d)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>a matrix of markers or explanatory variables, each column contains one marker and each row represents an individual.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a column vector of response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>number of variables to be selected from x.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Refitted cross validation method (RCV) which is a two step method, is used to get the estimate of the error variance. In first step, dataset is divided into two sub-datasets and with the help of HSIC LASSO most significant markers(variables) are selected from the two sub-datasets. This results in two small sets of selected variables. Then using the set selected from 1st sub-dataset error variance is estimated from the 2nd sub-dataset with ordinary least square method and using the set selected from the 2nd sub-dataset error variance is estimated from the 1st sub-dataset with ordinary least square method. Finally the average of those two error variances are taken as the final estimator of error variance with RCV method.
</p>


<h3>Value</h3>

<table><tr style="vertical-align: top;">
<td><code>Error variance</code></td>
<td>
</td>
</tr></table>
<h3>Author(s)</h3>

<p>Sayanti Guha Majumdar &lt;<a href="mailto:sayanti23gm@gmail.com">sayanti23gm@gmail.com</a>&gt;, Anil Rai, Dwijesh Chandra Mishra
</p>


<h3>References</h3>

<p>Fan, J., Guo, S., Hao, N. (2012). Variance estimation using refitted cross-validation in ultrahigh dimensional regression. <em>Journal of the Royal Statistical Society</em>, 74(1), 37-65.
<br> Yamada, M., Jitkrittum, W., Sigal, L., Xing, E. P. and Sugiyama, M. (2014). High-Dimensional Feature Selection by Feature-Wise Kernelized Lasso. <em>Neural Computation</em>, 26(1):185-207. doi:10.1162/NECO_a_00537
</p>


<h3>Examples</h3>

<pre><code class="language-R">library(GSelection)
data(GS)
x_trn &lt;- GS[1:40,1:110]
y_trn &lt;- GS[1:40,111]
x_tst &lt;- GS[41:60,1:110]
y_tst &lt;- GS[41:60,111]
hsic_var &lt;- hsic.var.rcv(x_trn,y_trn,10)
</code></pre>


</div>