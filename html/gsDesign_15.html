<div class="container">

<table style="width: 100%;"><tr>
<td>ciBinomial</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Testing, Confidence Intervals, Sample Size and Power for Comparing Two
Binomial Rates</h2>

<h3>Description</h3>

<p>Support is provided for sample size estimation, power, testing, confidence
intervals and simulation for fixed sample size trials (that is, not group
sequential or adaptive) with two arms and binary outcomes.  Both superiority
and non-inferiority trials are considered. While all routines default to
comparisons of risk-difference, options to base computations on risk-ratio
and odds-ratio are also included.
</p>
<p><code>nBinomial()</code> computes sample size or power using the method of
Farrington and Manning (1990) for a trial to test the difference between two
binomial event rates.  The routine can be used for a test of superiority or
non-inferiority. For a design that tests for superiority <code>nBinomial()</code>
is consistent with the method of Fleiss, Tytun, and Ury (but without the
continuity correction) to test for differences between event rates. This
routine is consistent with the Hmisc package routines <code>bsamsize</code> and
<code>bpower</code> for superiority designs. Vector arguments allow computing
sample sizes for multiple scenarios for comparative purposes.
</p>
<p><code>testBinomial()</code> computes a Z- or Chi-square-statistic that compares
two binomial event rates using the method of Miettinen and Nurminen (1980).
This can be used for superiority or non-inferiority testing. Vector
arguments allow easy incorporation into simulation routines for fixed, group
sequential and adaptive designs.
</p>
<p><code>ciBinomial()</code> computes confidence intervals for 1) the difference
between two rates, 2) the risk-ratio for two rates or 3) the odds-ratio for
two rates. This procedure provides inference that is consistent with
<code>testBinomial()</code> in that the confidence intervals are produced by
inverting the testing procedures in <code>testBinomial()</code>. The Type I error
<code>alpha</code> input to <code>ciBinomial</code> is always interpreted as 2-sided.
</p>
<p><code>simBinomial()</code> performs simulations to estimate the power for a
Miettinen and Nurminen (1985) test comparing two binomial rates for
superiority or non-inferiority.  As noted in documentation for
<code>bpower.sim()</code> in the HMisc package, by using <code>testBinomial()</code> you
can see that the formulas without any continuity correction are quite
accurate.  In fact, Type I error for a continuity-corrected test is
significantly lower (Gordon and Watson, 1996) than the nominal rate.  Thus,
as a default no continuity corrections are performed.
</p>
<p><code>varBinomial</code> computes blinded estimates of the variance of the
estimate of 1) event rate differences, 2) logarithm of the risk ratio, or 3)
logarithm of the odds ratio. This is intended for blinded sample size
re-estimation for comparative trials with a binary outcome.
</p>
<p>Testing is 2-sided when a Chi-square statistic is used and 1-sided when a
Z-statistic is used. Thus, these 2 options will produce substantially
different results, in general. For non-inferiority, 1-sided testing is
appropriate.
</p>
<p>You may wish to round sample sizes up using <code>ceiling()</code>.
</p>
<p>Farrington and Manning (1990) begin with event rates <code>p1</code> and <code>p2</code>
under the alternative hypothesis and a difference between these rates under
the null hypothesis, <code>delta0</code>. From these values, actual rates under
the null hypothesis are computed, which are labeled <code>p10</code> and
<code>p20</code> when <code>outtype=3</code>. The rates <code>p1</code> and <code>p2</code> are used
to compute a variance for a Z-test comparing rates under the alternative
hypothesis, while <code>p10</code> and <code>p20</code> are used under the null
hypothesis. This computational method is also used to estimate variances in
<code>varBinomial()</code> based on the overall event rate observed and the input
treatment difference specified in <code>delta0</code>.
</p>
<p>Sample size with <code>scale="Difference"</code> produces an error if
<code>p1-p2=delta0</code>.  Normally, the alternative hypothesis under
consideration would be <code>p1-p2-delta0</code>$&gt;0$. However, the alternative can
have <code>p1-p2-delta0</code>$&lt;0$.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ciBinomial(x1, x2, n1, n2, alpha = 0.05, adj = 0, scale = "Difference")

nBinomial(
  p1,
  p2,
  alpha = 0.025,
  beta = 0.1,
  delta0 = 0,
  ratio = 1,
  sided = 1,
  outtype = 1,
  scale = "Difference",
  n = NULL
)

simBinomial(
  p1,
  p2,
  n1,
  n2,
  delta0 = 0,
  nsim = 10000,
  chisq = 0,
  adj = 0,
  scale = "Difference"
)

testBinomial(
  x1,
  x2,
  n1,
  n2,
  delta0 = 0,
  chisq = 0,
  adj = 0,
  scale = "Difference",
  tol = 1e-11
)

varBinomial(x, n, delta0 = 0, ratio = 1, scale = "Difference")
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x1</code></td>
<td>
<p>Number of “successes” in the control group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x2</code></td>
<td>
<p>Number of “successes” in the experimental group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n1</code></td>
<td>
<p>Number of observations in the control group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2</code></td>
<td>
<p>Number of observations in the experimental group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>type I error; see <code>sided</code> below to distinguish between 1-
and 2-sided tests</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adj</code></td>
<td>
<p>With <code>adj=1</code>, the standard variance with a continuity
correction is used for a Miettinen and Nurminen test statistic This includes
a factor of <code class="reqn">n / (n - 1)</code> where <code class="reqn">n</code> is the total sample size. If
<code>adj</code> is not 1, this factor is not applied. The default is <code>adj=0</code>
since nominal Type I error is generally conservative with <code>adj=1</code>
(Gordon and Watson, 1996).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>“Difference”, “RR”, “OR”; see the
<code>scale</code> parameter documentation above and Details.  This is a scalar
argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p1</code></td>
<td>
<p>event rate in group 1 under the alternative hypothesis</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p2</code></td>
<td>
<p>event rate in group 2 under the alternative hypothesis</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>type II error</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta0</code></td>
<td>
<p>A value of 0 (the default) always represents no difference
between treatment groups under the null hypothesis. <code>delta0</code> is
interpreted differently depending on the value of the parameter
<code>scale</code>.  If <code>scale="Difference"</code> (the default), <code>delta0</code> is
the difference in event rates under the null hypothesis (p10 - p20). If
<code>scale="RR"</code>, <code>delta0</code> is the logarithm of the relative risk of
event rates (p10 / p20) under the null hypothesis. If <code>scale="LNOR"</code>,
<code>delta0</code> is the difference in natural logarithm of the odds-ratio under
the null hypothesis <code>log(p10 / (1 - p10)) - log(p20 / (1 - p20))</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ratio</code></td>
<td>
<p>sample size ratio for group 2 divided by group 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sided</code></td>
<td>
<p>2 for 2-sided test, 1 for 1-sided test</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>outtype</code></td>
<td>
<p><code>nBinomial</code> only; 1 (default) returns total sample size;
2 returns a data frame with sample size for each group (<code>n1, n2</code>; if
<code>n</code> is not input as <code>NULL</code>, power is returned in <code>Power</code>; 3
returns a data frame with total sample size (<code>n</code>), sample size in each
group (<code>n1, n2</code>), Type I error (<code>alpha</code>), 1 or 2 (<code>sided</code>, as
input), Type II error (<code>beta</code>), power (<code>Power</code>), null and
alternate hypothesis standard deviations (<code>sigma0, sigma1</code>), input
event rates (<code>p1, p2</code>), null hypothesis difference in treatment group
means (<code>delta0</code>) and null hypothesis event rates (<code>p10, p20</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>If power is to be computed in <code>nBinomial()</code>, input total trial
sample size in <code>n</code>; this may be a vector. This is also the sample size
in <code>varBinomial</code>, in which case the argument must be a scalar.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsim</code></td>
<td>
<p>The number of simulations to be performed in
<code>simBinomial()</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>chisq</code></td>
<td>
<p>An indicator of whether or not a chi-square (as opposed to Z)
statistic is to be computed. If <code>delta0=0</code> (default), the difference in
event rates divided by its standard error under the null hypothesis is used.
Otherwise, a Miettinen and Nurminen chi-square statistic for a 2 x 2 table
is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>Default should probably be used; this is used to deal with a
rounding issue in interim calculations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Number of “successes” in the combined control and
experimental groups.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>testBinomial()</code> and <code>simBinomial()</code> each return a vector
of either Chi-square or Z test statistics.  These may be compared to an
appropriate cutoff point (e.g., <code>qnorm(.975)</code> for normal or
<code>qchisq(.95,1)</code> for chi-square).
</p>
<p><code>ciBinomial()</code> returns a data frame with 1 row with a confidence
interval; variable names are <code>lower</code> and <code>upper</code>.
</p>
<p><code>varBinomial()</code> returns a vector of (blinded) variance estimates of the
difference of event rates (<code>scale="Difference"</code>), logarithm of the
odds-ratio (<code>scale="OR"</code>) or logarithm of the risk-ratio
(<code>scale="RR"</code>).
</p>
<p>With the default <code>outtype=1</code>, <code>nBinomial()</code> returns a vector of
total sample sizes is returned.  With <code>outtype=2</code>, <code>nBinomial()</code>
returns a data frame containing two vectors <code>n1</code> and <code>n2</code>
containing sample sizes for groups 1 and 2, respectively; if <code>n</code> is
input, this option also returns the power in a third vector, <code>Power</code>.
With <code>outtype=3</code>, <code>nBinomial()</code> returns a data frame with the
following columns: </p>
<table>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>A vector with total samples size required for
each event rate comparison specified</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n1</code></td>
<td>
<p>A vector of sample sizes for
group 1 for each event rate comparison specified</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n2</code></td>
<td>
<p>A vector of
sample sizes for group 2 for each event rate comparison specified</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>As input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sided</code></td>
<td>
<p>As input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>As input; if
<code>n</code> is input, this is computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Power</code></td>
<td>
<p>If <code>n=NULL</code> on input,
this is <code>1-beta</code>; otherwise, the power is computed for each sample size
input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma0</code></td>
<td>
<p>A vector containing the standard deviation of the
treatment effect difference under the null hypothesis times <code>sqrt(n)</code>
when <code>scale="Difference"</code> or <code>scale="OR"</code>; when <code>scale="RR"</code>,
this is the standard deviation time <code>sqrt(n)</code> for the numerator of the
Farrington-Manning test statistic <code>x1-exp(delta0)*x2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma1</code></td>
<td>
<p>A
vector containing the values as <code>sigma0</code>, in this case estimated under
the alternative hypothesis.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p1</code></td>
<td>
<p>As input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p2</code></td>
<td>
<p>As input</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p10</code></td>
<td>
<p>group 1 event rate used for null hypothesis</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p20</code></td>
<td>
<p>group 2
event rate used for null hypothesis</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Keaven Anderson <a href="mailto:keaven_anderson@merck.com">keaven_anderson@merck.com</a>
</p>


<h3>References</h3>

<p>Farrington, CP and Manning, G (1990), Test statistics and sample
size formulae for comparative binomial trials with null hypothesis of
non-zero risk difference or non-unity relative risk. <em>Statistics in
Medicine</em>; 9: 1447-1454.
</p>
<p>Fleiss, JL, Tytun, A and Ury (1980), A simple approximation for calculating
sample sizes for comparing independent proportions.
<em>Biometrics</em>;36:343-346.
</p>
<p>Gordon, I and Watson R (1985), The myth of continuity-corrected sample size
formulae. <em>Biometrics</em>; 52: 71-76.
</p>
<p>Miettinen, O and Nurminen, M (1985), Comparative analysis of two rates.
<em>Statistics in Medicine</em>; 4 : 213-226.
</p>


<h3>See Also</h3>

<p><code>Normal</code>,<code>uniroot</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Compute z-test test statistic comparing 39/500 to 13/500
# use continuity correction in variance
x &lt;- testBinomial(x1 = 39, x2 = 13, n1 = 500, n2 = 500, adj = 1)
x
pnorm(x, lower.tail = FALSE)

# Compute with unadjusted variance
x0 &lt;- testBinomial(x1 = 39, x2 = 23, n1 = 500, n2 = 500)
x0
pnorm(x0, lower.tail = FALSE)

# Perform 50k simulations to test validity of the above
# asymptotic p-values
# (you may want to perform more to reduce standard error of estimate)
sum(as.double(x0) &lt;=
  simBinomial(p1 = .078, p2 = .078, n1 = 500, n2 = 500, nsim = 10000)) / 10000
sum(as.double(x0) &lt;=
  simBinomial(p1 = .052, p2 = .052, n1 = 500, n2 = 500, nsim = 10000)) / 10000

# Perform a non-inferiority test to see if p2=400 / 500 is within 5% of
# p1=410 / 500 use a z-statistic with unadjusted variance
x &lt;- testBinomial(x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05)
x
pnorm(x, lower.tail = FALSE)

# since chi-square tests equivalence (a 2-sided test) rather than
# non-inferiority (a 1-sided test),
# the result is quite different
pchisq(testBinomial(
  x1 = 410, x2 = 400, n1 = 500, n2 = 500, delta0 = -.05,
  chisq = 1, adj = 1
), 1, lower.tail = FALSE)

# now simulate the z-statistic witthout continuity corrected variance
sum(qnorm(.975) &lt;=
  simBinomial(p1 = .8, p2 = .8, n1 = 500, n2 = 500, nsim = 100000)) / 100000

# compute a sample size to show non-inferiority
# with 5% margin, 90% power
nBinomial(p1 = .2, p2 = .2, delta0 = .05, alpha = .025, sided = 1, beta = .1)

# assuming a slight advantage in the experimental group lowers
# sample size requirement
nBinomial(p1 = .2, p2 = .19, delta0 = .05, alpha = .025, sided = 1, beta = .1)

# compute a sample size for comparing 15% vs 10% event rates
# with 1 to 2 randomization
nBinomial(p1 = .15, p2 = .1, beta = .2, ratio = 2, alpha = .05)

# now look at total sample size using 1-1 randomization
n &lt;- nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05)
n
# check if inputing sample size returns the desired power
nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, n = n)

# re-do with alternate output types
nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 2)
nBinomial(p1 = .15, p2 = .1, beta = .2, alpha = .05, outtype = 3)

# look at power plot under different control event rate and
# relative risk reductions
library(dplyr)
library(ggplot2)
p1 &lt;- seq(.075, .2, .000625)
len &lt;- length(p1)
p2 &lt;- c(p1 * .75, p1 * 2/3, p1 * .6, p1 * .5)
Reduction &lt;- c(rep("25 percent", len), rep("33 percent", len), 
               rep("40 percent", len), rep("50 percent", len))
df &lt;- tibble(p1 = rep(p1, 4), p2, Reduction) %&gt;% 
  mutate(`Sample size` = nBinomial(p1, p2, beta = .2, alpha = .025, sided = 1))
ggplot(df, aes(x = p1, y = `Sample size`, col = Reduction)) + 
  geom_line() + 
  xlab("Control group event rate") +
  ylim(0,6000) +
  ggtitle("Binomial sample size computation for 80 pct power")

# compute blinded estimate of treatment effect difference
x1 &lt;- rbinom(n = 1, size = 100, p = .2)
x2 &lt;- rbinom(n = 1, size = 200, p = .1)
# blinded estimate of risk difference variance
varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0)
# blinded estimate of log-risk-ratio variance
varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = "RR")
# blinded estimate of log-odds-ratio variance
varBinomial(x = x1 + x2, n = 300, ratio = 2, delta0 = 0, scale = "OR")
</code></pre>


</div>