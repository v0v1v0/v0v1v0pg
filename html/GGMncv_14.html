<div class="container">

<table style="width: 100%;"><tr>
<td>kl_mvn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Kullback-Leibler Divergence</h2>

<h3>Description</h3>

<p>Compute KL divergence for a multivariate normal distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kl_mvn(true, estimate, stein = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>true</code></td>
<td>
<p>Matrix. The true precision matrix
(inverse of the covariance matrix)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimate</code></td>
<td>
<p>Matrix. The estimated precision matrix
(inverse of the covariance matrix)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stein</code></td>
<td>
<p>Logical. Should Stein's loss be computed
(defaults to <code>TRUE</code>)? Note KL divergence is
half of Stein's loss.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Numeric corresponding to KL divergence.
</p>


<h3>Note</h3>

<p>A lower value is better, with a score of zero indicating that
the estimated precision matrix is identical to the true precision matrix.
</p>


<h3>Examples</h3>

<pre><code class="language-R">

# nodes
p &lt;- 20

main &lt;- gen_net(p = p, edge_prob = 0.15)

y &lt;- MASS::mvrnorm(250, rep(0, p), main$cors)

fit_l1 &lt;- ggmncv(R = cor(y),
              n = nrow(y),
              penalty = "lasso",
              progress = FALSE)

# lasso
kl_mvn(fit_l1$Theta, solve(main$cors))

fit_atan &lt;- ggmncv(R = cor(y),
              n = nrow(y),
              penalty = "atan",
              progress = FALSE)

kl_mvn(fit_atan$Theta, solve(main$cors))


</code></pre>


</div>