<div class="container">

<table style="width: 100%;"><tr>
<td>cv.gcdnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation for gcdnet</h2>

<h3>Description</h3>

<p>Does k-fold cross-validation for gcdnet, produces a plot, and returns a
value for <code>lambda</code>. This function is modified based on the <code>cv</code>
function from the <code>glmnet</code> package.
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.gcdnet(
  x,
  y,
  lambda = NULL,
  pred.loss = c("misclass", "loss"),
  nfolds = 5,
  foldid,
  delta = 2,
  omega = 0.5,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>x</code> matrix as in <code>gcdnet</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>response variable or class label <code>y</code> as in
<code>gcdnet</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>optional user-supplied lambda sequence; default is
<code>NULL</code>, and <code>gcdnet</code> chooses its own sequence.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pred.loss</code></td>
<td>
<p>loss function to use for cross-validation error. Valid
options are: </p>
 <ul>
<li> <p><code>"loss"</code> Margin based loss function.
When use least square loss <code>"ls"</code>, it gives mean square error (MSE).
When use expectile regression loss <code>"er"</code>, it gives asymmetric mean
square error (AMSE). </p>
</li>
<li> <p><code>"misclass"</code> only available for
classification: it gives misclassification error. </p>
</li>
</ul>
<p> Default is
<code>"loss"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfolds</code></td>
<td>
<p>number of folds - default is 5. Although <code>nfolds</code> can be
as large as the sample size (leave-one-out CV), it is not recommended for
large datasets. Smallest value allowable is <code>nfolds=3</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>foldid</code></td>
<td>
<p>an optional vector of values between 1 and <code>nfold</code>
identifying what fold each observation is in. If supplied, <code>nfold</code>
can be missing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>delta</code></td>
<td>
<p>parameter <code class="reqn">\delta</code> only used in HHSVM for computing
margin based loss function, only available for <code>pred.loss = "loss"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>omega</code></td>
<td>
<p>parameter <code class="reqn">\omega</code> only used in expectile
regression. Only available for <code>pred.loss = "loss"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other arguments that can be passed to gcdnet.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The function runs <code>gcdnet</code> <code>nfolds</code>+1 times; the first to
get the <code>lambda</code> sequence, and then the remainder to compute the fit
with each of the folds omitted. The average error and standard deviation
over the folds are computed.
</p>


<h3>Value</h3>

<p>an object of class <code>cv.gcdnet</code> is returned, which is a
list with the ingredients of the cross-validation fit. </p>
<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the
values of <code>lambda</code> used in the fits.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvm</code></td>
<td>
<p>the mean
cross-validated error - a vector of length <code>length(lambda)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvsd</code></td>
<td>
<p>estimate of standard error of <code>cvm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvupper</code></td>
<td>
<p>upper curve = <code>cvm+cvsd</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvlower</code></td>
<td>
<p>lower curve
= <code>cvm-cvsd</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nzero</code></td>
<td>
<p>number of non-zero coefficients at each
<code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>name</code></td>
<td>
<p>a text string indicating type of measure (for
plotting purposes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gcdnet.fit</code></td>
<td>
<p>a fitted <code>gcdnet</code>
object for the full data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>
<p>The optimal value of
<code>lambda</code> that gives minimum cross validation error <code>cvm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.1se</code></td>
<td>
<p>The largest value of <code>lambda</code> such that error is
within 1 standard error of the minimum.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Yi Yang, Yuwen Gu and Hui Zou<br> Maintainer: Yi Yang
&lt;yi.yang6@mcgill.ca&gt;
</p>


<h3>References</h3>

<p>Yang, Y. and Zou, H. (2012).
"An Efficient Algorithm for Computing The HHSVM and Its Generalizations."
<em>Journal of Computational and Graphical Statistics</em>, 22, 396-415.<br>
BugReport: <a href="https://github.com/emeryyi/gcdnet">https://github.com/emeryyi/gcdnet</a><br></p>
<p>Gu, Y., and Zou, H. (2016).
"High-dimensional generalizations of asymmetric least squares regression and their applications."
<em>The Annals of Statistics</em>, 44(6), 2661â€“2694.<br></p>
<p>Friedman, J., Hastie, T., and Tibshirani, R. (2010).
"Regularization paths for generalized linear models via coordinate descent."
<em>Journal of Statistical Software, 33, 1.</em><br><a href="https://www.jstatsoft.org/v33/i01/">https://www.jstatsoft.org/v33/i01/</a>
</p>


<h3>See Also</h3>

<p><code>gcdnet</code>, <code>plot.cv.gcdnet</code>,
<code>predict.cv.gcdnet</code>, and <code>coef.cv.gcdnet</code> methods.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# fit an elastic net penalized HHSVM with lambda2 = 0.1 for the L2 penalty.
# Use the misclassification rate as the cross validation prediction loss.
# Use five-fold CV to choose the optimal lambda for the L1 penalty.

data(FHT)
set.seed(2011)
cv &lt;- cv.gcdnet(FHT$x, FHT$y, method = "hhsvm",
                lambda2 = 0.1, pred.loss = "misclass",
                nfolds = 5, delta = 1.5)
plot(cv)

# fit an elastic net penalized least squares
# with lambda2 = 0.1 for the L2 penalty. Use the
# least square loss as the cross validation
# prediction loss. Use five-fold CV to choose
# the optimal lambda for the L1 penalty.

set.seed(2011)
cv1 &lt;- cv.gcdnet(FHT$x, FHT$y_reg, method ="ls",
                 lambda2 = 0.1, pred.loss = "loss",
                 nfolds = 5)
plot(cv1)

# To fit a LASSO penalized logistic regression
# we set lambda2 = 0 to disable the L2 penalty. Use the
# logistic loss as the cross validation
# prediction loss. Use five-fold CV to choose
# the optimal lambda for the L1 penalty.

set.seed(2011)
cv2 &lt;- cv.gcdnet(FHT$x, FHT$y, method ="logit",
                 lambda2 = 0, pred.loss="loss",
                 nfolds=5)
plot(cv2)

</code></pre>


</div>