<div class="container">

<table style="width: 100%;"><tr>
<td>GSparO</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Group sparse optimization</h2>

<h3>Description</h3>

<p>Group sparse optimization (GSparO) for least squares regression by using the proximal gradient algorithm to solve the L_2,1/2 regularization model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">GSparO(A, b, Initial, group, MaxIter, sparsity)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>decoding matrix (matrix of predictors)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b</code></td>
<td>
<p>noised signal (response)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Initial</code></td>
<td>
<p>an initial point of iteration, recommend to set as a column vector of zeros</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>group</code></td>
<td>
<p>group information, a column vector consisting of the length of each group</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>MaxIter</code></td>
<td>
<p>the maximum number of iterations (a stopping criterion), recommend to set as 200</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sparsity</code></td>
<td>
<p>a guess of the group sparsity level (the number of nonzero groups)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>GSparO is group sparse optimization for least squares regression described in [Hu et al(2017)], in which the proximal gradient algorithm is implemented to solve the L_2,1/2 regularization model. GSparO is an iterative algorithm consisting of a gradient step for the least squares regression and a proximal steps for the L_2,1/2 penalty, which is analytically formulated in this function. Also, GSparO can solve sparse variable selection problem in absence of group structure. In particular, setting group in GSparO be a vector of ones, GSparO is reduced to the iterative half thresholding algorithm introduced in [Xu et al (2012)].
Copyright by Dr. Yaohua Hu, College of Mathematics and Statistics, Shenzhen University.
Email: mayhhu@szu.edu.cn
</p>


<h3>Author(s)</h3>

<p>Yaohua Hu</p>


<h3>References</h3>

<p>Y. Hu, C. Li, K. Meng, J. Qin, and X. Yang (2017). Group sparse optimization via L_p,q regularization. Journal of Machine Learning Research, to appear.
</p>
<p>Z. Xu, X. Chang, F. Xu, and H. Zhang (2012). L_1/2 regularization: A thresholding representation theory and a fast solver. IEEE Transactions on Neural Networks and Learning Systems.
</p>


<h3>Examples</h3>

<pre><code class="language-R">m &lt;- 256
n &lt;- 1024
sparsity &lt;- 6
gLen &lt;- 16
MaxIter &lt;- 200
gNo &lt;- 1024/gLen
group &lt;- gLen*matrix(1,gNo,1)
A &lt;- matrix(rnorm(m*n,0,1),m,n)
library(ThreeWay)
A &lt;- orth(t(A))
A &lt;- t(A)
gNo1 &lt;- 1:gNo
ActInd &lt;- sample(gNo1,gNo)
Bs &lt;- matrix(0,n,1)
c &lt;- matrix(rnorm(n,0,1),n,1)
for (i in 1:sparsity){
 Bs[((ActInd[i]-1)*gLen+1):(ActInd[i]*gLen)] &lt;- matrix(1,gLen,1)}
c &lt;- Bs*c
sigma &lt;- 1e-3
b &lt;- A%*%c + sigma*matrix(runif(m,min=0,max=1),m,1)
Initial &lt;- matrix(0,n,1)
GSparO(A,b,Initial,group,MaxIter,sparsity)
</code></pre>


</div>