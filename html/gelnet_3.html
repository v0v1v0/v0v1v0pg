<div class="container">

<table style="width: 100%;"><tr>
<td>gelnet</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>GELnet for linear regression, binary classification and one-class problems.</h2>

<h3>Description</h3>

<p>Infers the problem type and learns the appropriate GELnet model via coordinate descent.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gelnet(X, y, l1, l2, nFeats = NULL, a = rep(1, n), d = rep(1, p),
  P = diag(p), m = rep(0, p), max.iter = 100, eps = 1e-05,
  w.init = rep(0, p), b.init = NULL, fix.bias = FALSE, silent = FALSE,
  balanced = FALSE, nonneg = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>n-by-p matrix of n samples in p dimensions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>n-by-1 vector of response values. Must be numeric vector for regression, factor with 2 levels for binary classification, or NULL for a one-class task.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l1</code></td>
<td>
<p>coefficient for the L1-norm penalty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l2</code></td>
<td>
<p>coefficient for the L2-norm penalty</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nFeats</code></td>
<td>
<p>alternative parameterization that returns the desired number of non-zero weights. Takes precedence over l1 if not NULL (default: NULL)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a</code></td>
<td>
<p>n-by-1 vector of sample weights (regression only)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>p-by-1 vector of feature weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p>p-by-p feature association penalty matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p>p-by-1 vector of translation coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max.iter</code></td>
<td>
<p>maximum number of iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>convergence precision</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w.init</code></td>
<td>
<p>initial parameter estimate for the weights</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.init</code></td>
<td>
<p>initial parameter estimate for the bias term</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fix.bias</code></td>
<td>
<p>set to TRUE to prevent the bias term from being updated (regression only) (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>silent</code></td>
<td>
<p>set to TRUE to suppress run-time output to stdout (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>balanced</code></td>
<td>
<p>boolean specifying whether the balanced model is being trained (binary classification only) (default: FALSE)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nonneg</code></td>
<td>
<p>set to TRUE to enforce non-negativity constraints on the weights (default: FALSE )</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The method determines the problem type from the labels argument y.
If y is a numeric vector, then a regression model is trained by optimizing the following objective function:
</p>
<p style="text-align: center;"><code class="reqn"> \frac{1}{2n} \sum_i a_i (y_i - (w^T x_i + b))^2 + R(w) </code>
</p>

<p>If y is a factor with two levels, then the function returns a binary classification model, obtained by optimizing the following objective function:
</p>
<p style="text-align: center;"><code class="reqn"> -\frac{1}{n} \sum_i y_i s_i - \log( 1 + \exp(s_i) ) + R(w) </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn"> s_i = w^T x_i + b </code>
</p>

<p>Finally, if no labels are provided (y == NULL), then a one-class model is constructed using the following objective function:
</p>
<p style="text-align: center;"><code class="reqn"> -\frac{1}{n} \sum_i s_i - \log( 1 + \exp(s_i) ) + R(w) </code>
</p>

<p>where
</p>
<p style="text-align: center;"><code class="reqn"> s_i = w^T x_i </code>
</p>

<p>In all cases, the regularizer is defined by
</p>
<p style="text-align: center;"><code class="reqn"> R(w) = \lambda_1 \sum_j d_j |w_j| + \frac{\lambda_2}{2} (w-m)^T P (w-m) </code>
</p>

<p>The training itself is performed through cyclical coordinate descent, and the optimization is terminated after the desired tolerance is achieved or after a maximum number of iterations.
</p>


<h3>Value</h3>

<p>A list with two elements:
</p>

<dl>
<dt>w</dt>
<dd>
<p>p-by-1 vector of p model weights</p>
</dd>
<dt>b</dt>
<dd>
<p>scalar, bias term for the linear model (omitted for one-class models)</p>
</dd>
</dl>
<h3>See Also</h3>

<p><code>gelnet.lin.obj</code>, <code>gelnet.logreg.obj</code>, <code>gelnet.oneclass.obj</code>
</p>


</div>