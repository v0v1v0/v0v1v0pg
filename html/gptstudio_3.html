<div class="container">

<table style="width: 100%;"><tr>
<td>chat</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Chat Interface for gptstudio</h2>

<h3>Description</h3>

<p>This function provides a high-level interface for communicating with various
services and models supported by gptstudio. It orchestrates the creation,
configuration, and execution of a request based on user inputs and options
set for gptstudio. The function supports a range of tasks from text
generation to code synthesis and can be customized according to skill level
and coding style preferences.
</p>


<h3>Usage</h3>

<pre><code class="language-R">chat(
  prompt,
  service = getOption("gptstudio.service"),
  history = list(list(role = "system", content = "You are an R chat assistant")),
  stream = FALSE,
  model = getOption("gptstudio.model"),
  skill = getOption("gptstudio.skill"),
  style = getOption("gptstudio.code_style", "no preference"),
  task = getOption("gptstudio.task", "coding"),
  custom_prompt = NULL,
  process_response = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prompt</code></td>
<td>
<p>A string containing the initial prompt or question to be sent
to the model. This is a required parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>service</code></td>
<td>
<p>The AI service to be used for the request. If not explicitly
provided, this defaults to the value set in
<code>getOption("gptstudio.service")</code>. If the option is not set, make sure to
provide this parameter to avoid errors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>history</code></td>
<td>
<p>An optional parameter that can be used to include previous
interactions or context for the current session. Defaults to a system
message indicating "You are an R chat assistant".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stream</code></td>
<td>
<p>A logical value indicating whether the interaction should be
treated as a stream for continuous interactions. If not explicitly
provided, this defaults to the value set in
<code>getOption("gptstudio.stream")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The specific model to use for the request. If not explicitly
provided, this defaults to the value set in <code>getOption("gptstudio.model")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>skill</code></td>
<td>
<p>A character string indicating the skill or capability level of
the user. This parameter allows for customizing the behavior of the model
to the user. If not explicitly provided, this defaults to the value set in
<code>getOption("gptstudio.skill")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>style</code></td>
<td>
<p>The coding style preferred by the user for code generation
tasks. This parameter is particularly useful when the task involves
generating code snippets or scripts. If not explicitly provided, this
defaults to the value set in <code>getOption("gptstudio.code_style")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>task</code></td>
<td>
<p>The specific type of task to be performed, ranging from text
generation to code synthesis, depending on the capabilities of the model.
If not explicitly provided, this defaults to the value set in
<code>getOption("gptstudio.task")</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>custom_prompt</code></td>
<td>
<p>An optional parameter that provides a way to extend or
customize the initial prompt with additional instructions or context.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>process_response</code></td>
<td>
<p>A logical indicating whether to process the model's
response. If <code>TRUE</code>, the response will be passed to
<code>gptstudio_response_process()</code> for further processing. Defaults to <code>FALSE</code>.
Refer to <code>gptstudio_response_process()</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Reserved for future use.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Depending on the task and processing, the function returns the
response from the model, which could be text, code, or any other structured
output defined by the task and model capabilities. The precise format and
content of the output depend on the specified options and the capabilities
of the selected model.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# Basic usage with a text prompt:
result &lt;- chat("What is the weather like today?")

# Advanced usage with custom settings, assuming appropriate global options are set:
result &lt;- chat(
  prompt = "Write a simple function in R",
  skill = "advanced",
  style = "tidyverse",
  task = "coding"
)

# Usage with explicit service and model specification:
result &lt;- chat(
  prompt = "Explain the concept of tidy data in R",
  service = "openai",
  model = "gpt-4-turbo-preview",
  skill = "intermediate",
  task = "general"
)

## End(Not run)

</code></pre>


</div>