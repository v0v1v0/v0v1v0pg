<div class="container">

<table style="width: 100%;"><tr>
<td>gp_energy</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Energy of a GP model</h2>

<h3>Description</h3>

<p>Returns the energy (negative log marginal likelihood) of a fitted GP model with the
current hyperparameters. The result is exact for the Gaussian likelihood and
dependent on the <code>approx</code> for other cases.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gp_energy(gp, include_prior = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>gp</code></td>
<td>
<p>The fitted GP model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>include_prior</code></td>
<td>
<p>Whether to add log density of the prior to the result (in which case
the result is -(log marginal likelihood + log prior))</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The energy value (negative log marginal likelihood).
</p>


<h3>References</h3>

<p>Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning. MIT Press.
</p>


<h3>Examples</h3>

<pre><code class="language-R">

# Generate some toy data
set.seed(1242)
n &lt;- 500
x &lt;- matrix(rnorm(n * 3), nrow = n)
f &lt;- sin(x[, 1]) + 0.5 * x[, 2]^2 + x[, 3]
y &lt;- f + 0.5 * rnorm(n)
x &lt;- data.frame(x1 = x[, 1], x2 = x[, 2], x3 = x[, 3])

# Basic usage
gp &lt;- gp_init(cf_sexp(), lik_gaussian())
gp &lt;- gp_fit(gp, x, y)
e &lt;- gp_energy(gp)


</code></pre>


</div>