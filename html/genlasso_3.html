<div class="container">

<table style="width: 100%;"><tr>
<td>cv.trendfilter</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Perform k-fold cross-validation to choose a trend filtering model
</h2>

<h3>Description</h3>

<p>This function performs k-fold cross-validation to choose the value of
the regularization parameter lambda for a trend filtering problem,
given the computed solution path. This function only applies to trend
filtering objects with identity predictor matrix (no <code>X</code> passed).
</p>


<h3>Usage</h3>

<pre><code class="language-R">cv.trendfilter(object, k = 5, mode = c("lambda", "df"),
               approx = FALSE, rtol = 1e-07, btol = 1e-07,
               verbose = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>

<p>the solution path object, of class "trendfilter", as returned by the
<code>trendfilter</code> function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>

<p>an integer indicating the number of folds to split the data
into. Must be between 2 and n-2 (n being the number of
observations), default is 5. It is generally not a good idea to
pass a value of k much larger than 10 (say, on the scale of n); see
"Details" below. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>

<p>a character string, either "lambda" or "df". Specifying "lambda"
means that the cross-validation error will be computed and reported
at each value of lambda that appears as a knot in the solution
path. Specifying "df" means that the cross-validation error will be 
computed and reported for every of degrees of freedom value
(actually, estimate) incurred along the solution path. In the case
that the same degrees of freedom value is visited multiple times,
the model with the most regularization (smallest value of lambda) is
considered. Default is "lambda". 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>approx</code></td>
<td>

<p>a logical variable indicating if the approximate solution path
should be used (with no dual coordinates leaving the boundary).
Default is <code>FALSE</code>.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rtol</code></td>
<td>

<p>a numeric variable giving the relative tolerance used in the
calculation of the hitting and leaving times. A larger value
is more conservative, and may cause the algorithm to miss some
hitting or leaving events (do not change unless you know what
you're getting into!). Defaultis 1e-7. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>btol</code></td>
<td>

<p>similar to <code>rtol</code> but in absolute terms. If numerical
instability is detected, first change rtol; then adjust btol
if problems persist.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>a logical variable indicating if progress should be reported after
each knot in the path.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For trend filtering (with an identity predictor matrix), the folds 
for k-fold cross-validation are chosen by placing every kth point into
the same fold. (Here the points are implicitly ordered according to their 
underlying positionsâ€”either assumed to be evenly spaced, or explicitly 
passed through the <code>pos</code> argument.) 
The first and last points are not included in any fold and are always
included in building the predictive model. As an example, 
with n=15 data points and k=4 folds, the points are assigned to folds 
in the following way:
</p>
<p style="text-align: center;"><code class="reqn">
    x \; 1 \; 2 \; 3 \; 4 \; 1 \; 2 \; 3 \;  4 \; 1 \; 2 \; 3 \; 4 \; 1
    \; x
  </code>
</p>

<p>where <code class="reqn">x</code> indicates no assignment. Therefore, the folds are not
random and running <code>cv.trendfilter</code> twice will give the same
result. In the calculation of the cross-validated error, the
predicted value at a point is given by the average of the fits at this 
point's two neighbors (guaranteed to be in a different fold). 
</p>
<p>Running cross-validation in modes "lambda" and "df" often yields very
similar results. The mode "df" simply gives an alternative
parametrization for the sequence of cross-validated models and can be
more convenient for some applications; if you are confused about its
function, simply leave the mode equal to "lambda".
</p>


<h3>Value</h3>

<p>Returns and object of class "cv.trendfilter", a list with the
following components:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>err</code></td>
<td>

<p>a numeric vector of cross-validated errors.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>se</code></td>
<td>

<p>a numeric vector of standard errors (standard deviations of the
cross-validation error estimates).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mode</code></td>
<td>

<p>a character string indicating the mode, either "lambda" or "df".
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>

<p>if <code>mode="lambda"</code>, the values of lambda at which the
cross-validation errors in <code>err</code> were computed. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.min</code></td>
<td>

<p>if <code>mode="lambda"</code>, the value of lambda at which the
cross-validation error is minimized.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.1se</code></td>
<td>

<p>if <code>mode="lambda"</code>, the value of lambda chosen by the one
standard error rule (the largest value of lambda such that the
cross-validation error is within one standard error of the minimum).  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>

<p>if <code>mode="df"</code>, the degrees of freedom values at which the
cross-validation errors in <code>err</code> were computed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df.min</code></td>
<td>

<p>if <code>mode="df"</code>, the degrees of freedom value at which the
cross-validation error is minimized.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df.1se</code></td>
<td>

<p>if <code>mode="df"</code>, the degrees of freedom value chosen by the 
one standard error rule (the smallest degrees of freedom value such 
that cross-validation error is within one standard error of the
minimum).   
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>i.min</code></td>
<td>

<p>the index of the model minimizing the cross-validation error.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>i.1se</code></td>
<td>

<p>the index of the model chosen by the one standard error rule.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>

<p>the matched call.
</p>
</td>
</tr>
</table>
<h3>See Also</h3>

<p><code>trendfilter</code>, <code>plot.cv.trendfilter</code>,
<code>plot.trendfilter</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Constant trend filtering (the 1d fused lasso)
set.seed(0)
n = 50
beta0 = rep(sample(1:10,5),each=n/5)
y = beta0 + rnorm(n,sd=0.8)
a = fusedlasso1d(y)
plot(a)

# Choose lambda by 5-fold cross-validation
cv = cv.trendfilter(a)
plot(cv)
plot(a,lambda=cv$lambda.min,main="Minimal CV error")
plot(a,lambda=cv$lambda.1se,main="One standard error rule")


# Cubic trend filtering
set.seed(0)
n = 100
beta0 = numeric(100)
beta0[1:40] = (1:40-20)^3
beta0[40:50] = -60*(40:50-50)^2 + 60*100+20^3
beta0[50:70] = -20*(50:70-50)^2 + 60*100+20^3
beta0[70:100] = -1/6*(70:100-110)^3 + -1/6*40^3 + 6000
beta0 = -beta0
beta0 = (beta0-min(beta0))*10/diff(range(beta0))
y = beta0 + rnorm(n)
a = trendfilter(y,ord=3,maxsteps=150)
plot(a,nlam=5)

# Choose lambda by 5-fold cross-validation
cv = cv.trendfilter(a)
plot(cv)
plot(a,lambda=cv$lambda.min,main="Minimal CV error")
plot(a,lambda=cv$lambda.1se,main="One standard error rule")

</code></pre>


</div>