<div class="container">

<table style="width: 100%;"><tr>
<td>gamm4</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Generalized Additive Mixed Models using lme4 and mgcv</h2>

<h3>Description</h3>

<p> Fits the specified  generalized additive mixed model (GAMM) to
data, by making use of the <code>modular</code> fitting functions provided 
by lme4 (new version). For earlier lme4 versions modelling fitting is via
a call to <code>lmer</code> in the normal errors identity link case, or by 
a call to <code>glmer</code> otherwise  (see <code>lmer</code>). Smoothness selection is by REML in the Gaussian 
additive case and (Laplace approximate) ML otherwise. 
</p>
<p><code>gamm4</code> is based on <code>gamm</code> from package <code>mgcv</code>, but uses <code>lme4</code> rather than 
<code>nlme</code> as the underlying fitting engine via a trick due to Fabian Scheipl. 
<code>gamm4</code> is more robust numerically than <code>gamm</code>, and by avoiding PQL gives better 
performance for binary and low mean count data. Its main disadvantage is that it can not handle most multi-penalty 
smooths (i.e. not <code>te</code> type tensor products or adaptive smooths) and there is 
no facilty for <code>nlme</code> style correlation structures. Tensor product smoothing is available via 
<code>t2</code> terms (Wood, Scheipl and Faraway, 2013).
</p>
<p>For fitting generalized additive models without random effects, <code>gamm4</code> is much slower 
than <code>gam</code> and has slightly worse MSE performance than <code>gam</code> 
with REML smoothness selection. For fitting GAMMs with modest numbers of i.i.d. random coefficients 
then <code>gamm4</code> is slower than <code>gam</code> (or <code>bam</code> for large data 
sets). <code>gamm4</code> is most useful when the random effects are not i.i.d., or when there are large 
numbers of random coeffecients (more than several hundred), each applying to only a small proportion 
of the response data. 
</p>
<p>To use this function effectively it helps to be quite familiar with the use of
<code>gam</code> and <code>lmer</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gamm4(formula,random=NULL,family=gaussian(),data=list(),weights=NULL,
      subset=NULL,na.action,knots=NULL,drop.unused.levels=TRUE,
      REML=TRUE,control=NULL,start=NULL,verbose=0L,...)
</code></pre>


<h3>Arguments</h3>

 
<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p> A GAM formula (see also <code>formula.gam</code> and <code>gam.models</code>).
This is like the formula for a <code>glm</code> except that smooth terms (<code>s</code> and <code>t2</code> 
but not <code>te</code>) can be added to the right hand side of the formula. Note that <code>id</code>s for smooths and fixed smoothing 
parameters are not supported.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>random</code></td>
<td>
<p>An optional formula specifying the random effects structure in <code>lmer</code> style.
See example below.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>A <code>family</code> as used in a call to <code>glm</code> or <code>gam</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p> A data frame or list containing the model response variable and 
covariates required by the formula.  By default the variables are taken 
from <code>environment(formula)</code>, typically the environment from 
which <code>gamm4</code> is called.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>a vector of prior weights on the observations. <code>NULL</code> is equivalent to a vector of 1s. Used, in particular, 
to supply the number-of-trials for binomial data, when the response is proportion of successes. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p> an optional vector specifying a subset of observations to be
used in the fitting process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>na.action</code></td>
<td>
<p> a function which indicates what should happen when the data
contain ‘NA’s.  The default is set by the ‘na.action’ setting
of ‘options’, and is ‘na.fail’ if that is unset.  The
“factory-fresh” default is ‘na.omit’.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knots</code></td>
<td>
<p>this is an optional list containing user specified knot values to be used for basis construction. 
Different terms can use different numbers of knots, unless they share a covariate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop.unused.levels</code></td>
<td>
<p>by default unused levels are dropped from factors before fitting. For some smooths 
involving factor variables you might want to turn this off. Only do so if you know what you are doing.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>REML</code></td>
<td>
<p>passed on to <code>lmer</code> fitting routines (but not <code>glmer</code> fitting routines) to control whether REML or ML is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p><code>lmerControl</code> or <code>glmerControl</code> list as appropriate (<code>NULL</code> means defaults are used).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>start</code></td>
<td>
<p>starting value list as used by <code>lmer</code> or <code>glmer</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>passed on to fitting <code>lme4</code> fitting routines.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>further arguments for passing on to model setup routines.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>A generalized additive mixed model is a generalized linear mixed model in which the linear predictor 
depends linearly on unknown smooth functions of some of the covariates (‘smooths’ for short). <code>gamm4</code> follows the approach taken 
by package <code>mgcv</code> and represents the smooths using penalized regression spline type smoothers, of 
moderate rank. For estimation purposes the penalized component of each smooth is treated as a random effect term, 
while the unpenalized component is treated as fixed. The wiggliness penalty matrix for the smooth is in effect the 
precision matrix when the smooth is treated as a random effect. Estimating the degree of smoothness of the term 
amounts to estimating the variance parameter for the term. 
</p>
<p><code>gamm4</code> uses the same reparameterization trick employed by <code>gamm</code> to allow any single quadratic 
penalty smoother to be used (see Wood, 2004, or 2006 for details). Given the reparameterization then the modular fitting approach employed in <code>lmer</code> can be used to fit a GAMM. Estimation is by 
Maximum Likelihood in the generalized case, and REML in the gaussian additive model case. <code>gamm4</code> allows 
the random effects specifiable with <code>lmer</code> to be combined with any number of any of the (single penalty) smooth
terms available in <code>gam</code> from package <code>mgcv</code> as well as <code>t2</code> tensor product smooths. 
Note that the model comparison on the basis of the (Laplace 
approximate) log likelihood is possible with GAMMs fitted by <code>gamm4</code>. 
</p>
<p>As in <code>gamm</code> the smooth estimates are assumed to be of interest, and a covariance matrix is returned which 
enables Bayesian credible intervals for the smooths to be constructed, which treat all the terms in <code>random</code> as random. 
</p>
<p>For details on how to condition smooths on factors, set up varying coefficient models, do signal regression or set up terms 
involving linear functionals of smooths, see <code>gam.models</code>, but note that <code>te</code> type tensor product and adaptive smooths are 
not available with <code>gamm4</code>.
</p>


<h3>Value</h3>

<p> Returns a list with two items:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>gam</code></td>
<td>
<p>an object of class <code>gam</code>. At present this contains enough information to use
<code>predict</code>, <code>plot</code>, <code>summary</code> and <code>print</code> methods and <code>vis.gam</code>, from package <code>mgcv</code>
but not to use e.g. the <code>anova</code> method function to compare models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mer</code></td>
<td>
<p>the fitted model object returned by <code>lmer</code> or <code>glmer</code>. Extra random and fixed 
effect terms will appear relating to the estimation of the smooth terms. Note that unlike <code>lme</code> objects returned
by <code>gamm</code>, everything in this object always relates to the fitted model itself, and never to a PQL working 
approximation: hence the usual methods of model comparison are entirely legitimate. </p>
</td>
</tr>
</table>
<h3>WARNINGS </h3>

<p>If you don't need random effects in addition to the smooths, then gam 
is substantially faster, gives fewer convergence warnings, and slightly better 
MSE performance (based on simulations).
</p>
<p>Models must contain at least one random effect: either a smooth with non-zero
smoothing parameter, or a random effect specified in argument <code>random</code>.
</p>
<p>Note that the <code>gam</code> object part of the returned object is not complete in
the sense of having all the elements defined in gamObject and
does not inherit from <code>glm</code>: hence e.g. multi-model <code>anova</code> calls will not work.
</p>
<p>Linked smoothing parameters, adaptive smoothing and te terms are not supported.
</p>
<p>This routine is obviously less well tested than gamm.
</p>


<h3>Author(s)</h3>

<p> Simon N. Wood <a href="mailto:simon.wood@r-project.org">simon.wood@r-project.org</a></p>


<h3>References</h3>

<p>Bates D., M. Maechler, B. Bolker &amp; S. Walker (2013). lme4: Linear mixed-effects
models using Eigen and S4. <a href="https://cran.r-project.org/package=lme4">https://cran.r-project.org/package=lme4</a>
</p>
<p>Wood S.N., Scheipl, F. and Faraway, J.J. (2013/2011 online) Straightforward intermediate 
rank tensor product smoothing in mixed models. Statistics and Computing 23(3): 341-360
</p>
<p>Wood, S.N. (2004) Stable and efficient multiple smoothing parameter estimation for
generalized additive models. Journal of the American Statistical Association. 99:673-686
</p>
<p>Wood S.N. (2006) Generalized Additive Models: An Introduction with R. Chapman
and Hall/CRC Press.
</p>
<p>For more GAMM references see <code>gamm</code>
</p>
<p><a href="http://www.maths.bris.ac.uk/~sw15190/">http://www.maths.bris.ac.uk/~sw15190/</a>
</p>


<h3>See Also</h3>

<p>gam, gamm, gam.models, 
lmer, predict.gam, plot.gam,  
summary.gam, s, vis.gam
</p>


<h3>Examples</h3>

<pre><code class="language-R">## NOTE: most examples are flagged as 'do not run' simply to
## save time in package checking on CRAN.

###################################
## A simple additive mixed model...
###################################
library(gamm4)

set.seed(0) 
dat &lt;- gamSim(1,n=400,scale=2) ## simulate 4 term additive truth
## Now add 20 level random effect `fac'...
dat$fac &lt;- fac &lt;- as.factor(sample(1:20,400,replace=TRUE))
dat$y &lt;- dat$y + model.matrix(~fac-1)%*%rnorm(20)*.5

br &lt;- gamm4(y~s(x0)+x1+s(x2),data=dat,random=~(1|fac))
plot(br$gam,pages=1)

summary(br$gam) ## summary of gam
summary(br$mer) ## underlying mixed model
anova(br$gam) 

## compare gam fit of the same
bg &lt;- gam(y~s(x0)+x1+s(x2)+s(fac,bs="re"),
          data=dat,method="REML")
plot(bg,pages=1)
gam.vcomp(bg)

##########################
## Poisson example GAMM...
##########################
## simulate data...
x &lt;- runif(100)
fac &lt;- sample(1:20,100,replace=TRUE)
eta &lt;- x^2*3 + fac/20; fac &lt;- as.factor(fac)
y &lt;- rpois(100,exp(eta))

## fit model and examine it...
bp &lt;- gamm4(y~s(x),family=poisson,random=~(1|fac))
plot(bp$gam)
bp$mer

## Not run: 
#################################################################
## Add a factor to the linear predictor, to be modelled as random
## and make response Poisson. Again compare `gamm' and `gamm4'
#################################################################
set.seed(6)
dat &lt;- gamSim(1,n=400,scale=2) ## simulate 4 term additive truth
## add random effect...
g &lt;- as.factor(sample(1:20,400,replace=TRUE))
dat$f &lt;- dat$f + model.matrix(~ g-1)%*%rnorm(20)*2
dat$y &lt;- rpois(400,exp(dat$f/7+1))

b2&lt;-gamm(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,
         data=dat,random=list(g=~1))
plot(b2$gam,pages=1)

b2r&lt;-gamm4(y~s(x0)+s(x1)+s(x2)+s(x3),family=poisson,
         data=dat,random = ~ (1|g))

plot(b2r$gam,pages=1)

rm(dat)
vis.gam(b2r$gam,theta=35)


##################################
# Multivariate varying coefficient
# With crossed and nested random 
# effects.
##################################

## Start by simulating data...

f0 &lt;- function(x, z, sx = 0.3, sz = 0.4) {
            (pi^sx * sz) * (1.2 * exp(-(x - 0.2)^2/sx^2 - (z -
                0.3)^2/sz^2) + 0.8 * exp(-(x - 0.7)^2/sx^2 -
                (z - 0.8)^2/sz^2))
        }
f1 &lt;- function(x2) 2 * sin(pi * x2)
f2 &lt;- function(x2) exp(2 * x2) - 3.75887
f3 &lt;- function (x2) 0.2 * x2^11 * (10 * (1 - x2))^6 + 10 * (10 * x2)^3 *
            (1 - x2)^10

n &lt;- 1000

## first set up a continuous-within-group effect...

g &lt;- factor(sample(1:50,n,replace=TRUE)) ## grouping factor
x &lt;- runif(n)                       ## continuous covariate
X &lt;- model.matrix(~g-1)
mu &lt;- X%*%rnorm(50)*.5 + (x*X)%*%rnorm(50)

## now add nested factors...
a &lt;- factor(rep(1:20,rep(50,20)))
b &lt;- factor(rep(rep(1:25,rep(2,25)),rep(20,50)))
Xa &lt;- model.matrix(~a-1)
Xb &lt;- model.matrix(~a/b-a-1)
mu &lt;- mu + Xa%*%rnorm(20) + Xb%*%rnorm(500)*.5

## finally simulate the smooth terms
v &lt;- runif(n);w &lt;- runif(n);z &lt;- runif(n)
r &lt;- runif(n)
mu &lt;- mu + f0(v,w)*z*10 + f3(r) 

y &lt;- mu + rnorm(n)*2 ## response data

## First compare gamm and gamm4 on a reduced model

br &lt;- gamm4(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),random = ~ (1|a/b))

ba &lt;- gamm(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),random = list(a=~1,b=~1),method="REML")


par(mfrow=c(2,2))
plot(br$gam)

plot(ba$gam)

## now fit the full model

br &lt;- gamm4(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),random = ~ (x+0|g) + (1|g) + (1|a/b))

br$mer
br$gam
plot(br$gam)

## try a Poisson example, based on the same linear predictor...

lp &lt;- mu/5
y &lt;- rpois(exp(lp),exp(lp)) ## simulated response

## again compare gamm and gamm4 on reduced model

br &lt;- gamm4(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),family=poisson,random = ~ (1|a/b))

ba &lt;- gamm(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),family=poisson,random = list(a=~1,b=~1))

par(mfrow=c(2,2))
plot(br$gam)
plot(ba$gam)

## and now fit full version (very slow)...

br &lt;- gamm4(y ~ s(v,w,by=z) + s(r,k=20,bs="cr"),family=poisson,random = ~ (x|g) + (1|a/b))
br$mer
br$gam
plot(br$gam)


####################################
# Different smooths of x2 depending 
# on factor `fac'...
####################################
dat &lt;- gamSim(4)

br &lt;- gamm4(y ~ fac+s(x2,by=fac)+s(x0),data=dat)
plot(br$gam,pages=1)
summary(br$gam)


####################################
# Timing comparison with `gam'...  #                                      
####################################

dat &lt;- gamSim(1,n=600,dist="binary",scale=.33)

system.time(lr.fit0 &lt;- gam(y~s(x0)+s(x1)+s(x2),
            family=binomial,data=dat,method="ML"))

system.time(lr.fit &lt;- gamm4(y~s(x0)+s(x1)+s(x2),
            family=binomial,data=dat))

lr.fit0;lr.fit$gam
cor(fitted(lr.fit0),fitted(lr.fit$gam))

## plot model components with truth overlaid in red
op &lt;- par(mfrow=c(2,2))
fn &lt;- c("f0","f1","f2","f3");xn &lt;- c("x0","x1","x2","x3")
for (k in 1:3) {
  plot(lr.fit$gam,select=k)
  ff &lt;- dat[[fn[k]]];xx &lt;- dat[[xn[k]]]
  ind &lt;- sort.int(xx,index.return=TRUE)$ix
  lines(xx[ind],(ff-mean(ff))[ind]*.33,col=2)
}
par(op)

## End(Not run)

######################################
## A "signal" regression example, in
## which a univariate response depends
## on functional predictors.
######################################

## simulate data first....

rf &lt;- function(x=seq(0,1,length=100)) {
## generates random functions...
  m &lt;- ceiling(runif(1)*5) ## number of components
  f &lt;- x*0;
  mu &lt;- runif(m,min(x),max(x));sig &lt;- (runif(m)+.5)*(max(x)-min(x))/10
  for (i in 1:m) f &lt;- f+ dnorm(x,mu[i],sig[i])
  f
}

x &lt;- seq(0,1,length=100) ## evaluation points

## example functional predictors...
par(mfrow=c(3,3));for (i in 1:9) plot(x,rf(x),type="l",xlab="x")

## simulate 200 functions and store in rows of L...
L &lt;- matrix(NA,200,100) 
for (i in 1:200) L[i,] &lt;- rf()  ## simulate the functional predictors

f2 &lt;- function(x) { ## the coefficient function
  (0.2*x^11*(10*(1-x))^6+10*(10*x)^3*(1-x)^10)/10 
}

f &lt;- f2(x) ## the true coefficient function

y &lt;- L%*%f + rnorm(200)*20 ## simulated response data

## Now fit the model E(y) = L%*%f(x) where f is a smooth function.
## The summation convention is used to evaluate smooth at each value
## in matrix X to get matrix F, say. Then rowSum(L*F) gives E(y).

## create matrix of eval points for each function. Note that
## `smoothCon' is smart and will recognize the duplication...
X &lt;- matrix(x,200,100,byrow=TRUE) 

## compare `gam' and `gamm4' this time

b &lt;- gam(y~s(X,by=L,k=20),method="REML")
br &lt;- gamm4(y~s(X,by=L,k=20))
par(mfrow=c(2,1))
plot(b,shade=TRUE);lines(x,f,col=2)
plot(br$gam,shade=TRUE);lines(x,f,col=2)

</code></pre>


</div>