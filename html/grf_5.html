<div class="container">

<table style="width: 100%;"><tr>
<td>best_linear_projection</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimate the best linear projection of a conditional average treatment effect.</h2>

<h3>Description</h3>

<p>Let tau(Xi) = E[Y(1) - Y(0) | X = Xi] be the CATE, and Ai be a vector of user-provided
covariates. This function provides a (doubly robust) fit to the linear model tau(Xi) ~ beta_0 + Ai * beta.
</p>


<h3>Usage</h3>

<pre><code class="language-R">best_linear_projection(
  forest,
  A = NULL,
  subset = NULL,
  debiasing.weights = NULL,
  compliance.score = NULL,
  num.trees.for.weights = 500,
  vcov.type = "HC3",
  target.sample = c("all", "overlap")
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>forest</code></td>
<td>
<p>The trained forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>A</code></td>
<td>
<p>The covariates we want to project the CATE onto.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p>Specifies subset of the training examples over which we
estimate the ATE. WARNING: For valid statistical performance,
the subset should be defined only using features Xi, not using
the treatment Wi or the outcome Yi.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>debiasing.weights</code></td>
<td>
<p>A vector of length n (or the subset length) of debiasing weights.
If NULL (default) these are obtained via the appropriate doubly robust score
construction, e.g., in the case of causal_forests with a binary treatment, they
are obtained via inverse-propensity weighting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compliance.score</code></td>
<td>
<p>Only used with instrumental forests. An estimate of the causal
effect of Z on W, i.e., Delta(X) = E[W | X, Z = 1] - E[W | X, Z = 0],
which can then be used to produce debiasing.weights. If not provided,
this is estimated via an auxiliary causal forest.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num.trees.for.weights</code></td>
<td>
<p>In some cases (e.g., with causal forests with a continuous
treatment), we need to train auxiliary forests to learn debiasing weights.
This is the number of trees used for this task. Note: this argument is only
used when debiasing.weights = NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vcov.type</code></td>
<td>
<p>Optional covariance type for standard errors. The possible
options are HC0, ..., HC3. The default is "HC3", which is recommended in small
samples and corresponds to the "shortcut formula" for the jackknife
(see MacKinnon &amp; White for more discussion, and Cameron &amp; Miller for a review).
For large data sets with clusters, "HC0" or "HC1" are significantly faster to compute.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target.sample</code></td>
<td>
<p>Which sample to compute the BLP over. The default is "all".
Option "overlap" uses weights equal to e(X)(1 - e(X)), where e(x) are estimates of
the propensity score.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Procedurally, we do so by regressing doubly robust scores derived from the
forest against the Ai. Note the covariates Ai may consist of a subset of the Xi,
or they may be distinct. The case of the null model tau(Xi) ~ beta_0 is equivalent
to fitting an average treatment effect via AIPW.
</p>
<p>In the event the treatment is continuous the inverse-propensity weight component of the
double robust scores are replaced with a component based on a forest based
estimate of Var[Wi | Xi = x]. These weights can also be passed manually by specifying
debiasing.weights.
</p>


<h3>Value</h3>

<p>An estimate of the best linear projection, along with coefficient standard errors.
</p>


<h3>References</h3>

<p>Cameron, A. Colin, and Douglas L. Miller. "A practitioner's guide to
cluster-robust inference." Journal of Human Resources 50, no. 2 (2015): 317-372.
</p>
<p>Cui, Yifan, Michael R. Kosorok, Erik Sverdrup, Stefan Wager, and Ruoqing Zhu.
"Estimating Heterogeneous Treatment Effects with Right-Censored Data via Causal Survival Forests."
Journal of the Royal Statistical Society: Series B, 85(2), 2023.
</p>
<p>MacKinnon, James G., and Halbert White. "Some heteroskedasticity-consistent
covariance matrix estimators with improved finite sample properties."
Journal of Econometrics 29.3 (1985): 305-325.
</p>
<p>Semenova, Vira, and Victor Chernozhukov. "Debiased Machine Learning of
Conditional Average Treatment Effects and Other Causal Functions".
The Econometrics Journal 24.2 (2021).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
n &lt;- 800
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n, p)
W &lt;- rbinom(n, 1, 0.25 + 0.5 * (X[, 1] &gt; 0))
Y &lt;- pmax(X[, 1], 0) * W + X[, 2] + pmin(X[, 3], 0) + rnorm(n)
forest &lt;- causal_forest(X, Y, W)
best_linear_projection(forest, X[,1:2])


</code></pre>


</div>