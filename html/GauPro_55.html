<div class="container">

<table style="width: 100%;"><tr>
<td>LatentFactorKernel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Latent Factor Kernel R6 class</h2>

<h3>Description</h3>

<p>Latent Factor Kernel R6 class
</p>
<p>Latent Factor Kernel R6 class
</p>


<h3>Usage</h3>

<pre><code class="language-R">k_LatentFactorKernel(
  s2 = 1,
  D,
  nlevels,
  xindex,
  latentdim,
  p_lower = 0,
  p_upper = 1,
  p_est = TRUE,
  s2_lower = 1e-08,
  s2_upper = 1e+08,
  s2_est = TRUE,
  useC = TRUE,
  offdiagequal = 1 - 1e-06
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>s2</code></td>
<td>
<p>Initial variance</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>Number of input dimensions of data</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlevels</code></td>
<td>
<p>Number of levels for the factor</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>xindex</code></td>
<td>
<p>Index of X to use the kernel on</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>latentdim</code></td>
<td>
<p>Dimension of embedding space</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_lower</code></td>
<td>
<p>Lower bound for p</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_upper</code></td>
<td>
<p>Upper bound for p</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_est</code></td>
<td>
<p>Should p be estimated?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s2_lower</code></td>
<td>
<p>Lower bound for s2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s2_upper</code></td>
<td>
<p>Upper bound for s2</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s2_est</code></td>
<td>
<p>Should s2 be estimated?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>useC</code></td>
<td>
<p>Should C code used? Much faster.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>offdiagequal</code></td>
<td>
<p>What should offdiagonal values be set to when the
indices are the same? Use to avoid decomposition errors, similar to
adding a nugget.</p>
</td>
</tr>
</table>
<h3>Format</h3>

<p><code>R6Class</code> object.
</p>


<h3>Details</h3>

<p>Used for factor variables, a single dimension.
Each level of the factor gets mapped into a latent space,
then the distances in that space determine their correlations.
</p>


<h3>Value</h3>

<p>Object of <code>R6Class</code> with methods for fitting GP model.
</p>


<h3>Super class</h3>

<p><code>GauPro::GauPro_kernel</code> -&gt; <code>GauPro_kernel_LatentFactorKernel</code>
</p>


<h3>Public fields</h3>

<div class="r6-fields">

<dl>
<dt><code>p</code></dt>
<dd>
<p>Parameter for correlation</p>
</dd>
<dt><code>p_est</code></dt>
<dd>
<p>Should p be estimated?</p>
</dd>
<dt><code>p_lower</code></dt>
<dd>
<p>Lower bound of p</p>
</dd>
<dt><code>p_upper</code></dt>
<dd>
<p>Upper bound of p</p>
</dd>
<dt><code>p_length</code></dt>
<dd>
<p>length of p</p>
</dd>
<dt><code>s2</code></dt>
<dd>
<p>variance</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 estimated?</p>
</dd>
<dt><code>logs2</code></dt>
<dd>
<p>Log of s2</p>
</dd>
<dt><code>logs2_lower</code></dt>
<dd>
<p>Lower bound of logs2</p>
</dd>
<dt><code>logs2_upper</code></dt>
<dd>
<p>Upper bound of logs2</p>
</dd>
<dt><code>xindex</code></dt>
<dd>
<p>Index of the factor (which column of X)</p>
</dd>
<dt><code>nlevels</code></dt>
<dd>
<p>Number of levels for the factor</p>
</dd>
<dt><code>latentdim</code></dt>
<dd>
<p>Dimension of embedding space</p>
</dd>
<dt><code>pf_to_p_log</code></dt>
<dd>
<p>Logical vector used to convert pf to p</p>
</dd>
<dt><code>p_to_pf_inds</code></dt>
<dd>
<p>Vector of indexes used to convert p to pf</p>
</dd>
<dt><code>offdiagequal</code></dt>
<dd>
<p>What should offdiagonal values be set to when the
indices are the same? Use to avoid decomposition errors, similar to
adding a nugget.</p>
</dd>
</dl>
</div>


<h3>Methods</h3>



<h4>Public methods</h4>


<ul>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-new"><code>LatentFactorKernel$new()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-k"><code>LatentFactorKernel$k()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-kone"><code>LatentFactorKernel$kone()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-dC_dparams"><code>LatentFactorKernel$dC_dparams()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-C_dC_dparams"><code>LatentFactorKernel$C_dC_dparams()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-dC_dx"><code>LatentFactorKernel$dC_dx()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-param_optim_start"><code>LatentFactorKernel$param_optim_start()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-param_optim_start0"><code>LatentFactorKernel$param_optim_start0()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-param_optim_lower"><code>LatentFactorKernel$param_optim_lower()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-param_optim_upper"><code>LatentFactorKernel$param_optim_upper()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-set_params_from_optim"><code>LatentFactorKernel$set_params_from_optim()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-p_to_pf"><code>LatentFactorKernel$p_to_pf()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-s2_from_params"><code>LatentFactorKernel$s2_from_params()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-plotLatent"><code>LatentFactorKernel$plotLatent()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-print"><code>LatentFactorKernel$print()</code></a>
</p>
</li>
<li> <p><a href="#method-GauPro_kernel_LatentFactorKernel-clone"><code>LatentFactorKernel$clone()</code></a>
</p>
</li>
</ul>
<details open><summary>Inherited methods</summary><ul>
<li><span class="pkg-link" data-pkg="GauPro" data-topic="GauPro_kernel" data-id="plot"><a href="../../GauPro/html/GauPro_kernel.html#method-GauPro_kernel-plot"><code>GauPro::GauPro_kernel$plot()</code></a></span></li>
</ul></details><hr>
<a id="method-GauPro_kernel_LatentFactorKernel-new"></a>



<h4>Method <code>new()</code>
</h4>

<p>Initialize kernel object
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$new(
  s2 = 1,
  D,
  nlevels,
  xindex,
  latentdim,
  p_lower = 0,
  p_upper = 1,
  p_est = TRUE,
  s2_lower = 1e-08,
  s2_upper = 1e+08,
  s2_est = TRUE,
  useC = TRUE,
  offdiagequal = 1 - 1e-06
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>s2</code></dt>
<dd>
<p>Initial variance</p>
</dd>
<dt><code>D</code></dt>
<dd>
<p>Number of input dimensions of data</p>
</dd>
<dt><code>nlevels</code></dt>
<dd>
<p>Number of levels for the factor</p>
</dd>
<dt><code>xindex</code></dt>
<dd>
<p>Index of X to use the kernel on</p>
</dd>
<dt><code>latentdim</code></dt>
<dd>
<p>Dimension of embedding space</p>
</dd>
<dt><code>p_lower</code></dt>
<dd>
<p>Lower bound for p</p>
</dd>
<dt><code>p_upper</code></dt>
<dd>
<p>Upper bound for p</p>
</dd>
<dt><code>p_est</code></dt>
<dd>
<p>Should p be estimated?</p>
</dd>
<dt><code>s2_lower</code></dt>
<dd>
<p>Lower bound for s2</p>
</dd>
<dt><code>s2_upper</code></dt>
<dd>
<p>Upper bound for s2</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Should s2 be estimated?</p>
</dd>
<dt><code>useC</code></dt>
<dd>
<p>Should C code used? Much faster.</p>
</dd>
<dt><code>offdiagequal</code></dt>
<dd>
<p>What should offdiagonal values be set to when the
indices are the same? Use to avoid decomposition errors, similar to
adding a nugget.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-k"></a>



<h4>Method <code>k()</code>
</h4>

<p>Calculate covariance between two points
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$k(x, y = NULL, p = self$p, s2 = self$s2, params = NULL)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x</code></dt>
<dd>
<p>vector.</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>vector, optional. If excluded, find correlation
of x with itself.</p>
</dd>
<dt><code>p</code></dt>
<dd>
<p>Correlation parameters.</p>
</dd>
<dt><code>s2</code></dt>
<dd>
<p>Variance parameter.</p>
</dd>
<dt><code>params</code></dt>
<dd>
<p>parameters to use instead of beta and s2.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-kone"></a>



<h4>Method <code>kone()</code>
</h4>

<p>Find covariance of two points
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$kone(
  x,
  y,
  pf,
  s2,
  isdiag = TRUE,
  offdiagequal = self$offdiagequal
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>x</code></dt>
<dd>
<p>vector</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>vector</p>
</dd>
<dt><code>pf</code></dt>
<dd>
<p>correlation parameters on regular scale, includes zeroes
for first level.</p>
</dd>
<dt><code>s2</code></dt>
<dd>
<p>Variance parameter</p>
</dd>
<dt><code>isdiag</code></dt>
<dd>
<p>Is this on the diagonal of the covariance?</p>
</dd>
<dt><code>offdiagequal</code></dt>
<dd>
<p>What should offdiagonal values be set to when the
indices are the same? Use to avoid decomposition errors, similar to
adding a nugget.</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-dC_dparams"></a>



<h4>Method <code>dC_dparams()</code>
</h4>

<p>Derivative of covariance with respect to parameters
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$dC_dparams(params = NULL, X, C_nonug, C, nug)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>params</code></dt>
<dd>
<p>Kernel parameters</p>
</dd>
<dt><code>X</code></dt>
<dd>
<p>matrix of points in rows</p>
</dd>
<dt><code>C_nonug</code></dt>
<dd>
<p>Covariance without nugget added to diagonal</p>
</dd>
<dt><code>C</code></dt>
<dd>
<p>Covariance with nugget</p>
</dd>
<dt><code>nug</code></dt>
<dd>
<p>Value of nugget</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-C_dC_dparams"></a>



<h4>Method <code>C_dC_dparams()</code>
</h4>

<p>Calculate covariance matrix and its derivative
with respect to parameters
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$C_dC_dparams(params = NULL, X, nug)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>params</code></dt>
<dd>
<p>Kernel parameters</p>
</dd>
<dt><code>X</code></dt>
<dd>
<p>matrix of points in rows</p>
</dd>
<dt><code>nug</code></dt>
<dd>
<p>Value of nugget</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-dC_dx"></a>



<h4>Method <code>dC_dx()</code>
</h4>

<p>Derivative of covariance with respect to X
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$dC_dx(XX, X, ...)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>XX</code></dt>
<dd>
<p>matrix of points</p>
</dd>
<dt><code>X</code></dt>
<dd>
<p>matrix of points to take derivative with respect to</p>
</dd>
<dt><code>...</code></dt>
<dd>
<p>Additional args, not used</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-param_optim_start"></a>



<h4>Method <code>param_optim_start()</code>
</h4>

<p>Starting point for parameters for optimization
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$param_optim_start(
  jitter = F,
  y,
  p_est = self$p_est,
  s2_est = self$s2_est
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>jitter</code></dt>
<dd>
<p>Should there be a jitter?</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>Output</p>
</dd>
<dt><code>p_est</code></dt>
<dd>
<p>Is p being estimated?</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-param_optim_start0"></a>



<h4>Method <code>param_optim_start0()</code>
</h4>

<p>Starting point for parameters for optimization
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$param_optim_start0(
  jitter = F,
  y,
  p_est = self$p_est,
  s2_est = self$s2_est
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>jitter</code></dt>
<dd>
<p>Should there be a jitter?</p>
</dd>
<dt><code>y</code></dt>
<dd>
<p>Output</p>
</dd>
<dt><code>p_est</code></dt>
<dd>
<p>Is p being estimated?</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-param_optim_lower"></a>



<h4>Method <code>param_optim_lower()</code>
</h4>

<p>Lower bounds of parameters for optimization
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$param_optim_lower(p_est = self$p_est, s2_est = self$s2_est)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>p_est</code></dt>
<dd>
<p>Is p being estimated?</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-param_optim_upper"></a>



<h4>Method <code>param_optim_upper()</code>
</h4>

<p>Upper bounds of parameters for optimization
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$param_optim_upper(p_est = self$p_est, s2_est = self$s2_est)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>p_est</code></dt>
<dd>
<p>Is p being estimated?</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-set_params_from_optim"></a>



<h4>Method <code>set_params_from_optim()</code>
</h4>

<p>Set parameters from optimization output
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$set_params_from_optim(
  optim_out,
  p_est = self$p_est,
  s2_est = self$s2_est
)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>optim_out</code></dt>
<dd>
<p>Output from optimization</p>
</dd>
<dt><code>p_est</code></dt>
<dd>
<p>Is p being estimated?</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-p_to_pf"></a>



<h4>Method <code>p_to_pf()</code>
</h4>

<p>Convert p (short parameter vector) to pf (long parameter
vector with zeros).
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$p_to_pf(p)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>p</code></dt>
<dd>
<p>Parameter vector</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-s2_from_params"></a>



<h4>Method <code>s2_from_params()</code>
</h4>

<p>Get s2 from params vector
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$s2_from_params(params, s2_est = self$s2_est)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>params</code></dt>
<dd>
<p>parameter vector</p>
</dd>
<dt><code>s2_est</code></dt>
<dd>
<p>Is s2 being estimated?</p>
</dd>
</dl>
</div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-plotLatent"></a>



<h4>Method <code>plotLatent()</code>
</h4>

<p>Plot the points in the latent space
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$plotLatent()</pre></div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-print"></a>



<h4>Method <code>print()</code>
</h4>

<p>Print this object
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$print()</pre></div>


<hr>
<a id="method-GauPro_kernel_LatentFactorKernel-clone"></a>



<h4>Method <code>clone()</code>
</h4>

<p>The objects of this class are cloneable with this method.
</p>


<h5>Usage</h5>

<div class="r"><pre>LatentFactorKernel$clone(deep = FALSE)</pre></div>



<h5>Arguments</h5>

<div class="arguments">

<dl>
<dt><code>deep</code></dt>
<dd>
<p>Whether to make a deep clone.</p>
</dd>
</dl>
</div>




<h3>References</h3>

<p>https://stackoverflow.com/questions/27086195/linear-index-upper-triangular-matrix
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Create a new kernel for a single factor with 5 levels,
#  mapped into two latent dimensions.
kk &lt;- LatentFactorKernel$new(D=1, nlevels=5, xindex=1, latentdim=2)
# Random initial parameter values
kk$p
# Plots to understand
kk$plotLatent()
kk$plot()


# 5 levels, 1/4 are similar and 2/3/5 are similar
n &lt;- 30
x &lt;- matrix(sample(1:5, n, TRUE))
y &lt;- c(ifelse(x == 1 | x == 4, 4, -3) + rnorm(n,0,.1))
plot(c(x), y)
m5 &lt;- GauPro_kernel_model$new(
  X=x, Z=y,
  kernel=LatentFactorKernel$new(D=1, nlevels = 5, xindex = 1, latentdim = 2))
m5$kernel$p
# We should see 1/4 and 2/3/4 in separate clusters
m5$kernel$plotLatent()

if (requireNamespace("dplyr", quietly=TRUE)) {
library(dplyr)
n &lt;- 20
X &lt;- cbind(matrix(runif(n,2,6), ncol=1),
           matrix(sample(1:2, size=n, replace=TRUE), ncol=1))
X &lt;- rbind(X, c(3.3,3), c(3.7,3))
n &lt;- nrow(X)
Z &lt;- X[,1] - (4-X[,2])^2 + rnorm(n,0,.1)
plot(X[,1], Z, col=X[,2])
tibble(X=X, Z) %&gt;% arrange(X,Z)
k2a &lt;- IgnoreIndsKernel$new(k=Gaussian$new(D=1), ignoreinds = 2)
k2b &lt;- LatentFactorKernel$new(D=2, nlevels=3, xind=2, latentdim=2)
k2 &lt;- k2a * k2b
k2b$p_upper &lt;- .65*k2b$p_upper
gp &lt;- GauPro_kernel_model$new(X=X, Z=Z, kernel = k2, verbose = 5,
  nug.min=1e-2, restarts=1)
gp$kernel$k1$kernel$beta
gp$kernel$k2$p
gp$kernel$k(x = gp$X)
tibble(X=X, Z=Z, pred=gp$predict(X)) %&gt;% arrange(X, Z)
tibble(X=X[,2], Z) %&gt;% group_by(X) %&gt;% summarize(n=n(), mean(Z))
curve(gp$pred(cbind(matrix(x,ncol=1),1)),2,6, ylim=c(min(Z), max(Z)))
points(X[X[,2]==1,1], Z[X[,2]==1])
curve(gp$pred(cbind(matrix(x,ncol=1),2)), add=TRUE, col=2)
points(X[X[,2]==2,1], Z[X[,2]==2], col=2)
curve(gp$pred(cbind(matrix(x,ncol=1),3)), add=TRUE, col=3)
points(X[X[,2]==3,1], Z[X[,2]==3], col=3)
legend(legend=1:3, fill=1:3, x="topleft")
# See which points affect (5.5, 3 themost)
data.frame(X, cov=gp$kernel$k(X, c(5.5,3))) %&gt;% arrange(-cov)
plot(k2b)
}
</code></pre>


</div>