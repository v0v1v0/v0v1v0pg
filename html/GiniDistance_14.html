<div class="container">

<table style="width: 100%;"><tr>
<td>Kgmd</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Kernel Gini Mean Difference Statistics</h2>

<h3>Description</h3>

<p>Computes Kernel Gini mean difference statistics,
in which Xs are quantitative, sigma is kernel standard deviation, alpha is an exponent on the Euclidean distance and returns the kernel Gini mean difference.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  Kgmd(x, sigma)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> data </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p> kernel standard deviation</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><code>Kgmd</code> compute kernel Gini mean difference statistics for data.
It is a self-contained R function dealing with both univariate and multivariate data. 
</p>
<p>The sample size (number of rows) of the data must agree with the length of the label vector, and samples must not contain missing values. Argument
<code>x</code>, is treated as data.
</p>
<p>Energy distance based statistics naturally generalizes from a Euclidean space to metric spaces (<cite>Lyons13</cite>). By using a positive definite kernel (Mercer kernel) (<cite>Mercer1909</cite>), distributions are mapped into a RKHS (<cite>Smola07</cite>) with a kernel induced distance. Hence one can extend energy distances to a much richer family of statistics defined in RKHS (<cite>Sejdinovic13</cite>). Let <code class="reqn">\kappa: R^q \times R^q \rightarrow R</code> be a Mercer kernel (<cite>Mercer1909</cite>). There is an associated RKHS <code class="reqn">H_{\kappa}</code> of real functions on <code class="reqn">R^q</code> with reproducing kernel <code class="reqn">\kappa</code>, where the function <code class="reqn">d: {R}^q \times {R}^q \rightarrow{{R}}</code> defines a distance in <code class="reqn">\mathcal{H}_\kappa</code>,
</p>
<p style="text-align: center;"><code class="reqn">
  d_\kappa(x,x') = \sqrt{\kappa(x,x) + \kappa(x',x') - 2 \kappa(x,x')}.</code>
</p>

<p>Here <code>Kgcov</code> is defined as Gini distance covariance between <code class="reqn">x</code> and <code class="reqn">\mathrm{rank}(x)</code>. 
</p>


<h3>Value</h3>

<p><code>Kgmd</code> returns the sample Kernel Gini distance
</p>


<h3>References</h3>

<p>Lyons, R. (2013). Distance covariance in metric spaces. The Annals of Probability, 41 (5), 3284-3305. 
</p>


<h3>See Also</h3>

<p><code>gCov</code>  <code>gCor</code>  <code>dCor</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">  x&lt;-iris[,1]
  Kgmd(x, sigma=1)
</code></pre>


</div>