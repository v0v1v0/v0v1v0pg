<div class="container">

<table style="width: 100%;"><tr>
<td>glmmLasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Variable Selection for Generalized Linear Mixed Models by L1-Penalized Estimation.</h2>

<h3>Description</h3>

<p>A variable selection approach for generalized linear mixed models by L1-penalized estimation is provided.
</p>


<h3>Usage</h3>

<pre><code class="language-R">glmmLasso(fix=formula, rnd=formula, data, lambda, family = gaussian(link="identity"), 
          switch.NR=FALSE, final.re=FALSE, control = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>fix</code></td>
<td>
<p>a two-sided linear formula object describing the
fixed-effects part of the model, with the response on the left of a
<code>~</code> operator and the terms, separated by <code>+</code> operators, on
the right. For categorical covariables use <code>as.factor(.)</code> in the formula. 
Note, that the corresponding dummies are treated as a group and are updated blockwise</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rnd</code></td>
<td>
<p>a two-sided linear formula object describing the
random-effects part of the model, with the grouping factor on the left of a
<code>~</code> operator and the random terms, separated by <code>+</code> operators, on
the right; aternatively, the random effects design matrix can be given directly (with suitable column names). If set to NULL, no random effects are included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>the data frame containing the variables named in
<code>formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>the penalty parameter that controls the shrinkage of fixed terms and controls the variable selection.
The optimal penalty parameter is a tuning parameter of the procedure that has to be determined, 
e.g. by use of information criteria or cross validation. (See details or the quick demo for an example.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>

<p>a GLM family, see <code>glm</code> and
<code>family</code>. Also ordinal response models can be fitted: use <code>family=acat()</code> and <code>family=cumulative()</code> for the fitting of an adjacent category or cumulative model, respectively. If <code>family</code> is missing then a
linear mixed model is fit; otherwise a generalized linear mixed
model is fit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>switch.NR</code></td>
<td>
<p>logical. Should the algorithm swith to a Newton-Raphson update step, when reasonable? Default is FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>final.re</code></td>
<td>
<p>logical. Should the final Fisher scoring re-estimation be performed? Default is FALSE.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control</code></td>
<td>
<p>a list of control values for the estimation algorithm to replace the default values returned by the function <code>glmmLassoControl</code>. Defaults to an empty list.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The <code>glmmLasso</code> algorithm is a gradient ascent algorithm designed for generalized linear mixed models, which incorporates variable selection by L1-penalized estimation. In a final re-estimation step a model the includes only the variables corresponding to the non-zero fixed effects is fitted by simple Fisher scoring. For both the main algorithm as well as for the final re-estimation Fisher scoring 
two methods for the computation of the random-effects variance-covariance parameter estimates can be chosen, an EM-type estimate and an REML-type estimate.
</p>

<table>
<tr>
<td style="text-align: left;">
Package: </td>
<td style="text-align: left;"> glmmLasso</td>
</tr>
<tr>
<td style="text-align: left;">
Type: </td>
<td style="text-align: left;"> Package</td>
</tr>
<tr>
<td style="text-align: left;">
Version: </td>
<td style="text-align: left;"> 1.6.3</td>
</tr>
<tr>
<td style="text-align: left;">
Date: </td>
<td style="text-align: left;"> 2023-08-19</td>
</tr>
<tr>
<td style="text-align: left;">
License: </td>
<td style="text-align: left;"> GPL-2</td>
</tr>
<tr>
<td style="text-align: left;">
LazyLoad: </td>
<td style="text-align: left;"> yes</td>
</tr>
<tr>
<td style="text-align: left;">
</td>
</tr>
</table>
<p>for loading a dataset type data(nameofdataset)
</p>


<h3>Value</h3>

<p>Generic functions such as <code>print</code>, <code>predict</code>, <code>plot</code> and <code>summary</code> have methods to show the results of the fit.
The <code>predict</code> function returns predictions on the scale of the response variable and uses also estimates of random effects for prediction, if possible (i.e. for known subjects of the grouping factor). The <code>plot</code> function 
plots the smooth terms, if any have been specified. 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>a list containing an image of the <code>glmmLasso</code> call that produced the object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coefficients</code></td>
<td>
<p>a vector containing the estimated fixed effects. By default the covariates are standardized/centered within the procedure (see <code>glmmLassoControl</code>), so the coefficients are transformed back to the original scale.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smooth</code></td>
<td>
<p>a vector containing the estimated spline coefficients, if smooth terms have been specified.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ranef</code></td>
<td>
<p>a vector containing the estimated random effects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>StdDev</code></td>
<td>
<p>a scalar or matrix containing the estimates of the random effects standard deviation or variance-covariance parameters, respectively.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>a vector of fitted values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>phi</code></td>
<td>
<p>estimated scale parameter, if <code>overdispersion=TRUE</code> is used. Otherwise, it is equal to one.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Deltamatrix</code></td>
<td>
<p>a matrix containing the estimates of fixed and random effects (columns) for each iteration (rows) of the main algorithm (i.e. before the final re-estimation step is performed, see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Q_long</code></td>
<td>
<p>a list containing the estimates of the random effects variance-covariance parameters for each iteration of the main algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fixerror</code></td>
<td>
<p>a vector with standrad errors for the fixed effects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ranerror</code></td>
<td>
<p>a vector with standrad errors for the random effects.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aic</code></td>
<td>
<p>AIC: The negative of twice the log-likelihood plus twice the corresponding degrees of freedom. The corresponding degrees of freedom are determined by the sum of nonzero coefficients corresponding to fixed
effects plus the number of random effects covariance parameters that have to be  estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bic</code></td>
<td>
<p>BIC: The negative of twice the log-likelihood plus the product of the logarithm of the overall number of observations
with the corresponding degrees of freedom. The corresponding degrees of freedom are determined by the sum of nonzero coefficients corresponding to fixed
effects plus the number of random effects covariance parameters that have to be  estimated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>conv.step</code></td>
<td>
<p>number of iterations until the main algorithm has converged.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Andreas Groll  <a href="mailto:groll@statistik.tu-dortmund.de">groll@statistik.tu-dortmund.de</a>
</p>


<h3>References</h3>

<p>Groll, A. and G. Tutz (2014). 
Variable selection for generalized linear mixed models by
L1-penalized estimation. <em>Statistics and Computing</em> 24(2), 137–154.
</p>
<p>Goeman, J. J. (2010). L1 Penalized Estimation in the Cox Proportional Hazards Model.
<em>Biometrical Journal</em> 52, 70–84.
</p>


<h3>See Also</h3>

<p><code>glmmLassoControl,soccer,knee</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
data("soccer")

soccer[,c(4,5,9:16)]&lt;-scale(soccer[,c(4,5,9:16)],center=TRUE,scale=TRUE)
soccer&lt;-data.frame(soccer)

## linear mixed model
lm1 &lt;- glmmLasso(points ~ transfer.spendings + ave.unfair.score 
       + ball.possession + tackles 
       + ave.attend + sold.out, rnd = list(team=~1), 
       lambda=50, data = soccer)
      
summary(lm1)

## similar linear model without random effects
lm1b &lt;- glmmLasso(points ~ transfer.spendings + ave.unfair.score 
       + ball.possession + tackles 
       + ave.attend + sold.out, rnd = NULL, 
       lambda=50, data = soccer)
      
summary(lm1b)


## linear mixed model with slope on ave.attend;  
## the coefficient of ave.attend is not penalized;
lm2 &lt;- glmmLasso(points~transfer.spendings + ave.unfair.score 
      + ball.possession + tackles + ave.attend 
       + sold.out, rnd = list(team=~1 + ave.attend), lambda=10, 
       data = soccer, control = list(index=c(1,2,3,4,NA,5), 
       method="REML",print.iter=TRUE))

summary(lm2)

## linear mixed model with categorical covariates
## and final Fisher scoring re-estimation step
lm3 &lt;- glmmLasso(points ~ transfer.spendings + as.factor(red.card)  
       + as.factor(yellow.red.card) + ball.possession 
       + tackles + ave.attend + sold.out, rnd = list(team=~1), 
       data = soccer, lambda=100, final.re=TRUE,
       control = list(print.iter=TRUE,print.iter.final=TRUE))

summary(lm3)

## generalized linear mixed model
## with starting values
glm1 &lt;- glmmLasso(points~transfer.spendings  
        + ave.unfair.score + sold.out 
        + tackles + ave.attend + ball.possession, rnd = list(team=~1),  
        family = poisson(link = log), data = soccer, lambda=100, 
        control = list(print.iter=TRUE,start=c(1,rep(0,29)),q_start=0.7)) 

summary(glm1)

## generalized linear mixed model with a smooth term
glm2 &lt;- glmmLasso(points~ + ave.unfair.score + ave.attend 
        + ball.possession + tackles  + sold.out, 
        rnd = list(team=~1),  family = poisson(link = log), 
        data = soccer, lambda=100, control = list(smooth=
        list(formula=~-1 + transfer.spendings, nbasis=7, 
        spline.degree=3, diff.ord=2, penal=5), 
        print.iter=TRUE)) 
 
summary(glm2)
 
plot(glm2,plot.data=FALSE)        

#####################
#####################
#####################

data(knee)

knee[,c(2,4:6)]&lt;-scale(knee[,c(2,4:6)],center=TRUE,scale=TRUE)
knee&lt;-data.frame(knee)

## fit cumulative model
glm3 &lt;- glmmLasso(pain ~ time + th + age + sex, rnd = NULL,  
        family = cumulative(), data = knee, lambda=10,
        control=list(print.iter=TRUE)) 

summary(glm3)

## fit adjacent category model
glm4 &lt;- glmmLasso(pain ~ time + th + age + sex, rnd = NULL,  
        family = acat(), data = knee, lambda=10,
        control=list(print.iter=TRUE)) 

summary(glm4)


# see also demo("glmmLasso-soccer")

## End(Not run)</code></pre>


</div>