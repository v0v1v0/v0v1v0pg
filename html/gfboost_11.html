<div class="container">

<table style="width: 100%;"><tr>
<td>RejStep</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>CMB validation step</h2>

<h3>Description</h3>

<p>Validation step to combine different SingBoost models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">RejStep(
  D,
  nsing,
  Bsing = 1,
  ind,
  sing = FALSE,
  singfam = Gaussian(),
  evalfam = Gaussian(),
  M = 10,
  m_iter = 100,
  kap = 0.1,
  LS = FALSE,
  best = 1
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>D</code></td>
<td>
<p>Data matrix. Has to be an <code class="reqn">n \times (p+1)-</code>dimensional data frame in the format <code class="reqn">(X,Y)</code>. The <code class="reqn">X-</code>part must not
contain an intercept column containing only ones since this column will be added automatically.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nsing</code></td>
<td>
<p>Number of observations (rows) used for the SingBoost submodels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Bsing</code></td>
<td>
<p>Number of subsamples based on which the SingBoost models are validated. Default is 1. Not to confuse with parameter <code>B</code> for the Stability Selection.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind</code></td>
<td>
<p>Vector with indices for dividing the data set into training and validation data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sing</code></td>
<td>
<p>If <code>sing=FALSE</code> and the <code>singfam</code> family is a standard Boosting family that is contained in the package
<code>mboost</code>, the CMB aggregation procedure is executed for the corresponding standard Boosting models.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>singfam</code></td>
<td>
<p>A SingBoost family. The SingBoost models are trained based on the corresponding loss function. Default is <code>Gaussian()</code> (squared loss).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>evalfam</code></td>
<td>
<p>A SingBoost family. The SingBoost models are validated according to the corresponding loss function. Default is <code>Gaussian()</code> (squared loss).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>
<p>An integer between 2 and <code>m_iter</code>. Indicates that in every <code class="reqn">M-</code>th iteration, a singular iteration will be
performed. Default is 10.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m_iter</code></td>
<td>
<p>Number of SingBoost iterations. Default is 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>kap</code></td>
<td>
<p>Learning rate (step size). Must be a real number in <code class="reqn">]0,1]</code>. Default is 0.1 It is recommended to use
a value smaller than 0.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>LS</code></td>
<td>
<p>If a <code>singfamily</code> object that is already provided by <code>mboost</code> is used, the respective Boosting algorithm
will be performed in the singular iterations if <code>Ls</code> is set to <code>TRUE</code>. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>best</code></td>
<td>
<p>Needed in the case of localized ranking. The parameter <code>K</code> of the localized ranking loss will be
computed by <code class="reqn">best \cdot n</code> (rounded to the next larger integer). Warning: If a parameter <code>K</code> is inserted into the
<code>LocRank</code> family, it will be ignored when executing SingBoost.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Divides the data set into a training and a validation set. The SingBoost models are computed on the training
set and evaluated on the validation set based on the loss function corresponding to the selected Boosting family.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>loss</code></td>
<td>
<p>Vector of validation losses.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>occ</code></td>
<td>
<p>Selection frequencies for each Boosting model.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Werner, T., Gradient-Free Gradient Boosting, PhD Thesis, Carl von Ossietzky University Oldenburg, 2020
</p>


</div>