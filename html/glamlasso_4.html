<div class="container">

<table style="width: 100%;"><tr>
<td>glamlassoRR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Penalized reduced rank regression  in a GLAM</h2>

<h3>Description</h3>

<p>Efficient design matrix free procedure for fitting large scale penalized reduced rank
regressions in a 3-dimensional generalized linear array model. To obtain a factorization of the parameter array, 
the <code>glamlassoRR</code> function performes a block relaxation scheme within the gdpg algorithm, see <cite>Lund and Hansen, 2018</cite>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">glamlassoRR(X, 
            Y, 
            Z = NULL,
            family = "gaussian",
            penalty = "lasso",
            intercept = FALSE,
            weights = NULL,
            betainit = NULL,
            alphainit = NULL,
            nlambda = 100,
            lambdaminratio = 1e-04,
            lambda = NULL,
            penaltyfactor = NULL,
            penaltyfactoralpha = NULL,
            reltolinner = 1e-07,
            reltolouter = 1e-04,
            reltolalt = 1e-04,
            maxiter = 15000,
            steps = 1,
            maxiterinner = 3000,
            maxiterouter = 25,
            maxalt = 10,
            btinnermax = 100,
            btoutermax  = 100,
            iwls = "exact",
            nu = 1)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>A list containing the 3 tensor components of the tensor design matrix. These are  matrices of sizes <code class="reqn">n_i   \times p_i</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>The response values, an array of size <code class="reqn">n_1 \times n_2\times n_3</code>. For option 
<code>family = "binomial"</code> this array must contain the proportion of successes and the 
number of trials is then specified as <code>weights</code> (see below).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>The non tensor structrured part of the design matrix. A matrix of size <code class="reqn">n_1 n_2 n_3\times q</code>. 
Is set to <code>NULL</code> as default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>A string specifying the model family (essentially the response distribution). Possible values 
are <code>"gaussian", "binomial", "poisson", "gamma"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalty</code></td>
<td>
<p>A string specifying the penalty. Possible values are <code>"lasso", "scad"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Logical variable indicating if the model includes an intercept.  When <code>intercept = TRUE</code> the first 
coulmn in the non-tensor design component <code>Z</code> is all 1s. Default is <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>Observation weights, an array of size <code class="reqn">n_1 \times \cdots \times n_d</code>. For option 
<code>family = "binomial"</code> this array must contain the number of trials and must be provided.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betainit</code></td>
<td>
<p>A list (length 2) containing the initial parameter values for each of the parameter factors. 
Default is NULL in which case all parameters are initialized at 0.01.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphainit</code></td>
<td>
<p>A <code class="reqn">q\times 1</code> vector containing the initial parameter values for the non-tensor parameter. 
Default is NULL in which case all parameters are initialized at 0.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of <code>lambda</code> values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambdaminratio</code></td>
<td>
<p>The smallest value for <code>lambda</code>, given as a fraction of 
<code class="reqn">\lambda_{max}</code>; the (data derived) smallest value for which all coefficients are zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The sequence of penalty parameters for the regularization path.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penaltyfactor</code></td>
<td>
<p>A list of length two containing an array of size <code class="reqn">p_1 \times  p_2</code> and a <code class="reqn">p_3 \times  1</code> vector.
Multiplied  with each element in <code>lambda</code> to allow differential shrinkage on the (tensor) coefficients blocks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penaltyfactoralpha</code></td>
<td>
<p>A <code class="reqn">q \times 1</code> vector multiplied with each element in <code>lambda</code> to allow differential shrinkage on the non-tensor coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltolinner</code></td>
<td>
<p>The convergence tolerance for the inner loop</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltolouter</code></td>
<td>
<p>The convergence tolerance for the outer loop.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>reltolalt</code></td>
<td>
<p>The convergence tolerance for the alternation loop over the two parameter blocks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiter</code></td>
<td>
<p>The maximum number of inner iterations allowed for each <code>lambda</code>
value, when  summing over all outer iterations for said <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>steps</code></td>
<td>
<p>The number of steps used in the multi-step adaptive lasso algorithm for non-convex penalties. Automatically set to 1 when <code>penalty = "lasso"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiterinner</code></td>
<td>
<p>The maximum number of inner iterations allowed for each outer iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxiterouter</code></td>
<td>
<p>The maximum number of outer iterations allowed for each lambda.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>maxalt</code></td>
<td>
<p>The maximum number of  alternations over parameter blocks.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>btinnermax</code></td>
<td>
<p>Maximum number of backtracking steps allowed in each inner iteration. Default is <code>btinnermax = 100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>btoutermax</code></td>
<td>
<p>Maximum number of backtracking steps allowed in each outer iteration. Default is <code>btoutermax = 100</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iwls</code></td>
<td>
<p>A string indicating whether to use the exact iwls weight matrix or use a tensor structured approximation to it.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nu</code></td>
<td>
<p>A number between 0 and 1 that controls the step size <code class="reqn">\delta</code> in the proximal algorithm (inner loop) by 
scaling the upper bound <code class="reqn">\hat{L}_h</code> on the Lipschitz constant <code class="reqn">L_h</code> (see <cite>Lund et al., 2017</cite>). 
For <code>nu = 1</code> backtracking never occurs and the proximal step size is always <code class="reqn">\delta = 1 / \hat{L}_h</code>. 
For <code>nu = 0</code> backtracking always occurs and the proximal step size is initially <code class="reqn">\delta = 1</code>. 
For <code>0 &lt; nu &lt; 1</code> the proximal step size is initially <code class="reqn">\delta = 1/(\nu\hat{L}_h)</code> and backtracking 
is only employed if the objective function does not decrease. A <code>nu</code> close  to 0 gives large step 
sizes and presumably more backtracking in the inner loop. The default is <code>nu = 1</code> and the option is only 
used if <code>iwls = "exact"</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Given the setting from <code>glamlasso</code> we place a reduced rank
restriction on the <code class="reqn">p_1\times p_2\times p _3</code> parameter array <code class="reqn">B</code> 
given by
</p>
<p style="text-align: center;"><code class="reqn">B=(B_{i,j,k})_{i,j,k} = (\gamma_{k}\kappa_{i,j})_{i,j,k}, \ \ \ \gamma_k,\kappa_{i,j}\in \mathcal{R}.</code>
</p>
  
<p>The  <code>glamlassoRR</code> function  solves the PMLE problem by combining a 
block relaxation scheme with the gdpg algorithm. This scheme alternates 
between  optimizing over the first parameter block <code class="reqn">\kappa=(\kappa_{i,j})_{i,j}</code> 
and  the second block <code class="reqn">\gamma=(\gamma_k)_k</code> while fixing the second resp. 
first block. 
</p>
<p>Note that the individual parameter blocks are only identified up to a 
multiplicative constant. Also note that the algorithm is sensitive to
inital values <code>betainit</code> which can prevent convergence.
</p>


<h3>Value</h3>

<p>An object with S3 Class "glamlasso". 
</p>
<table>
<tr style="vertical-align: top;">
<td><code>spec</code></td>
<td>
<p>A string indicating the model family and the penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef12</code></td>
<td>
<p>A <code class="reqn">p_1 p_2 \times</code> <code>nlambda</code> matrix containing the 
estimates of the first model coefficient factor  (<code class="reqn">\kappa</code>) for each 
<code>lambda</code>-value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>coef3</code></td>
<td>
<p>A <code class="reqn">p_3 \times</code> <code>nlambda</code> matrix containing the 
estimates of the second model coefficient factor  (<code class="reqn">\gamma</code>) for each 
<code>lambda</code>-value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>A <code class="reqn">q \times</code> <code>nlambda</code> matrix containing the estimates 
of the parameters for the non tensor structured part of the model 
(<code>alpha</code>) for each <code>lambda</code>-value. If <code>intercept = TRUE</code> the 
first row contains the intercept estimate for each <code>lambda</code>-value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>A vector containing the sequence of penalty values used in the 
estimation procedure.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
<p>The number of nonzero coefficients for each value of <code>lambda</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dimcoef</code></td>
<td>
<p>A vector giving the dimension of the model coefficient array 
<code class="reqn">\beta</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>dimobs</code></td>
<td>
<p>A vector giving the dimension of the observation (response) 
array <code>Y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Iter</code></td>
<td>
<p>A list with 4 items: <code>bt_iter_inner</code>  is total number of 
backtracking steps performed in the inner loop, <code>bt_enter_inner</code> is the 
number of times the backtracking is initiated in the inner loop, 
<code>bt_iter_outer</code> is total number of backtracking steps performed in the 
outer loop, and <code>iter_mat</code> is a <code>nlambda</code> <code class="reqn">\times</code> 
<code>maxiterouter</code> matrix containing the  number of inner iterations for 
each <code>lambda</code> value and each outer iteration and  <code>iter</code> is total 
number of iterations i.e. <code>sum(Iter)</code>.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Adam Lund
</p>
<p>Maintainer: Adam Lund, <a href="mailto:adam.lund@math.ku.dk">adam.lund@math.ku.dk</a>
</p>


<h3>References</h3>

<p>Lund, A., M. Vincent, and N. R. Hansen (2017). Penalized estimation in 
large-scale generalized linear array models. 
<em>Journal of Computational and Graphical Statistics</em>, 26, 3, 709-724.  url = https://doi.org/10.1080/10618600.2017.1279548.
</p>
<p>Lund, A. and N. R. Hansen (2019). Sparse Network  Estimation for  Dynamical Spatio-temporal Array Models. 
<em>Journal of Multivariate Analysis</em>, 174. url = https://doi.org/10.1016/j.jmva.2019.104532.
</p>


<h3>Examples</h3>

<pre><code class="language-R"> 
##size of example 
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 12; p2 &lt;- 6; p3 &lt;- 4

##marginal design matrices (tensor components)
X1 &lt;- matrix(rnorm(n1 * p1), n1, p1) 
X2 &lt;- matrix(rnorm(n2 * p2), n2, p2) 
X3 &lt;- matrix(rnorm(n3 * p3), n3, p3) 
X &lt;- list(X1, X2, X3)
Beta12 &lt;- matrix(rnorm(p1 * p2), p1, p2) * matrix(rbinom(p1 * p2, 1, 0.5), p1, p2)
Beta3 &lt;- matrix(rnorm(p3) * rbinom(p3, 1, 0.5), p3, 1)
Beta &lt;- outer(Beta12, c(Beta3))
Mu &lt;- RH(X3, RH(X2, RH(X1, Beta)))
Y &lt;- array(rnorm(n1 * n2 * n3, Mu), dim = c(n1, n2, n3))  

system.time(fit &lt;- glamlassoRR(X, Y))

modelno  &lt;- length(fit$lambda)
oldmfrow &lt;- par()$mfrow
par(mfrow = c(1, 3))
plot(c(Beta), type = "h")
points(c(Beta))
lines(c(outer(fit$coef12[, modelno], c(fit$coef3[, modelno]))), col = "red", type = "h")
plot(c(Beta12), ylim = range(Beta12, fit$coef12[, modelno]), type = "h")
points(c(Beta12))
lines(fit$coef12[, modelno], col = "red", type = "h")
plot(c(Beta3), ylim = range(Beta3, fit$coef3[, modelno]), type = "h")
points(c(Beta3))
lines(fit$coef3[, modelno], col = "red", type = "h")
par(mfrow = oldmfrow)

###with non tensor design component Z
q &lt;- 5
alpha &lt;- matrix(rnorm(q)) * rbinom(q, 1, 0.5)
Z &lt;- matrix(rnorm(n1 * n2 * n3 * q), n1 * n2 * n3, q) 
Y &lt;- array(rnorm(n1 * n2 * n3, Mu + array(Z %*% alpha, c(n1, n2, n3))), c(n1, n2, n3))
system.time(fit &lt;- glamlassoRR(X, Y, Z))

modelno &lt;- length(fit$lambda)
oldmfrow &lt;- par()$mfrow
par(mfrow = c(2, 2))
plot(c(Beta), type = "h")
points(c(Beta))
lines(c(outer(fit$coef12[, modelno], c(fit$coef3[, modelno]))), col = "red", type = "h")
plot(c(Beta12), ylim = range(Beta12,fit$coef12[, modelno]), type = "h")
points(c(Beta12))
lines(fit$coef12[, modelno], col = "red", type = "h")
plot(c(Beta3), ylim = range(Beta3, fit$coef3[, modelno]), type = "h")
points(c(Beta3))
lines(fit$coef3[, modelno], col = "red", type = "h")
plot(c(alpha), ylim = range(alpha, fit$alpha[, modelno]), type = "h")
points(c(alpha))
lines(fit$alpha[, modelno], col = "red", type = "h")
par(mfrow = oldmfrow)

################ poisson example
set.seed(7954) ## for this seed the algorithm fails to converge for default initial values!!
set.seed(42)
##size of example 
n1 &lt;- 65; n2 &lt;- 26; n3 &lt;- 13; p1 &lt;- 12; p2 &lt;- 6; p3 &lt;- 4

##marginal design matrices (tensor components)
X1 &lt;- matrix(rnorm(n1 * p1), n1, p1) 
X2 &lt;- matrix(rnorm(n2 * p2), n2, p2) 
X3 &lt;- matrix(rnorm(n3 * p3), n3, p3) 
X &lt;- list(X1, X2, X3)

Beta12 &lt;- matrix(rnorm(p1 * p2, 0, 0.5) * rbinom(p1 * p2, 1, 0.1), p1, p2) 
Beta3 &lt;-  matrix(rnorm(p3, 0, 0.5) * rbinom(p3, 1, 0.5), p3, 1)
Beta &lt;- outer(Beta12, c(Beta3))
Mu &lt;- RH(X3, RH(X2, RH(X1, Beta)))
Y &lt;- array(rpois(n1 * n2 * n3, exp(Mu)), dim = c(n1, n2, n3))
system.time(fit &lt;- glamlassoRR(X, Y ,family = "poisson"))
modelno &lt;- length(fit$lambda)
oldmfrow &lt;- par()$mfrow
par(mfrow = c(1, 3))
plot(c(Beta), type = "h")
points(c(Beta))
lines(c(outer(fit$coef12[, modelno], c(fit$coef3[, modelno]))), col = "red", type = "h")
plot(c(Beta12), ylim = range(Beta12, fit$coef12[, modelno]), type = "h")
points(c(Beta12))
lines(fit$coef12[, modelno], col = "red", type = "h")
plot(c(Beta3), ylim = range(Beta3, fit$coef3[, modelno]), type = "h")
points(c(Beta3))
lines(fit$coef3[, modelno], col = "red", type = "h")
par(mfrow = oldmfrow)


</code></pre>


</div>