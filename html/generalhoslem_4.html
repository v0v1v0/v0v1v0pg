<div class="container">

<table style="width: 100%;"><tr>
<td>logitgof</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Hosmer-Lemeshow Tests for Logistic Regression Models</h2>

<h3>Description</h3>

<p>Performs the Hosmer-Lemeshow goodness of fit tests for binary, multinomial and ordinal logistic regression models.</p>


<h3>Usage</h3>

<pre><code class="language-R">logitgof(obs, exp, g = 10, ord = FALSE)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obs</code></td>
<td>
<p> a vector of observed values. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>exp</code></td>
<td>
<p> expected values fitted by the model. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>g</code></td>
<td>
<p> number of quantiles of risk, 10 by default.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ord</code></td>
<td>
<p> logical indicating whether to run the ordinal version, FALSE by default.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p><b>The Hosmer-Lemeshow tests</b>
The Hosmer-Lemeshow tests are goodness of fit tests for binary, multinomial and ordinal logistic regression models. <code>logitgof</code> is capable of performing all three. Essentially, they compare observed with expected frequencies of the outcome and compute a test statistic which is distributed according to the chi-squared distribution. The degrees of freedom depend upon the number of quantiles used and the number of outcome categories. A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).
</p>
<p><b>Binary version</b>
If <code>obs</code> is a vector of 1s and 0s or a factor vector with 2 levels, then the binary version of the test is run. <code>exp</code> must be the fitted values obtained from the model, which can be accessed using the <code>fitted()</code> function.
</p>
<p><b>Multinomial version</b>
If <code>obs</code> is a factor with three or more levels and <code>ord = FALSE</code>, the multinomial version of the test is run. If  using the <code>mlogit</code> package to run a model, ensure <code>outcome = FALSE</code> in the <code>fitted()</code> function. See examples.
</p>
<p><b>Ordinal version</b>
If <code>obs</code> is a factor with three or more levels and <code>ord = TRUE</code>, the ordinal version of the test is run. See examples for how to extract fitted values from models constructed using <code>MASS::polr</code> or <code>oridinal::clm</code>.
</p>
<p>Note that Fagerland and Hosmer (2013) point out that the model needs to have at least as many covariate patterns as groups. This is achieved easily where there are continuous predictors or several categorical variables. This test will not be valid where there is only one or two categorical predictor variables. Fagerland and Hosmer (2016) also recommend running the Hosmer-Lemeshow test for ordinal models alongisde the Lipsitz test (<code>lipsitz.test</code>) and Pulkstenis-Robinson tests (<code>pulkrob.chisq</code> and <code>pulkrob.deviance</code>), as each detects different types of lack of fit.
</p>
<p>Finally, it has been observed that the results from this implementation of the binary and ordinal Hosmer-Lemeshow tests and the Lipsitz test are slightly different from the Stata implementations. It is not not yet clear why this is but is under investigation.
</p>


<h3>Value</h3>

<p>A list of class <code>htest</code> containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>statistic</code></td>
<td>
<p> the value of the relevant test statistic.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>parameter</code></td>
<td>
<p> the number of degrees of freedom used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p.value</code></td>
<td>
<p> the p-value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p> a character string indicating whether the binary or multinomial version of the test was performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data.name</code></td>
<td>
<p> a character string containing the names of the data passed to <code>obs</code> and <code>exp</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>observed</code></td>
<td>
<p> a table of observed frequencies with <code>g</code> rows. Either an <code>xtabs</code> generated table (used in the binary version) or a <code>cast</code> generated data frame (multinomial version).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>expected</code></td>
<td>
<p> a table of expected frequencies with <code>g</code> rows. Either an <code>xtabs</code> generated table or a <code>cast</code> generated data frame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stddiffs</code></td>
<td>
<p> a table of the standardised differences. See Hosmer, Lemeshow and Sturdivant (2013), p 162.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Matthew Alexander Jay, with code adapted from <code>ResourceSelection::hoslem.test</code> by Peter Solymos.</p>


<h3>References</h3>


<ul>
<li>
<p> Fagerland MW, Hosmer DW, Bofin AM. Multinomial goodness-of-fit tests for logistic regression models. Statistics in Medicine 2008;27(21):4238-53.
</p>
</li>
<li>
<p> Fagerland MW, Hosmer DW. A goodness-of-fit test for the proportional odds regression model. Statistics in Medicine 2013;32:2235-2249.
</p>
</li>
<li>
<p> Fagerland MW, Hosmer DW. Tests for goodness of fit in ordinal logistic regression models. Journal of Statistical Computation and Simulation 2016. DOI: 10.1080/00949655.2016.1156682.
</p>
</li>
<li>
<p> Fagerland MW, Hosmer DW. How to test for goodness of fit in ordinal logistic regression models. The Stata Journal 2017;17(3):668-686.
</p>
</li>
<li>
<p> Hosmer DW, Lemeshow S, Sturdivant RX. Applied Logistic Regression, 3rd Edition. 2013. New York, USA: John Wiley and Sons.
</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>lipsitz.test</code>, <code>pulkrob.chisq</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">### The mtcars dataset is a terrible example to use due to its small
### size - some of the models will return warnings as a result.
## Binary model
# 1/0 coding
data(mtcars)
mod1 &lt;- glm(vs ~ cyl + mpg, data = mtcars, family = binomial)
logitgof(mtcars$vs, fitted(mod1))

# factor name coding
mtcars$engine &lt;- factor(ifelse(mtcars$vs==0, "V", "S"), levels = c("V", "S"))
mod2 &lt;- glm(engine ~ cyl + mpg, data = mtcars, family = binomial)
logitgof(mtcars$engine, fitted(mod2))

## Multinomial model
# with nnet
library(nnet)
mod3 &lt;- multinom(gear ~ mpg + cyl, data = mtcars)
logitgof(mtcars$gear, fitted(mod3))

# with mlogit
library(mlogit)
data("Fishing", package = "mlogit")
Fish &lt;- mlogit.data(Fishing, varying = c(2:9), shape = "wide", choice = "mode")
mod4 &lt;- mlogit(mode ~ 0 | income, data = Fish)
logitgof(Fishing$mode, fitted(mod4, outcome = FALSE))

## Ordinal model
# polr in package MASS
mod5 &lt;- polr(as.factor(gear) ~ mpg + cyl, data = mtcars)
logitgof(mtcars$gear, fitted(mod5), g = 5, ord = TRUE)

# clm in package ordinal
library(ordinal)
mtcars$gear &lt;- as.factor(mtcars$gear)
mod6 &lt;- clm(gear ~ mpg + cyl, data = mtcars)
predprob &lt;- data.frame(mpg = mtcars$mpg, cyl = mtcars$cyl)
fv &lt;- predict(mod6, newdata = predprob, type = "prob")$fit
logitgof(mtcars$gear, fv, g = 5, ord = TRUE)
</code></pre>


</div>