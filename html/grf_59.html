<div class="container">

<table style="width: 100%;"><tr>
<td>rank_average_treatment_effect.fit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitter function for Rank-Weighted Average Treatment Effect (RATE).</h2>

<h3>Description</h3>

<p>Provides an optional interface to <code>rank_average_treatment_effect</code> which allows for user-supplied
evaluation scores.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rank_average_treatment_effect.fit(
  DR.scores,
  priorities,
  target = c("AUTOC", "QINI"),
  q = seq(0.1, 1, by = 0.1),
  R = 200,
  sample.weights = NULL,
  clusters = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>DR.scores</code></td>
<td>
<p>A vector with the evaluation set scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priorities</code></td>
<td>
<p>Treatment prioritization scores S(Xi) for the units in the evaluation set.
Two prioritization rules can be compared by supplying a two-column array or named list of priorities
(yielding paired standard errors that account for the correlation between RATE metrics estimated on
the same evaluation data).
WARNING: for valid statistical performance, these scores should be constructed independently from the evaluation
dataset used to construct DR.scores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>The type of RATE estimate, options are "AUTOC" (exhibits greater power when only a small subset
of the population experience nontrivial heterogeneous treatment effects) or "QINI" (exhibits greater power
when the entire population experience diffuse or substantial heterogeneous treatment effects).
Default is "AUTOC".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>
<p>The grid q to compute the TOC curve on. Default is
(10%, 20%, ..., 100%).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R</code></td>
<td>
<p>Number of bootstrap replicates for SEs. Default is 200.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sample.weights</code></td>
<td>
<p>Weights given to an observation in estimation.
If NULL, each observation is given the same weight. Default is NULL.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>clusters</code></td>
<td>
<p>Vector of integers or factors specifying which cluster each observation corresponds to.
Default is NULL (ignored).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list of class 'rank_average_treatment_effect' with elements </p>

<ul>
<li>
<p> estimate: the RATE estimate.
</p>
</li>
<li>
<p> std.err: bootstrapped standard error of RATE.
</p>
</li>
<li>
<p> target: the type of estimate.
</p>
</li>
<li>
<p> TOC: a data.frame with the Targeting Operator Characteristic curve
estimated on grid q, along with bootstrapped SEs.
</p>
</li>
</ul>
<h3>Examples</h3>

<pre><code class="language-R">
# Estimate CATEs with a causal forest.
n &lt;- 2000
p &lt;- 5
X &lt;- matrix(rnorm(n * p), n, p)
W &lt;- rbinom(n, 1, 0.5)
event.probability &lt;- 1 / (1 + exp(2 * (pmax(2 * X[, 1], 0) * W - X[, 2])))
Y &lt;- 1 - rbinom(n, 1, event.probability)

train &lt;- sample(1:n, n / 2)
cf.cate &lt;- causal_forest(X[train, ], Y[train], W[train])

# Predict treatment effects on a held-out test set.
test &lt;- -train
cate.hat &lt;-  predict(cf.cate, X[test, ])$predictions

# Estimate AIPW nuisance components on the held-out test set.
Y.forest.eval &lt;- regression_forest(X[test, ], Y[test], num.trees = 500)
Y.hat.eval &lt;- predict(Y.forest.eval)$predictions
W.forest.eval &lt;- regression_forest(X[test, ], W[test], num.trees = 500)
W.hat.eval &lt;- predict(W.forest.eval)$predictions
cf.eval &lt;- causal_forest(X[test, ], Y[test], W[test],
                         Y.hat = Y.hat.eval,
                         W.hat = W.hat.eval)

# Form doubly robust scores.
tau.hat.eval &lt;- predict(cf.eval)$predictions
debiasing.weights.eval &lt;- (W[test] - W.hat.eval) / (W.hat.eval * (1 - W.hat.eval))
Y.residual.eval &lt;- Y[test] - (Y.hat.eval + tau.hat.eval * (W[test] - W.hat.eval))
DR.scores &lt;- tau.hat.eval + debiasing.weights.eval * Y.residual.eval

# Could equivalently be obtained by
# DR.scores &lt;- get_scores(cf.eval)

# Form a doubly robust RATE estimate on the held-out test set.
rate &lt;- rank_average_treatment_effect.fit(DR.scores, cate.hat)
rate

# Same as
# rate &lt;- rank_average_treatment_effect(cf.eval, cate.hat)

# In settings where the treatment randomization probabilities W.hat are known, an
# alternative to AIPW scores is to use inverse-propensity weighting (IPW):
# 1(W=1) * Y / W.hat - 1(W=0) * Y / (1 - W.hat).
# Here, W.hat = 0.5, and an IPW-based estimate of RATE is:
IPW.scores &lt;- ifelse(W[test] == 1, Y[test] / 0.5, -Y[test] / 0.5)
rate.ipw &lt;- rank_average_treatment_effect.fit(IPW.scores, cate.hat)
rate.ipw

# IPW-based estimators typically have higher variance. For details on
# score constructions for other causal estimands, please see the RATE paper.


</code></pre>


</div>