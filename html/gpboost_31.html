<div class="container">

<table style="width: 100%;"><tr>
<td>gpb.grid.search.tune.parameters</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Function for choosing tuning parameters</h2>

<h3>Description</h3>

<p>Function that allows for choosing tuning parameters from a grid in a determinstic or random way using cross validation or validation data sets.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gpb.grid.search.tune.parameters(param_grid, data, params = list(),
  num_try_random = NULL, nrounds = 100L, gp_model = NULL,
  line_search_step_length = FALSE, use_gp_model_for_validation = TRUE,
  train_gp_model_cov_pars = TRUE, folds = NULL, nfold = 4L,
  label = NULL, weight = NULL, obj = NULL, eval = NULL,
  verbose_eval = 1L, stratified = TRUE, init_model = NULL,
  colnames = NULL, categorical_feature = NULL,
  early_stopping_rounds = NULL, callbacks = list(),
  return_all_combinations = FALSE, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>param_grid</code></td>
<td>
<p><code>list</code> with candidate parameters defining the grid over which a search is done</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>a <code>gpb.Dataset</code> object, used for training. Some functions, such as <code>gpb.cv</code>,
may allow you to pass other types of data like <code>matrix</code> and then separately supply
<code>label</code> as a keyword argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>params</code></td>
<td>
<p><code>list</code> with other parameters not included in <code>param_grid</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_try_random</code></td>
<td>
<p><code>integer</code> with number of random trial on parameter grid. If NULL, a deterministic search is done</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nrounds</code></td>
<td>
<p>number of boosting iterations (= number of trees). This is the most important tuning parameter for boosting</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gp_model</code></td>
<td>
<p>A <code>GPModel</code> object that contains the random effects (Gaussian process and / or grouped random effects) model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>line_search_step_length</code></td>
<td>
<p>Boolean. If TRUE, a line search is done to find the optimal step length for every boosting update 
(see, e.g., Friedman 2001). This is then multiplied by the <code>learning_rate</code>. 
Applies only to the GPBoost algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>use_gp_model_for_validation</code></td>
<td>
<p>Boolean. If TRUE, the <code>gp_model</code> 
(Gaussian process and/or random effects) is also used (in addition to the tree model) for calculating 
predictions on the validation data. If FALSE, the <code>gp_model</code> (random effects part) is ignored 
for making predictions and only the tree ensemble is used for making predictions for calculating the validation / test error.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_gp_model_cov_pars</code></td>
<td>
<p>Boolean. If TRUE, the covariance parameters 
of the <code>gp_model</code> (Gaussian process and/or random effects) are estimated in every 
boosting iterations, otherwise the <code>gp_model</code> parameters are not estimated. 
In the latter case, you need to either estimate them beforehand or provide the values via 
the <code>init_cov_pars</code> parameter when creating the <code>gp_model</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p><code>list</code> provides a possibility to use a list of pre-defined CV folds
(each element must be a vector of test fold's indices). When folds are supplied,
the <code>nfold</code> and <code>stratified</code> parameters are ignored.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nfold</code></td>
<td>
<p>the original dataset is randomly partitioned into <code>nfold</code> equal size subsamples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>label</code></td>
<td>
<p>Vector of labels, used if <code>data</code> is not an <code>gpb.Dataset</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weight</code></td>
<td>
<p>vector of response values. If not NULL, will set to dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj</code></td>
<td>
<p>(character) The distribution of the response variable (=label) conditional on fixed and random effects.
This only needs to be set when doing independent boosting without random effects / Gaussian processes.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eval</code></td>
<td>
<p>Evaluation metric to be monitored when doing CV and parameter tuning. 
This can be a string, function, or list with a mixture of strings and functions.
</p>

<ul>
<li>
<p><b>a. character vector</b>:
Non-exhaustive list of supported metrics: "test_neg_log_likelihood", "mse", "rmse", "mae", 
"auc", "average_precision", "binary_logloss", "binary_error"
See <a href="https://gpboost.readthedocs.io/en/latest/Parameters.html#metric-parameters">
the "metric" section of the parameter documentation</a>
for a complete list of valid metrics.

</p>
</li>
<li>
<p><b>b. function</b>:
You can provide a custom evaluation function. This
should accept the keyword arguments <code>preds</code> and <code>dtrain</code> and should return a named
list with three elements:
</p>

<ul>
<li>
<p><code>name</code>: A string with the name of the metric, used for printing
and storing results.

</p>
</li>
<li>
<p><code>value</code>: A single number indicating the value of the metric for the
given predictions and true values

</p>
</li>
<li>
<p><code>higher_better</code>: A boolean indicating whether higher values indicate a better fit.
For example, this would be <code>FALSE</code> for metrics like MAE or RMSE.

</p>
</li>
</ul>
</li>
<li>
<p><b>c. list</b>:
If a list is given, it should only contain character vectors and functions.
These should follow the requirements from the descriptions above.

</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose_eval</code></td>
<td>
<p><code>integer</code>. Whether to display information on the progress of tuning parameter choice. 
If None or 0, verbose is of.
If = 1, summary progress information is displayed for every parameter combination.
If &gt;= 2, detailed progress is displayed at every boosting stage for every parameter combination.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stratified</code></td>
<td>
<p>a <code>boolean</code> indicating whether sampling of folds should be stratified
by the values of outcome labels.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init_model</code></td>
<td>
<p>path of model file of <code>gpb.Booster</code> object, will continue training from this model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>colnames</code></td>
<td>
<p>feature names, if not null, will use this to overwrite the names in dataset</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>categorical_feature</code></td>
<td>
<p>categorical features. This can either be a character vector of feature
names or an integer vector with the indices of the features (e.g.
<code>c(1L, 10L)</code> to say "the first and tenth columns").</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stopping_rounds</code></td>
<td>
<p>int. Activates early stopping. Requires at least one validation data
and one metric. When this parameter is non-null,
training will stop if the evaluation of any metric on any validation set
fails to improve for <code>early_stopping_rounds</code> consecutive boosting rounds.
If training stops early, the returned model will have attribute <code>best_iter</code>
set to the iteration number of the best iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>callbacks</code></td>
<td>
<p>List of callback functions that are applied at each iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>return_all_combinations</code></td>
<td>
<p>a <code>boolean</code> indicating whether all tried 
parameter combinations are returned</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>other parameters, see Parameters.rst for more information.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A <code>list</code> with the best parameter combination and score
The list has the following format:
list("best_params" = best_params, "best_iter" = best_iter, "best_score" = best_score)
If return_all_combinations is TRUE, then the list contains an additional entry 'all_combinations'
</p>


<h3>Early Stopping</h3>

<p>"early stopping" refers to stopping the training process if the model's performance on a given
validation set does not improve for several consecutive iterations.
</p>
<p>If multiple arguments are given to <code>eval</code>, their order will be preserved. If you enable
early stopping by setting <code>early_stopping_rounds</code> in <code>params</code>, by default all
metrics will be considered for early stopping.
</p>
<p>If you want to only consider the first metric for early stopping, pass
<code>first_metric_only = TRUE</code> in <code>params</code>. Note that if you also specify <code>metric</code>
in <code>params</code>, that metric will be considered the "first" one. If you omit <code>metric</code>,
a default metric will be used based on your choice for the parameter <code>obj</code> (keyword argument)
or <code>objective</code> (passed into <code>params</code>).
</p>


<h3>Author(s)</h3>

<p>Fabio Sigrist
</p>


<h3>Examples</h3>

<pre><code class="language-R"># See https://github.com/fabsig/GPBoost/tree/master/R-package for more examples

library(gpboost)
data(GPBoost_data, package = "gpboost")

# Create random effects model, dataset, and define parameter grid
gp_model &lt;- GPModel(group_data = group_data[,1], likelihood="gaussian")
dataset &lt;- gpb.Dataset(X, label = y)
param_grid = list("learning_rate" = c(1,0.1,0.01), 
                  "min_data_in_leaf" = c(10,100,1000),
                  "max_depth" = c(1,2,3,5,10),
                  "lambda_l2" = c(0,1,10))
other_params &lt;- list(num_leaves = 2^10)
# Note: here we try different values for 'max_depth' and thus set 'num_leaves' to a large value.
#       An alternative strategy is to impose no limit on 'max_depth', 
#       and try different values for 'num_leaves' as follows:
# param_grid = list("learning_rate" = c(1,0.1,0.01), 
#                   "min_data_in_leaf" = c(10,100,1000),
#                   "num_leaves" = 2^(1:10),
#                   "lambda_l2" = c(0,1,10))
# other_params &lt;- list(max_depth = -1)
set.seed(1)
opt_params &lt;- gpb.grid.search.tune.parameters(param_grid = param_grid, params = other_params,
                                              num_try_random = NULL, nfold = 4,
                                              data = dataset, gp_model = gp_model,
                                              use_gp_model_for_validation=TRUE, verbose_eval = 1,
                                              nrounds = 1000, early_stopping_rounds = 10)
print(paste0("Best parameters: ",
             paste0(unlist(lapply(seq_along(opt_params$best_params), 
                                  function(y, n, i) { paste0(n[[i]],": ", y[[i]]) }, 
                                  y=opt_params$best_params, 
                                  n=names(opt_params$best_params))), collapse=", ")))
print(paste0("Best number of iterations: ", opt_params$best_iter))
print(paste0("Best score: ", round(opt_params$best_score, digits=3)))
# Note: other scoring / evaluation metrics can be chosen using the 
#       'metric' argument, e.g., metric = "l1"

# Using manually defined validation data instead of cross-validation
valid_tune_idx &lt;- sample.int(length(y), as.integer(0.2*length(y)))
folds = list(valid_tune_idx)
opt_params &lt;- gpb.grid.search.tune.parameters(param_grid = param_grid, params = other_params,
                                              num_try_random = NULL, folds = folds,
                                              data = dataset, gp_model = gp_model,
                                              use_gp_model_for_validation=TRUE, verbose_eval = 1,
                                              nrounds = 1000, early_stopping_rounds = 10)


</code></pre>


</div>