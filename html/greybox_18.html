<div class="container">

<table style="width: 100%;"><tr>
<td>AICc</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Corrected Akaike's Information Criterion and Bayesian Information Criterion</h2>

<h3>Description</h3>

<p>This function extracts AICc / BICc from models. It can be applied to wide
variety of models that use logLik() and nobs() methods (including the
popular lm, forecast, smooth classes).
</p>


<h3>Usage</h3>

<pre><code class="language-R">AICc(object, ...)

BICc(object, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>Time series model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Some stuff.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>AICc was proposed by Nariaki Sugiura in 1978 and is used on small samples
for the models with normally distributed residuals. BICc was derived in
McQuarrie (1999) and is used in similar circumstances.
</p>
<p>IMPORTANT NOTE: both of the criteria can only be used for univariate models
(regression models, ARIMA, ETS etc) with normally distributed residuals!
In case of multivariate models, both criteria need to be modified. See
Bedrick &amp; Tsai (1994) for details.
</p>


<h3>Value</h3>

<p>This function returns numeric value.
</p>


<h3>Author(s)</h3>

<p>Ivan Svetunkov, <a href="mailto:ivan@svetunkov.ru">ivan@svetunkov.ru</a>
</p>


<h3>References</h3>


<ul>
<li>
<p> Burnham Kenneth P. and Anderson David R. (2002). Model Selection
and Multimodel Inference. A Practical Information-Theoretic Approach.
Springer-Verlag New York. DOI: [10.1007/b97636](http://dx.doi.org/10.1007/b97636).
</p>
</li>
<li>
<p> McQuarrie, A. D. (1999). A small-sample correction for the Schwarz SIC model
selection criterion. Statistics &amp; Probability Letters, 44(1), 79â€“86.
[10.1016/S0167-7152(98)00294-6](https://doi.org/10.1016/S0167-7152(98)00294-6).
</p>
</li>
</ul>
<ul>
<li>
<p> McQuarrie A.D., A small-sample correction for the Schwarz SIC
model selection criterion, Statistics &amp; Probability Letters 44 (1999)
pp.79-86. <a href="https://doi.org/10.1016/S0167-7152%2898%2900294-6">doi:10.1016/S0167-7152(98)00294-6</a>
</p>
</li>
<li>
<p> Sugiura Nariaki (1978) Further analysts of the data by Akaike's
information criterion and the finite corrections, Communications in
Statistics - Theory and Methods, 7:1, 13-26,
<a href="https://doi.org/10.1080/03610927808827599">doi:10.1080/03610927808827599</a>
</p>
</li>
<li>
<p> Bedrick, E. J., &amp; Tsai, C.-L. (1994). Model Selection for
Multivariate Regression in Small Samples. Biometrics, 50(1), 226.
<a href="https://doi.org/10.2307/2533213">doi:10.2307/2533213</a>
</p>
</li>
</ul>
<h3>See Also</h3>

<p>AIC, BIC
</p>


<h3>Examples</h3>

<pre><code class="language-R">
xreg &lt;- cbind(rnorm(100,10,3),rnorm(100,50,5))
xreg &lt;- cbind(100+0.5*xreg[,1]-0.75*xreg[,2]+rnorm(100,0,3),xreg,rnorm(100,300,10))
colnames(xreg) &lt;- c("y","x1","x2","Noise")

ourModel &lt;- stepwise(xreg)

AICc(ourModel)
BICc(ourModel)

</code></pre>


</div>