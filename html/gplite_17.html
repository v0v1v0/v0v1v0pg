<div class="container">

<table style="width: 100%;"><tr>
<td>gp_loo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model assessment and comparison</h2>

<h3>Description</h3>

<p>Function <code>gp_loo</code> computes the approximate leave-one-out (LOO)
cross-validation statistics for the given GP model with the current
hyperparameters.
Function <code>gp_compare</code> estimates the difference in the expected
predictive accuracy of two or more GP models given their LOO statistics.
</p>


<h3>Usage</h3>

<pre><code class="language-R">gp_loo(
  gp,
  x,
  y,
  quadrature = TRUE,
  quad_order = 11,
  draws = 4000,
  jitter = NULL,
  seed = NULL,
  ...
)

gp_compare(..., ref = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>gp</code></td>
<td>
<p>The gp model object to be fitted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>n-by-d matrix of input values (n is the number of observations and d the input dimension).
Can also be a vector of length n if the model has only a single input.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Vector of n output (target) values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quadrature</code></td>
<td>
<p>Whether to use deterministic Gauss-Hermite quadrature to estimate the
required integrals. If FALSE, then Monte Carlo estimate is used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quad_order</code></td>
<td>
<p>Order of the numerical quadrature
(only applicable if <code>quadrature=TRUE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>draws</code></td>
<td>
<p>Number of posterior draws to estimate the required integrals (only applicable
if <code>quadrature=FALSE</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jitter</code></td>
<td>
<p>Magnitude of diagonal jitter for covariance matrices for numerical stability.
Default is 1e-6.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Random seed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>For <code>gp_compare</code>, LOO statistics for the models to compare. For
<code>gp_loo</code>, possible additional data that is required for LOO predictions (for example,
argument <code>trials</code> in case of binomial likelihood).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ref</code></td>
<td>
<p>Index of the model against which to compare the other models (pairwise
comparison for LOO difference). If not given, then the model with the best LOO is
used as the reference for comparisons.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>gp_loo</code> returns a list with LOO statistics.
<code>gp_compare</code> returns a matrix with comparison statistics (LOO differences 
and stardard errors in the estimates).
</p>


<h3>References</h3>

<p>Vehtari A., Mononen T., Tolvanen V., Sivula T. and Winther O. (2016).
Bayesian Leave-One-Out Cross-Validation Approximations for Gaussian Latent
Variable Models. Journal of Machine Learning Research 17(103):1-38.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# Generate some toy data
set.seed(32004)
n &lt;- 50
sigma &lt;- 0.1
x &lt;- rnorm(n)
ycont &lt;- sin(3 * x) * exp(-abs(x)) + rnorm(n) * sigma
y &lt;- rep(0, n)
y[ycont &gt; 0] &lt;- 1
trials &lt;- rep(1, n)

# Set up two models
gp1 &lt;- gp_init(cf_sexp(), lik_binomial())
gp2 &lt;- gp_init(cf_matern32(), lik_binomial())

# Optimize
gp1 &lt;- gp_optim(gp1, x, y, trials = trials)
gp2 &lt;- gp_optim(gp2, x, y, trials = trials)

# Compare
loo1 &lt;- gp_loo(gp1, x, y, trials = trials)
loo2 &lt;- gp_loo(gp2, x, y, trials = trials)
gp_compare(loo1, loo2)


</code></pre>


</div>