<div class="container">

<table style="width: 100%;"><tr>
<td>coef.cv.gglasso</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>get coefficients or make coefficient predictions from a "cv.gglasso" object.</h2>

<h3>Description</h3>

<p>This function gets coefficients or makes coefficient predictions from a
cross-validated <code>gglasso</code> model, using the stored <code>"gglasso.fit"</code>
object, and the optimal value chosen for <code>lambda</code>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'cv.gglasso'
coef(object, s = c("lambda.1se", "lambda.min"), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>fitted <code>cv.gglasso</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s</code></td>
<td>
<p>value(s) of the penalty parameter <code>lambda</code> at which
predictions are required. Default is the value <code>s="lambda.1se"</code> stored
on the CV <code>object</code>, it is the largest value of <code>lambda</code> such that
error is within 1 standard error of the minimum. Alternatively
<code>s="lambda.min"</code> can be used, it is the optimal value of <code>lambda</code>
that gives minimum cross validation error <code>cvm</code>. If <code>s</code> is
numeric, it is taken as the value(s) of <code>lambda</code> to be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>not used. Other arguments to predict.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function makes it easier to use the results of cross-validation to get
coefficients or make coefficient predictions.
</p>


<h3>Value</h3>

<p>The coefficients at the requested values for <code>lambda</code>.
</p>


<h3>Author(s)</h3>

<p>Yi Yang and Hui Zou<br> Maintainer: Yi Yang &lt;yi.yang6@mcgill.ca&gt;
</p>


<h3>References</h3>

<p>Yang, Y. and Zou, H. (2015), “A Fast Unified Algorithm for
Computing Group-Lasso Penalized Learning Problems,” <em>Statistics and
Computing</em>. 25(6), 1129-1141.<br> BugReport:
<a href="https://github.com/emeryyi/gglasso">https://github.com/emeryyi/gglasso</a><br></p>
<p>Friedman, J., Hastie, T., and Tibshirani, R. (2010), "Regularization paths
for generalized linear models via coordinate descent," <em>Journal of
Statistical Software, 33, 1.</em><br><a href="http://www.jstatsoft.org/v33/i01/">http://www.jstatsoft.org/v33/i01/</a>
</p>


<h3>See Also</h3>

<p><code>cv.gglasso</code>, and <code>predict.cv.gglasso</code>
methods.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
# load gglasso library
library(gglasso)

# load data set
data(colon)

# define group index
group &lt;- rep(1:20,each=5)

# 5-fold cross validation using group lasso 
# penalized logisitic regression
cv &lt;- cv.gglasso(x=colon$x, y=colon$y, group=group, loss="logit",
pred.loss="misclass", lambda.factor=0.05, nfolds=5)

# the coefficients at lambda = lambda.1se
pre = coef(cv$gglasso.fit, s = cv$lambda.1se)
</code></pre>


</div>