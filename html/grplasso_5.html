<div class="container">

<table style="width: 100%;"><tr>
<td>grpl.control-class</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Class "grpl.control": Options for the Group Lasso Algorithm</h2>

<h3>Description</h3>

<p>Objects of class "grpl.control" define options such as bounds on the Hessian,
convergence criteria and output management for the Group Lasso algorithm.
</p>


<h3>Details</h3>

<p>For the convergence criteria see chapter 8.2.3.2 of Gill et
al. (1981).</p>


<h3>Objects from the Class</h3>

<p>Objects can be created by calls of the form <code>grpl.control(...)</code>
</p>


<h3>Slots</h3>


<dl>
<dt><code>save.x</code></dt>
<dd>
<p>a logical indicating whether the design matrix
should be saved.</p>
</dd> 
<dt><code>save.y</code></dt>
<dd>
<p>a logical indicating whether the response should
be saved.</p>
</dd> 
<dt><code>update.hess</code></dt>
<dd>
<p>should the hessian be updated in each
iteration ("always")? update.hess = "lambda" will update
the Hessian once for each component of the penalty
parameter "lambda" based on the parameter estimates
corresponding to the previous value of the penalty
parameter.</p>
</dd>
<dt><code>update.every</code></dt>
<dd>
<p>Only used if update.hess = "lambda". E.g. set to 3
if you want to update the Hessian only every third grid point.</p>
</dd>
<dt><code>inner.loops</code></dt>
<dd>
<p>How many loops should be done (at maximum)
when solving only the active set (without considering the remaining
predictors). Useful if the number of predictors is large. Set to 0
if no inner loops should be performed.</p>
</dd>
<dt><code>line.search</code></dt>
<dd>
<p>Should line searches be performed?</p>
</dd>
<dt><code>max.iter</code></dt>
<dd>
<p>Maximal number of loops through all groups</p>
</dd>
<dt><code>tol</code></dt>
<dd>
<p>convergence tolerance; the smaller the more precise.</p>
</dd>
<dt><code>lower</code></dt>
<dd>
<p>lower bound for the diagonal approximation of the
corresponding block submatrix of the Hessian of the negative
log-likelihood function.</p>
</dd>
<dt><code>upper</code></dt>
<dd>
<p>upper bound for the diagonal approximation of the
corresponding block submatrix of the Hessian of the negative
log-likelihood function.</p>
</dd>
<dt><code>beta</code></dt>
<dd>
<p>scaling factor <code class="reqn">\beta &lt; 1</code> of the Armijo line search.</p>
</dd>
<dt><code>sigma</code></dt>
<dd>
<p><code class="reqn">0 &lt; \sigma &lt; 1</code> used in the Armijo line search.</p>
</dd>
<dt><code>trace</code></dt>
<dd>
<p>integer. <code>1</code> prints the current lambda value,
<code>2</code> prints the improvement in the objective function after each
sweep through all the parameter groups and additional information.</p>
</dd>
</dl>
<h3>References</h3>

<p>Philip E. Gill, Walter Murray and Margaret H. Wright (1981)
<em>Practical Optimization</em>, Academic Press.
</p>
<p>Dimitri P. Bertsekas (2003) <em>Nonlinear Programming</em>, Athena Scientific.</p>


</div>