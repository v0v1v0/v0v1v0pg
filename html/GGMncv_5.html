<div class="container">

<table style="width: 100%;"><tr>
<td>compare_edges</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compare Edges Between Gaussian Graphical Models</h2>

<h3>Description</h3>

<p>Establish whether each of the corresponding edges
are significantly different in two groups,
with the de-sparsified estimator of (Jankova and Van De Geer 2015).
</p>


<h3>Usage</h3>

<pre><code class="language-R">compare_edges(object_1, object_2, method = "fdr", alpha = 0.05, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object_1</code></td>
<td>
<p>object of class <code>ggmncv</code> .</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object_2</code></td>
<td>
<p>An object of class <code>ggmncv</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Character string. A correction method for
multiple comparisons (defaults to <code>fdr</code>), which
can be abbreviated. See p.adjust.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>Numeric. Significance level (defaults to <code>0.05</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Currently ignored.</p>
</td>
</tr>
</table>
<h3>Value</h3>


<ul>
<li> <p><code>P_diff</code> De-sparsified partial correlation differences
</p>
</li>
<li> <p><code>adj</code> Adjacency matrix based on the p-values.
</p>
</li>
<li> <p><code>pval_uncorrected</code> Uncorrected p-values
</p>
</li>
<li> <p><code>pval_corrected</code> Corrected p-values
</p>
</li>
<li> <p><code>method</code> The approach used for multiple comparisons
</p>
</li>
<li> <p><code>alpha</code> Significance level
</p>
</li>
</ul>
<h3>Note</h3>

<p>For low-dimensional settings, i.e., when the number of observations
far exceeds the number of nodes, this function likely has limited utility and
a non regularized approach should be used for comparing edges
(see for example <strong>GGMnonreg</strong>).
</p>
<p>Further, whether the de-sparsified estimator provides nominal error rates
remains to be seen, at least across a range of conditions. For example,
the simulation results in Williams (2021)
demonstrated that the confidence intervals
can have (severely) compromised coverage properties (whereas non-regularized methods
had coverage at the nominal level).
</p>


<h3>References</h3>

<p>Jankova J, Van De Geer S (2015).
“Confidence intervals for high-dimensional inverse covariance estimation.”
<em>Electronic Journal of Statistics</em>, <b>9</b>(1), 1205–1229.<br><br> Williams DR (2021).
“The Confidence Interval that Wasn't: Bootstrapped "Confidence Intervals" in L1-Regularized Partial Correlation Networks.”
<em>PsyArXiv</em>.
doi: <a href="https://doi.org/10.31234/osf.io/kjh2f">10.31234/osf.io/kjh2f</a>.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># data
# note: all edges equal
Y1 &lt;- MASS::mvrnorm(250, rep(0, 10), Sigma = diag(10))
Y2 &lt;- MASS::mvrnorm(250, rep(0, 10), Sigma = diag(10))

# fit models
# note: atan penalty by default

# group 1
fit1 &lt;- ggmncv(cor(Y1), n = nrow(Y1),
               progress = FALSE)

# group 2
fit2 &lt;- ggmncv(cor(Y2), n = nrow(Y2),
               progress = FALSE)

# compare
compare_ggms &lt;- compare_edges(fit1, fit2)

compare_ggms
</code></pre>


</div>