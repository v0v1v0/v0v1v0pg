<div class="container">

<table style="width: 100%;"><tr>
<td>cv.gam</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Robust Cross-Validation</h2>

<h3>Description</h3>

<p>Compute Robust Cross-Validation for selecting best model.
</p>


<h3>Usage</h3>

<pre><code class="language-R">  cv.gam(X, Y, init.mode = c("sLTS", "RLARS", "RANSAC"),
         lambda.mode = "lambda0", lmax = 1, lmin = 0.05, nlambda = 50,
         fold = 10, ncores = 1, gam = 0.1, gam0 = 0.5, intercept = "TRUE",
         alpha = 1, ini.subsamp = 0.2, ini.cand = 1000, alpha.LTS = 0.75,
         nlambda.LTS = 40)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>Predictor variables Matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>Response variables Matrix.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init.mode</code></td>
<td>
<p><code>"sLTS"</code>: a initial point is the estimate of sparse least trimmed squares. <code>"RLARS"</code>: a initial point is the estimate of Robust LARS. <code>"RANSAC"</code>: a initial point is the estimate of RANSAC algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda.mode</code></td>
<td>
<p><code>"lambda0"</code>: Robust Cross-Validation uses grids on range [0.05lambda0,lambda0] with log scale, where lambda0 is an estimator of sparse tuning parameter which would shrink regression coefficients to zero.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmax</code></td>
<td>
<p>When <code>lambda.mode</code> is not lambda0, upper bound of range of grids is lmax.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmin</code></td>
<td>
<p>When <code>lambda.mode</code> is not lambda0, lower bound of range of grids is lmin.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda</code></td>
<td>
<p>The number of grids for Robust Cross-Validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fold</code></td>
<td>
<p>the number of folds for K-fold Robust Cross-Validation. If <code>fold</code> equals to sample size, Robust Cross-Validation is leave-one-out method.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>positive integer giving the number of processor cores to be used for parallel computing (the default is 1 for no parallelization).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gam</code></td>
<td>
<p>Robust tuning parameter of gamma-divergence for regression.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>gam0</code></td>
<td>
<p>tuning parameter of Robust Cross-Validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept</code></td>
<td>
<p>Should intercept be fitted <code>TRUE</code> or set to zero <code>FALSE</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The elasticnet mixing parameter, with <code class="reqn">0 \le \alpha \le 1</code>. <code>alpha=1</code> is the lasso penalty, and <code>alpha=0</code> the ridge penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ini.subsamp</code></td>
<td>
<p>The fraction of subsamples in "<code>RANSAC</code>".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ini.cand</code></td>
<td>
<p>The number of candidates for estimating itnial points in "<code>RANSAC</code>".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.LTS</code></td>
<td>
<p>The fraction of subsamples for trimmed squares in "<code>sLTS</code>".</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlambda.LTS</code></td>
<td>
<p>The number of grids for sparse tuning parameter in "<code>sLTS</code>".</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If the "<code>RANSAC</code>" is used as the initial point, the parameter <code>ini.subsamp</code> and <code>ini.cand</code> can be determined carefully. The smaller <code>ini.subsamp</code> is, the more robust initial point is. However, less efficiency.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>A numeric vector giving the values of the penalty parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fit</code></td>
<td>
<p>All results at each lambda.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Rocv</code></td>
<td>
<p>The result of best model by Robust Cross-Validation.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Takayuki Kawashima
</p>


<h3>References</h3>

<p>Kawashima, T. and Fujisawa, H. (2017).
<em>Robust and Sparse Regression via gamma-divergence, Entropy, 19(11).</em><br>
Fujisawa, H. and Eguchi, S. (2008).
<em>Robust parameter estimation with a small bias against heavy contamination, Journal of Multivariate Analysis, 99(9), 2053-2081.</em><br></p>


<h3>Examples</h3>

<pre><code class="language-R">  ## generate data
  library(mvtnorm)
  n &lt;- 30                      # number of observations
  p &lt;- 10                      # number of expalanatory variables

  epsilon &lt;- 0.1               # contamination ratio

  beta0 &lt;- 0.0                 # intercept
  beta &lt;- c(numeric(p))        # regression coefficients
  beta[1] &lt;- 1
  beta[2] &lt;- 2
  beta[3] &lt;- 3
  beta[4] &lt;- 4

  Sigma &lt;- 0.2^t(sapply(1:p, function(i, j) abs(i-j), 1:p))
  X &lt;- rmvnorm(n, sigma=Sigma) # explanatory variables
  e &lt;- rnorm(n) # error terms

  i &lt;- 1:ceiling(epsilon*n)    # index of outliers
  e[i] &lt;- e[i] + 20            # vertical outliers
  Y &lt;- beta0*(numeric(n)+1) + X%*%beta


  res &lt;- cv.gam(X,Y,nlambda = 5, nlambda.LTS=20 ,init.mode="sLTS")


</code></pre>


</div>