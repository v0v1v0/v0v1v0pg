<div class="container">

<table style="width: 100%;"><tr>
<td>loss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Loss Function</h2>

<h3>Description</h3>

<p>Implementation of various loss functions to measure
statistical discrepancy between two datasets.
</p>


<h3>Usage</h3>

<pre><code class="language-R">loss(x, y, type = c("MMD", "CvM", "MSE", "BCE"), ...)

MMD(x, y, ...)
CvM(x, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>2d-tensor or <code class="reqn">(n, d)</code>-matrix (during training, <code class="reqn">n</code> is
the batch size and <code class="reqn">d</code> is the dimension of the input dataset).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>2d-tensor or <code class="reqn">(m, d)</code>-matrix (during training, <code class="reqn">m</code> is
the batch size (and typically equal to <code class="reqn">n</code>) and <code class="reqn">d</code> is the
dimension of the input dataset).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p><code>character</code> string indicating the type of
loss used. Currently available are the
(kernel) maximum mean discrepancy (<code>"MMD"</code>, calling <code>MMD()</code>),
the Cramer-von Mises statistc (<code>"CvM"</code>, calling <code>CvM()</code>)
of Rémillard and Scaillet (2009),
the mean squared error (<code>"MSE"</code>)
and the binary cross entropy (<code>"BCE"</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>additional arguments passed to the underlying functions,
most notably <code>bandwidth</code> (a number or numeric vector of
bandwidths for the radial basis function kernels) in case
<code>type = "MMD"</code>.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p><code>loss()</code> returns a 0d tensor containing the loss.
</p>
<p><code>MMD()</code> and <code>CvM()</code> return a 0d tensor (if <code>x</code>
and <code>y</code> are tensors) or <code>numeric(1)</code> (if <code>x</code> or
<code>y</code> are <span style="font-family: Courier New, Courier; color: #666666;"><b>R</b></span> matrices).
</p>


<h3>Author(s)</h3>

<p>Marius Hofert and Avinash Prasad</p>


<h3>References</h3>

<p>Kingma, D. P. and Welling, M. (2014).
Stochastic gradient VB and the variational auto-encoder.
<em>Second International Conference on Learning Representations (ICLR)</em>.
See https://keras.rstudio.com/articles/examples/variational_autoencoder.html
</p>
<p>Rémillard, B. and Scaillet, O. (2009).
Testing for equality between two copulas.
<em>Journal of Multivariate Analysis</em>
<b>100</b>, 377–386.
</p>


<h3>See Also</h3>

<p><code>FNN()</code> where <code>loss()</code> is used.
</p>


</div>